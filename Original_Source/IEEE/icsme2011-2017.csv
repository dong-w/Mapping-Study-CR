Document Title,Authors,Author Affiliations,Publication Title,Date Added To Xplore,Publication_Year,Volume,Issue,Start Page,End Page,Abstract,ISSN,ISBNs,DOI,Funding Information,PDF Link,Author Keywords,IEEE Terms,INSPEC Controlled Terms,INSPEC Non-Controlled Terms,Mesh_Terms,Article Citation Count,Patent Citation Count,Reference Count,Copyright Year,License,Online Date,Issue Date,Meeting Date,Publisher,Document Identifier,,page_num
Late propagation in software clones,L. Barbour; F. Khomh; Y. Zou,"Department of Electrical and Computer Engineering, Queen's University, Kingston, ON, Canada",2011 27th IEEE International Conference on Software Maintenance (ICSM),20111117,2011,,,273,282,"Two similar code segments, or clones, form a clone pair within a software system. The changes to the clones over time create a clone evolution history. In this work we study late propagation, a specific pattern of clone evolution. In late propagation, one clone in the clone pair is modified, causing the clone pair to become inconsistent. The code segments are then re-synchronized in a later revision. Existing work has established late propagation as a clone evolution pattern, and suggested that the pattern is related to a high number of faults. In this study we examine the characteristics of late propagation in two long-lived software systems using the Simian and CCFinder clone detection tools. We define 8 types of late propagation and compare them to other forms of clone evolution. Our results not only verify that late propagation is more harmful to software systems, but also establish that some specific cases of late propagations are more harmful than others. Specifically, two cases are most risky: (1) when a clone experiences inconsistent changes and then a re-synchronizing change without any modification to the other clone in a clone pair; and (2) when two clones undergo an inconsistent modification followed by a re-synchronizing change that modifies both the clones in a clone pair.",1063-6773;10636773,Electronic:978-1-4577-0664-6; POD:978-1-4577-0663-9,10.1109/ICSM.2011.6080794,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6080794,clone genealogies;fault-proneness;late propagation,Cloning,software engineering,CCFinder clone detection tools;Simian clone detection tools;clone evolution history;code segments;late propagation;software clones;software system,,21,,17,,,,25-30 Sept. 2011,,IEEE,IEEE Conferences,,9
SCOTCH: Test-to-code traceability using slicing and conceptual coupling,A. Qusef; G. Bavota; R. Oliveto; A. De Lucia; D. Binkley,"University of Salerno, Fisciano, Italy",2011 27th IEEE International Conference on Software Maintenance (ICSM),20111117,2011,,,63,72,"Maintaining traceability links between unit tests and tested classes is an important factor for effectively managing the development and evolution of software systems. Exploiting traceability links helps in program comprehension and maintenance by ensuring consistency between unit tests and tested classes during maintenance activities. Unfortunately, it is often the case that such links are not explicitly maintained and thus they have to be recovered manually during software evolution. A novel automated solution to this problem, based on dynamic slicing and conceptual coupling, is presented. The resulting tool, SCOTCH (Slicing and Coupling based Test to Code trace Hunter), is empirically evaluated on three systems: an open source system and two industrial systems. The results indicate that SCOTCH identifies traceability links between unit test classes and tested classes with a high accuracy and greater stability than existing techniques, highlighting its potential usefulness as a feature within a software development environment.",1063-6773;10636773,Electronic:978-1-4577-0664-6; POD:978-1-4577-0663-9,10.1109/ICSM.2011.6080773,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6080773,Conceptual Coupling;Empirical Studies;Slicing;Traceability,Accuracy;Couplings;Java;Maintenance engineering;Measurement;Software;Testing,program slicing;program testing;public domain software;reverse engineering;software development management;software maintenance,SCOTCH;automated solution;conceptual coupling;dynamic slicing;industrial system;open source system;program comprehension;software system development management;software system evolution;test to code trace hunter;test-to-code traceability;traceability link maintenance,,16,,27,,,,25-30 Sept. 2011,,IEEE,IEEE Conferences,,9
A seismology-inspired approach to study change propagation,S. Hassaine; F. Boughanmi; Y. G. Guê©hê©neuc; S. Hamel; G. Antoniol,"DIRO, Universit&#x00E9; de Montr&#x00E9;al, Qu&#x00E9;bec, Canada",2011 27th IEEE International Conference on Software Maintenance (ICSM),20111117,2011,,,53,62,"Change impact analysis aims at identifying software artefacts that are being affected by a change. It helps developers to assess their change efforts and perform more adequate changes. Several approaches have been proposed to aid in impact analysis. However, to the best of our knowledge, none of these approaches have been used to study the scope of changes in a program. We present a metaphor inspired by seismology and propose a mapping between the concepts of seismology and change propagation, to study the scope of change propagation. We perform three case studies on Pooka, Rhino, and Xerces-J to observe change propagation. We use ANOVA and Duncan statistical tests to assess the statistically significance of our observations, which show that changes propagate to a limited scope.",1063-6773;10636773,Electronic:978-1-4577-0664-6; POD:978-1-4577-0663-9,10.1109/ICSM.2011.6080772,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6080772,Change Impact Analysis;Change Propagation;Earthquake Forecasting;Software evolution,Earthquakes;History;Measurement;Seismic waves;Seismology;Software;Vectors,software engineering;statistical analysis,Duncan statistical test;Pooka;Rhino;Xerces-J;analysis of variance;change impact analysis;change propagation;object-oriented programming;seismology-inspired approach,,4,,43,,,,25-30 Sept. 2011,,IEEE,IEEE Conferences,,9
Automated change impact analysis for agent systems,H. K. Dam; A. Ghose,"School of Computer Science and Software Engineering, University of Wollongong, New South Wales 2522, Australia",2011 27th IEEE International Conference on Software Maintenance (ICSM),20111117,2011,,,33,42,"Intelligent agent technology has evolved rapidly over the past few years along with the growing number of agent systems in various domains. Although a substantial amount of work in agent-oriented software engineering has provided methodologies for analysing, designing and implementing agent-based systems, recent studies have highlighted that there has been very little work on maintenance and evolution of agent-based systems. A critical issue in software maintenance and evolution is change impact analysis: determining the potential consequences of a proposed change. There has been a proliferation of techniques proposed to support change impact analysis of procedural or object-oriented systems, but to the best of our knowledge, no such an effort has been made for agent-based software. In this paper, we fill this gap by proposing a framework to support change impact analysis for agent systems. At the core of our framework is the taxonomy of atomic changes which can precisely capture semantic differences between versions of an agent system. We also present a change impact model in the form of an intra-agent dependency graph that represents various dependencies within an agent system. An algorithm to compute the set of entities impacted by a change is also presented. The proposed techniques have been implemented in AgentCIA, a change impact analysis plugin for Jason, one of the most well-known agent programming platforms.",1063-6773;10636773,Electronic:978-1-4577-0664-6; POD:978-1-4577-0663-9,10.1109/ICSM.2011.6080770,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6080770,,Computer architecture;Context;Libraries;Robots;Software maintenance;Taxonomy,graph theory;object-oriented programming;software agents;software maintenance,AgentCIA;Jason;agent programming platforms;agent systems;agent-oriented software engineering;atomic change taxonomy;automated change impact analysis;autonomous computational entity;intelligent agent technology;intra-agent dependency graph;object-oriented systems;procedural systems;semantic differences;software agent;software evolution;software maintenance,,6,,20,,,,25-30 Sept. 2011,,IEEE,IEEE Conferences,,9
The evolution of Information Systems a case study on document management,P. Salvaneschi,"University of Bergamo, Faculty of Engineering, Dalmine, Italy",2011 27th IEEE International Conference on Software Maintenance (ICSM),20111117,2011,,,428,437,The paper describes a case study whose aim is to verify a set of hypotheses related to the management of documents during the evolution of Information Systems. The idea is to distinguish the evolution documents (documents that support the evolution of long living applications) from the development documents (related to a single development step of the application life). The evolution documents are derived from the development documents using a minimalist approach and a cost-benefit analysis. The study involved ninety applications of a large information system of a retail company. We describe the context and the method of the study. We present the results and discuss both validity and scope. The evolution documents are a collection of selected parts of the development documents with a size reduction (in pages) of an order of magnitude. The study identifies minimal sets of document types for classes of software applications. These sets are organized into patterns of evolution documents. All the evolution documents are stored into a common knowledge base managed through a wiki-based tool.,1063-6773;10636773,Electronic:978-1-4577-0664-6; POD:978-1-4577-0663-9,10.1109/ICSM.2011.6080810,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6080810,document management;minimalism;software evolution,Databases;Information systems;Maintenance engineering;Software;Software architecture;Supply chains,Web sites;document handling;information systems;knowledge management;retail data processing;software maintenance,cost-benefit analysis;development documents;document management;evolution documents;information system evolution;minimalist approach;retail company;software evolution;wiki-based tool,,0,,28,,,,25-30 Sept. 2011,,IEEE,IEEE Conferences,,9
An automatic framework for extracting and classifying near-miss clone genealogies,R. K. Saha; C. K. Roy; K. A. Schneider,"Department of Computer Science, University of Saskatchewan, Canada",2011 27th IEEE International Conference on Software Maintenance (ICSM),20111117,2011,,,293,302,"Extracting code clone genealogies across multiple versions of a program and classifying them according to their change patterns underlies the study of code clone evolution. While there are a few studies in the area, the approaches do not handle near-miss clones well and the associated tools are often computationally expensive. To address these limitations, we present a framework for automatically extracting both exact and near-miss clone genealogies across multiple versions of a program and for identifying their change patterns using a few key similarity factors. We have developed a prototype clone genealogy extractor, applied it to three open source projects including the Linux Kernel, and evaluated its accuracy in terms of precision and recall. Our experience shows that the prototype is scalable, adaptable to different clone detection tools, and can automatically identify evolution patterns of both exact and near-miss clones by constructing their genealogies.",1063-6773;10636773,Electronic:978-1-4577-0664-6; POD:978-1-4577-0663-9,10.1109/ICSM.2011.6080796,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6080796,clone evolution;clone genealogy extractor;mapping,Accuracy;Cloning;Complexity theory;History;Measurement;Prototypes;Software systems,Linux;operating system kernels;pattern classification;program diagnostics;software maintenance;source coding,Linux kernel;automatic framework;clone detection tools;code clone evolution;key similarity factors;near-miss clone genealogies classification;near-miss clone genealogies extraction;open source projects;software engineering research community,,17,,24,,,,25-30 Sept. 2011,,IEEE,IEEE Conferences,,9
Using source code metrics to predict change-prone Java interfaces,D. Romano; M. Pinzger,"Software Engineering Research Group, Delft University of Technology, The Netherlands",2011 27th IEEE International Conference on Software Maintenance (ICSM),20111117,2011,,,303,312,"Recent empirical studies have investigated the use of source code metrics to predict the change- and defect-proneness of source code files and classes. While results showed strong correlations and good predictive power of these metrics, they do not distinguish between interface, abstract or concrete classes. In particular, interfaces declare contracts that are meant to remain stable during the evolution of a software system while the implementation in concrete classes is more likely to change. This paper aims at investigating to which extent the existing source code metrics can be used for predicting change-prone Java interfaces. We empirically investigate the correlation between metrics and the number of fine-grained source code changes in interfaces of ten Java open-source systems. Then, we evaluate the metrics to calculate models for predicting change-prone Java interfaces. Our results show that the external interface cohesion metric exhibits the strongest correlation with the number of source code changes. This metric also improves the performance of prediction models to classify Java interfaces into change-prone and not change-prone.",1063-6773;10636773,Electronic:978-1-4577-0664-6; POD:978-1-4577-0663-9,10.1109/ICSM.2011.6080797,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6080797,,Complexity theory;Concrete;Correlation;Java;Measurement;Predictive models;Software systems,Java;software metrics;software reliability;user interfaces,Java open-source systems;change-prone Java interfaces;change-proneness;concrete classes;defect-proneness;external interface cohesion metric;fine-grained source code;prediction models;software system;source code classes;source code files;source code metrics,,30,1,38,,,,25-30 Sept. 2011,,IEEE,IEEE Conferences,,9
You can't control the unfamiliar: A study on the relations between aggregation techniques for software metrics,B. Vasilescu; A. Serebrenik; M. van den Brand,"Technische Universiteit Eindhoven, Den Dolech 2, P.O. Box 513, 5600 MB, The Netherlands",2011 27th IEEE International Conference on Software Maintenance (ICSM),20111117,2011,,,313,322,"A popular approach to assessing software maintainability and predicting its evolution involves collecting and analyzing software metrics. However, metrics are usually defined on a micro-level (method, class, package), and should therefore be aggregated in order to provide insights in the evolution at the macro-level (system). In addition to traditional aggregation techniques such as the mean, median, or sum, recently econometric aggregation techniques, such as the Gini, Theil, Kolm, Atkinson, and Hoover inequality indices have been proposed and applied to software metrics. In this paper we present the results of an extensive correlation study of the most widely-used traditional and econometric aggregation techniques, applied to lifting SLOC values from class to package level in the 106 systems comprising the Qualitas Corpus. Moreover, we investigate the nature of this relation, and study its evolution on a subset of 12 systems from the Qualitas Corpus. Our results indicate high and statistically significant correlation between the Gini, Theil, Atkinson, and Hoover indices, i.e., aggregation values obtained using these techniques convey the same information. However, we discuss some of the rationale behind choosing between one index or another.",1063-6773;10636773,Electronic:978-1-4577-0664-6; POD:978-1-4577-0663-9,10.1109/ICSM.2011.6080798,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6080798,,Correlation;Econometrics;Indexes;Java;Software;Software metrics,econometrics;software maintenance;software metrics,Qualitas Corpus;SLOC values;econometric aggregation techniques;software maintainability;software metrics,,17,,60,,,,25-30 Sept. 2011,,IEEE,IEEE Conferences,,9
Source code comprehension strategies and metrics to predict comprehension effort in software maintenance and evolution tasks - an empirical study with industry practitioners,K. Nishizono; S. Morisakl; R. Vivanco; K. Matsumoto,"Graduate School, of Information Science, Nara Institute of Science and Technology, 8916-5 Takayama, Ikoma, 630-0192 JAPAN",2011 27th IEEE International Conference on Software Maintenance (ICSM),20111117,2011,,,473,481,"The goal of this research was to assess the consistency of source code comprehension strategies and comprehension effort estimation metrics, such as LOC, across different types of modification tasks in software maintenance and evolution. We conducted an empirical study with software development practitioners using source code from a small paint application written in Java, along with four semantics-preserving modification tasks (refactoring, defect correction) and four semantics-modifying modification tasks (enhancive and modification). Each task has a change specification and corresponding source code patch. The subjects were asked to comprehend the original source code and then judge whether each patch meets the corresponding change specification in the modification task. The subjects recorded the time to comprehend and described the comprehension strategies used and their reason for the patch judgments. The 24 subjects used similar comprehension strategies. The results show that the comprehension strategies and effort estimation metrics are not consistent across different types of modification tasks. The recorded descriptions indicate the subjects scanned through the original source code and the patches when trying to comprehend patches in the semantics-modifying tasks while the subjects only read the source code of the patches in semantics-preserving tasks. An important metric for estimating comprehension efforts of the semantics-modifying tasks is the Code Clone Subtracted from LOC(CCSLOC), while that of semantics-preserving tasks is the number of referred variables.",1063-6773;10636773,Electronic:978-1-4577-0664-6; POD:978-1-4577-0663-9,10.1109/ICSM.2011.6080814,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6080814,comprehension effort estimation metrics;semantics-modifying;semantics-preserving;software maintenance and evolution;source code comprehension,Analytical models;Measurement,software maintenance;software metrics,code clone subtracted from LOC;comprehension effort estimation metrics;defect correction;evolution task;refactoring;semantics-modifying modification task;semantics-preserving modification task;software development practitioner;software evolution;software maintenance;source code comprehension;source code patch,,2,,17,,,,25-30 Sept. 2011,,IEEE,IEEE Conferences,,8
A cost model based on software maintainability,T. Bakota; P. HegedÅ±s; G. Ladêçnyi; P. Kê_rtvê©lyesi; R. Ferenc; T. Gyimê_thy,"Dept. of Software Eng., Univ. of Szeged, Szeged, Hungary",2012 28th IEEE International Conference on Software Maintenance (ICSM),20130110,2012,,,316,325,"In this paper we present a maintainability based model for estimating the costs of developing source code in its evolution phase. Our model adopts the concept of entropy in thermodynamics, which is used to measure the disorder of a system. In our model, we use maintainability for measuring disorder (i.e. entropy) of the source code of a software system. We evaluated our model on three proprietary and two open source real world software systems implemented in Java, and found that the maintainability of these evolving software is decreasing over time. Furthermore, maintainability and development costs are in exponential relationship with each other. We also found that our model is able to predict future development costs with high accuracy in these systems.",1063-6773;10636773,Electronic:978-1-4673-2312-3; POD:978-1-4673-2313-0,10.1109/ICSM.2012.6405288,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6405288,ISO/IEC 25000;ISO/IEC 9126;Software maintainability;cost prediction model;development cost estimation,Computational modeling;Entropy;Mathematical model;Measurement;Predictive models;Software systems,Java;entropy;public domain software;software cost estimation;software maintenance,Java;cost estimation;cost model;development cost;entropy concept;evolution phase;evolving software;open source real world software system;software maintainability;source code development;system disorder measurement;thermodynamics,,11,,42,,,,23-28 Sept. 2012,,IEEE,IEEE Conferences,,9
Sustainability guidelines for long-living software systems,Z. Durdik; B. Klatt; H. Koziolek; K. Krogmann; J. Stammel; R. Weiss,"Res. Center for Inf. Technol. (FZI), Karlsruhe, Germany",2012 28th IEEE International Conference on Software Maintenance (ICSM),20130110,2012,,,517,526,"Economically sustainable software systems must be able to cost-effectively evolve in response to changes in their environment, their usage profile, and business demands. However, in many software development projects, sustainability is treated as an afterthought, as developers are driven by time-to-market pressure and are often not educated to apply sustainability-improving techniques. While software engineering research and practice has suggested a large amount of such techniques, a holistic overview is missing and the effectiveness of individual techniques is often not sufficiently validated. On this behalf we created a catalog of _ã–software sustainability guidelines_ãù to support project managers, software architects, and developers during system design, development, operation, and maintenance. This paper describes how we derived these guidelines and how we applied selected techniques from them in two industrial case studies. We report several lessons learned about sustainable software development.",1063-6773;10636773,Electronic:978-1-4673-2312-3; POD:978-1-4673-2313-0,10.1109/ICSM.2012.6405316,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6405316,Software maintenance;guidelines;software engineering;sustainable development,Computer architecture;Evolution (biology);Guidelines;Maintenance engineering;Software maintenance;Software systems,project management;software maintenance;sustainable development,business demands;economically sustainable software systems;long-living software systems;software development projects;software engineering practice;software engineering research;software sustainability guidelines;sustainability-improving techniques;system design;system development;system maintenance;system operation;time-to-market pressure;usage profile,,8,,36,,,,23-28 Sept. 2012,,IEEE,IEEE Conferences,,9
Domain specific warnings: Are they any better?,A. Hora; N. Anquetil; S. Ducasse; S. Allier,"RMoD Team, INRIA, Lille, France",2012 28th IEEE International Conference on Software Maintenance (ICSM),20130110,2012,,,441,450,"Tools to detect coding standard violations in source code are commonly used to improve code quality. One of their original goals is to prevent bugs, yet, a high number of false positives is generated by the rules of these tools, i.e., most warnings do not indicate real bugs. There are empirical evidences supporting the intuition that the rules enforced by such tools do not prevent the introduction of bugs in software. This may occur because the rules are too generic and do not focus on domain specific problems of the software under analysis. We underwent an investigation of rules created for a specific domain based on expert opinion to understand if such rules are worthwhile enforcing in the context of defect prevention. In this paper, we performed a systematic study to investigate the relation between generic and domain specific warnings and observed defects. From our experiment on a real case, long term evolution, software, we have found that domain specific rules provide better defect prevention than generic ones.",1063-6773;10636773,Electronic:978-1-4673-2312-3; POD:978-1-4673-2313-0,10.1109/ICSM.2012.6405305,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6405305,,Computer bugs;Conferences;Encoding;History;Software maintenance;Standards,program debugging;software quality,code quality;coding standard violations;defect prevention;domain specific warnings;expert opinion;software bugs;source code,,10,,23,,,,23-28 Sept. 2012,,IEEE,IEEE Conferences,,9
Search-based detection of high-level model changes,A. ben Fadhel; M. Kessentini; P. Langer; M. Wimmer,"Comput. Sci. Dept., Missouri Univ. of Sci. &amp; Technol., Rolla, MO, USA",2012 28th IEEE International Conference on Software Maintenance (ICSM),20130110,2012,,,212,221,"Software models are iteratively refined, restructured and evolved. The detection and analysis of changes applied between two versions of a model are one of the most important tasks during evolution and maintenance activities. In this paper, we propose an approach to detect high-level model changes in terms of refactorings. Our approach takes as input an exhaustive list of possible refactorings, the initial model and revised model, and generates as output a list of detected changes representing a sequence of refactorings. A solution is defined as a combination of refactorings that should maximize as much as possible the similarity between the expected revised model and the generated model after applying the refactoring sequence on the initial model. Due to the huge number of possible refactoring combinations, a heuristic method is used to explore the space of possible solutions. To this end, we used and adapted genetic algorithm as global heuristic search. The validation results on various versions of real-world models taken from an open source project confirm the effectiveness of our approach.",1063-6773;10636773,Electronic:978-1-4673-2312-3; POD:978-1-4673-2313-0,10.1109/ICSM.2012.6405274,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6405274,model evolution;refactoring detection;search-based model-driven software engineering,Adaptation models;Analytical models;Computational modeling;Genetic algorithms;Sociology;Space exploration;Statistics,genetic algorithms;public domain software;search problems;software maintenance,adapted genetic algorithm;global heuristic search-based detection;high-level software model change analysis;high-level software model change detection;open source project confirm;software evolution activities;software maintenance activities;software refactoring,,6,,32,,,,23-28 Sept. 2012,,IEEE,IEEE Conferences,,9
Fine-grained change impact analysis for component-based product families,A. R. Yazdanshenas; L. Moonen,"Simula Res. Lab., Lysaker, Norway",2012 28th IEEE International Conference on Software Maintenance (ICSM),20130110,2012,,,119,128,"Developing software product-lines based on a set of shared components is a proven tactic to enhance reuse, quality, and time to market in producing a portfolio of products. Large-scale product families face rapidly increasing maintenance challenges as their evolution can happen both as a result of collective domain engineering activities, and as a result of product-specific developments. To make informed decisions about prospective modifications, developers need to estimate what other sections of the system will be affected and need attention, which is known as change impact analysis. This paper contributes a method to carry out change impact analysis in a component-based product family, based on system-wide information flow analysis. We use static program slicing as the underlying analysis technique, and use model-driven engineering (MDE) techniques to propagate the ripple effects from a source code modification into all members of the product family. In addition, our approach ranks results based on an approximation of the scale of their impact. We have implemented our approach in a prototype tool, called Richter, which was evaluated on a real-world product family.",1063-6773;10636773,Electronic:978-1-4673-2312-3; POD:978-1-4673-2313-0,10.1109/ICSM.2012.6405262,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6405262,change impact analysis;component-based software development;information flow;software product-lines,Actuators;Conferences;Safety;Sensors;Software maintenance,program slicing;software maintenance;software quality;software reliability;time to market,MDE techniques;Richter;domain engineering activities;fine-grained change impact analysis;information flow analysis;large-scale component-based product families;model-driven engineering techniques;product-specific developments;ripple effects;software maintenance;software product portfolio production;software product-line development;software quality enhancement;software reuse enhancement;software time-to-market enhancement;source code modification;static program slicing,,2,,29,,,,23-28 Sept. 2012,,IEEE,IEEE Conferences,,9
An empirical investigation into the impact of refactoring on regression testing,N. Rachatasumrit; M. Kim,"Univ. of Texas at Austin, Austin, TX, USA",2012 28th IEEE International Conference on Software Maintenance (ICSM),20130110,2012,,,357,366,"It is widely believed that refactoring improves software quality and developer's productivity by making it easier to maintain and understand software systems. On the other hand, some believe that refactoring has the risk of functionality regression and increased testing cost. This paper investigates the impact of refactoring edits on regression tests using the version history of Java open source projects: (1) Are there adequate regression tests for refactoring in practice? (2) How many of existing regression tests are relevant to refactoring edits and thus need to be re-run for the new version? (3) What proportion of failure-inducing changes are relevant to refactorings? By using a refactoring reconstruction analysis and a change impact analysis in tandem, we investigate the relationship between the types and locations of refactoring edits identified by RefFinder and the affecting changes and affected tests identified by the FaultTracer change impact analysis. The results on three open source projects, JMeter, XMLSecurity, and ANT, show that only 22% of refactored methods and fields are tested by existing regression tests. While refactorings only constitutes 8% of atomic changes, 38% of affected tests are relevant to refactorings. Furthermore, refactorings are involved in almost half of the failed test cases. These results call for new automated regression test augmentation and selection techniques for validating refactoring edits.",1063-6773;10636773,Electronic:978-1-4673-2312-3; POD:978-1-4673-2313-0,10.1109/ICSM.2012.6405293,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6405293,empirical study;refactoring;regression testing;software evolution,Conferences;Engines;History;Measurement;Software maintenance;Testing,Java;configuration management;program testing;program verification;public domain software;software maintenance;software quality;system recovery,ANT;FaultTracer;JMeter;Java open source project;RefFinder;XMLSecurity;atomic change;change impact analysis;developer productivity improvement;failure-inducing change;functionality regression;refactoring edit validation;refactoring reconstruction analysis;regression testing;software quality improvement;software system maintenance;software system understanding;testing cost;version history,,11,,36,,,,23-28 Sept. 2012,,IEEE,IEEE Conferences,,9
Architecture Compliance Checking of Semantically Rich Modular Architectures: A Comparative Study of Tool Support,L. Pruijt; C. Kê_ppe; S. Brinkkemper,"Inf. Syst. Archit. Res. Group, HU Univ. of Appl. Sci., Utrecht, Netherlands",2013 IEEE International Conference on Software Maintenance,20131202,2013,,,220,229,"Architecture Compliance Checking (ACC) is an approach to verify the conformance of implemented program code to high-level models of architectural design. ACC is used to prevent architectural erosion during the development and evolution of a software system. Static ACC, based on static software analysis techniques, focuses on the modular architecture and especially on rules constraining the modular elements. A semantically rich modular architecture (SRMA) is expressive and may contain modules with different semantics, like layers and subsystems, constrained by rules of different types. To check the conformance to an SRMA, ACC-tools should support the module and rule types used by the architect. This paper presents requirements regarding SRMA support and an inventory of common module and rule types, on which basis eight commercial and non-commercial tools were tested. The test results show large differences between the tools, but all could improve their support of SRMA, what might contribute to the adoption of ACC in practice.",1063-6773;10636773,Electronic:978-0-7695-4981-1; POD:978-1-4673-5218-5,10.1109/ICSM.2013.33,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6676893,Architectural Erosion;Architecture Compliance;Architecture Conformance;Modular Architecture;Software Architecture;Static Analysis,Computer architecture;Java;Semantics;Software architecture;Software systems;Unified modeling language,program diagnostics;software architecture,ACC;SRMA;architectural erosion;architecture compliance checking;program code;semantically rich modular architectures;static software analysis;tool support,,9,,24,,,,22-28 Sept. 2013,,IEEE,IEEE Conferences,,9
The Evolution of Project Inter-dependencies in a Software Ecosystem: The Case of Apache,G. Bavota; G. Canfora; M. D. Penta; R. Oliveto; S. Panichella,"Univ. of Sannio, Benevento, Italy",2013 IEEE International Conference on Software Maintenance,20131202,2013,,,280,289,"Software ecosystems consist of multiple software projects, often interrelated each other by means of dependency relations. When one project undergoes changes, other projects may decide to upgrade the dependency. For example, a project could use a new version of another project because the latter has been enhanced or subject to some bug-fixing activities. This paper reports an exploratory study aimed at observing the evolution of the Java subset of the Apache ecosystem, consisting of 147 projects, for a period of 14 years, and resulting in 1,964 releases. Specifically, we analyze (i) how dependencies change over time, (ii) whether a dependency upgrade is due to different kinds of factors, such as different kinds of API changes or licensing issues, and (iii) how an upgrade impacts on a related project. Results of this study help to comprehend the phenomenon of library/component upgrade, and provides the basis for a new family of recommenders aimed at supporting developers in the complex (and risky) activity of managing library/component upgrade within their software projects.",1063-6773;10636773,Electronic:978-0-7695-4981-1; POD:978-1-4673-5218-5,10.1109/ICSM.2013.39,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6676899,,Data mining;Ecosystems;History;Java;Libraries;Licenses;Software,Java;software engineering;software management,API;Apache ecosystem;Java subset;multiple software projects;project inter-dependencies;software ecosystem,,18,,26,,,,22-28 Sept. 2013,,IEEE,IEEE Conferences,,9
LHDiff: A Language-Independent Hybrid Approach for Tracking Source Code Lines,M. Asaduzzaman; C. K. Roy; K. A. Schneider; M. D. Penta,"Dept. of Comput. Sci., Univ. of Saskatchewan, Saskatoon, SK, Canada",2013 IEEE International Conference on Software Maintenance,20131202,2013,,,230,239,"Tracking source code lines between two different versions of a file is a fundamental step for solving a number of important problems in software maintenance such as locating bug introducing changes, tracking code fragments or defects across versions, merging file versions, and software evolution analysis. Although a number of such approaches are available in the literature, their performance is sensitive to the kind and degree of source code changes. There is also a marked lack of study on the effect of change types on source location tracking techniques. In this paper, we propose a language-independent technique, LHDiff, for tracking source code lines across versions that leverages simhash technique together with heuristics to improve accuracy. We evaluate our approach against state-of-the- art techniques using benchmarks containing different degrees of changes where files are selected from real world applications. We further evaluate LHDiff with other techniques using a mutation based analysis to understand how different types of changes affect their performance. The results reveal that our technique is more effective than language-independent approaches and no worse than some language-dependent techniques. In our study LHDiff even shows better performance than a state-of-the-art language- dependent approach. In addition, we also discuss limitations of different line tracking techniques including ours and propose future research directions.",1063-6773;10636773,Electronic:978-0-7695-4981-1; POD:978-1-4673-5218-5,10.1109/ICSM.2013.34,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6676894,diff;levenshtein;lightweight;line tracking,Accuracy;Benchmark testing;Cloning;Context;Position measurement;Software;Syntactics,merging;software maintenance;source coding,LHDiff;file merging;language-independent hybrid approach;software evolution analysis;software maintenance;source code lines tracking,,6,,32,,,,22-28 Sept. 2013,,IEEE,IEEE Conferences,,9
Stakeholders' Information Needs for Artifacts and Their Dependencies in a Real World Context,S. C. Mê_ller; T. Fritz,"Dept. of Inf., Univ. of Zurich, Zurich, Switzerland",2013 IEEE International Conference on Software Maintenance,20131202,2013,,,290,299,"In the evolution of software, stakeholders continuously seek and consult various information artifacts and their interdependencies to successfully complete their daily activities. While a lot of research has focused on supporting stakeholders in satisfying various information needs, there is little empirical evidence on how these information needs manifest themselves in the context of professional software development teams of real world companies. To investigate the information needs of the different stakeholder roles involved in software evolution activities, we conducted an empirical study with 23 participants from two professional development teams of one company. The analysis of the gathered data shows that information needs exhibit a crosscutting nature with respect to stakeholder role, activity, artifacts and even fragments of artifacts. We also found that the dependencies between information artifacts are important for the successful performance of software evolution activities, but often not captured explicitly. The lack of an explicit representation of these interdependencies often result in difficulties identifying dependent artifacts and additional communication effort. Based on our findings, we suggest ways to better support stakeholders with their information needs.",1063-6773;10636773,Electronic:978-0-7695-4981-1; POD:978-1-4673-5218-5,10.1109/ICSM.2013.40,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6676900,activity;artifact;crosscutting nature;fragment;information needs;missing link;stakeholder role,Companies;Context;Encoding;Informatics;Interviews;Project management;Software,software engineering,data analysis;information artifacts;information needs;professional software development teams;software evolution activity;stakeholder information,,6,,35,,,,22-28 Sept. 2013,,IEEE,IEEE Conferences,,9
An Empirical Study of API Stability and Adoption in the Android Ecosystem,T. McDonnell; B. Ray; M. Kim,"Dept. of Electr. & Comput. Eng., Univ. of Texas at Austin, Austin, TX, USA",2013 IEEE International Conference on Software Maintenance,20131202,2013,,,70,79,"When APIs evolve, clients make corresponding changes to their applications to utilize new or updated APIs. Despite the benefits of new or updated APIs, developers are often slow to adopt the new APIs. As a first step toward understanding the impact of API evolution on software ecosystems, we conduct an in-depth case study of the co-evolution behavior of Android API and dependent applications using the version history data found in github. Our study confirms that Android is evolving fast at a rate of 115 API updates per month on average. Client adoption, however, is not catching up with the pace of API evolution. About 28% of API references in client applications are outdated with a median lagging time of 16 months. 22% of outdated API usages eventually upgrade to use newer API versions, but the propagation time is about 14 months, much slower than the average API release interval (3 months). Fast evolving APIs are used more by clients than slow evolving APIs but the average time taken to adopt new versions is longer for fast evolving APIs. Further, API usage adaptation code is more defect prone than the one without API usage adaptation. This may indicate that developers avoid API instability.",1063-6773;10636773,Electronic:978-0-7695-4981-1; POD:978-1-4673-5218-5,10.1109/ICSM.2013.18,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6676878,,Androids;Google;History;Humanoid robots;Mobile communication;Smart phones;Software,application program interfaces;mobile computing;operating systems (computers);software maintenance,API evolution;API stability;API usage adaptation code;Android API coevolution behavior;Android ecosystem;github;software ecosystems;version history data,,49,,30,,,,22-28 Sept. 2013,,IEEE,IEEE Conferences,,9
Investigating the Impact of Code Smells on System's Quality: An Empirical Study on Systems of Different Application Domains,F. A. Fontana; V. Ferme; A. Marino; B. Walter; P. Martenka,"Dept. of Comp. Sci., Univ. of Milano Bicocca, Milan, Italy",2013 IEEE International Conference on Software Maintenance,20131202,2013,,,260,269,"There are various activities that support software maintenance. Program comprehension and detection of design anomalies and their symptoms, like code smells and anti patterns, are particularly relevant for improving the quality and facilitating evolution of a system. In this paper we describe an empirical study on the detection of code smells, aiming at identifying the most frequent smells in systems of different domains and hence the domains characterized by more smells. Moreover, we study possible correlations existing among smells and the values of a set of software quality metrics using Spearman's rank correlation and Principal Component Analysis.",1063-6773;10636773,Electronic:978-0-7695-4981-1; POD:978-1-4673-5218-5,10.1109/ICSM.2013.37,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6676897,code smell detection;domain-dependent analysis;metric and smell correlations;software evolution;software maintenance,Correlation;Detectors;Educational institutions;Generators;Java;Measurement;Software,Java;object-oriented programming;program diagnostics;software maintenance;software quality,Spearman rank correlation;code smell detection;object-oriented Java systems;principal component analysis;program comprehension;program detection;software maintenance;software quality metrics;software system quality,,7,,34,,,,22-28 Sept. 2013,,IEEE,IEEE Conferences,,9
How Multiple Developers Affect the Evolution of Code Clones,J. Harder,"Software Eng. Group, Univ. of Bremen, Bremen, Germany",2013 IEEE International Conference on Software Maintenance,20131202,2013,,,30,39,"The use of copy and paste in programming causes redundant passages of source code. The effect such clones have on software quality and maintainability in particular has been subject to various studies in the recent past. Although negative effects could not be confirmed in general, a non-negligible number of situations where clones did cause problems has been found. Hence, there may be yet unknown influencing factors that cause these problems. One such factor may be the number of developers involved in the creation and maintenance of a clone. The interaction of multiple developers, unevenly distributed knowledge and communication deficiencies may lead to unwanted inconsistencies and bugs, when the clones are changed. This paper presents an empirical study on long-lived software systems, in which we analyze how many developers are involved in the maintenance exact clones and whether the number of developers affects the likelihood of inconsistent changes. Our results indicate that differences between single-author and multi-author clones exist. Nevertheless, we did not find multiple developers to be the cause of problematic changes to clones.",1063-6773;10636773,Electronic:978-0-7695-4981-1; POD:978-1-4673-5218-5,10.1109/ICSM.2013.14,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6676874,code authorship;code clones;software evolution;software quality,Cloning;Computer bugs;History;Maintenance engineering;Measurement;Programming;Software systems,human factors;software maintenance;software quality,clone maintenance;long-lived software systems;multiauthor clones;multiple developers;single-author clones;software quality,,1,,26,,,,22-28 Sept. 2013,,IEEE,IEEE Conferences,,9
Mining Logical Clones in Software: Revealing High-Level Business and Programming Rules,W. Qian; X. Peng; Z. Xing; S. Jarzabek; W. Zhao,"Software Sch., Fudan Univ., Shanghai, China",2013 IEEE International Conference on Software Maintenance,20131202,2013,,,40,49,"Software systems contain many implicit application-specific business and programming rules. These rules represent high-level logical structures and processes for application-specific business and programming concerns. They are crucial for program understanding, consistent evolution, and systematic reuse. However, existing pattern mining and analysis approaches cannot effectively mine such application-specific rules. In this paper, we present an approach for mining logical clones in software that reveal high-level business and programming rules. Our approach extracts a program model from source code, and enriches the program model with code clone information, functional clusters (i.e., a set of methods dealing with similar topics or concerns), and abstract entity classes (representing sibling entity classes). It then analyzes the enriched program model for mining recurring logical structures as logical clones. We have implemented our approach in a tool called MiLoCo (Mining Logical Clone) and conducted a case study with an open-source ERP and CRM software. Our results show that MiLoCo can identify meaningful and useful logical clones for program understanding, evolution and reuse.",1063-6773;10636773,Electronic:978-0-7695-4981-1; POD:978-1-4673-5218-5,10.1109/ICSM.2013.15,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6676875,evolution;logical clone;program comprehension;reuse;semantic clustering,Abstracts;Business;Cloning;Clustering algorithms;Data mining;Programming;Semantics,commerce;customer relationship management;data mining;enterprise resource planning;public domain software;software reusability,CRM software;MiLoCo;application-specific business;high-level business;logical clones mining;open-source ERP software;pattern mining;program reuse;programming rules;software systems,,3,,23,,,,22-28 Sept. 2013,,IEEE,IEEE Conferences,,9
An Empirical Study of Clone Removals,S. Bazrafshan; R. Koschke,"Software Eng. Group, Univ. of Bremen, Bremen, Germany",2013 IEEE International Conference on Software Maintenance,20131202,2013,,,50,59,"It is often claimed that duplicated source code is a threat to the maintainability of a software system and that developers should manage code duplication. A previous study analyzed the evolution of four software systems and found a remarkable discrepancy between code clones detected by a state-of-the-art clone detector and those deliberately removed by developers as the scope of the clones hardly ever matched. However, the results are based on a relatively small amount of data and need to be validated by a more extensive analysis. In this paper, we present an extension of this study by analyzing deliberate as well as accidental removals of code duplication in the evolution of eleven systems. Based on our findings, we could confirm the results of the previous study. Beyond that we found that accidental removals of cloned code occur slightly more often than deliberate removals and that many clone removals were in fact incomplete.",1063-6773;10636773,Electronic:978-0-7695-4981-1; POD:978-1-4673-5218-5,10.1109/ICSM.2013.16,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6676876,Clone removal;clone evolution;software maintenance,Cloning;Cyclones;Detectors;Measurement;Open source software;Software systems,software maintenance;software management,clone removals;code clone detection;duplicated source code;software system maintainability,,4,,35,,,,22-28 Sept. 2013,,IEEE,IEEE Conferences,,9
Determining Developers' Expertise and Role: A Graph Hierarchy-Based Approach,P. Bhattacharya; I. Neamtiu; M. Faloutsos,"Dept. of Comput. Sci. & Eng., Univ. of California, Riverside, Riverside, CA, USA",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,11,20,"Determining contributors' expertise, role, and individual importance are fundamental for assessing their impact on a software project. Currently-used expertise metrics are agnostic to contributor roles and can lead to incorrect characterizations. To address these issues, we operationalize contributor expertise and role. First, we revisit current expertise metrics and show that their use bundles many different aspects, creating ambiguity. Second, we introduce clearly-defined contributor roles, which capture multiple project facets. Third, we propose a graph model, based on contributor collaborations, that captures the hierarchical structure of the contributor community in a concise yet informative way. We demonstrate the model's usefulness in two ways: (a) for identifying the structure and evolution of contributor interactions, (b) for predicting contributor roles. We substantiate our study using two large open-source projects, Fire fox and Eclipse. Our systematic approach clarifies and isolates contributor role and expertise, and sheds light onto the dynamics of contributors within software projects.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.23,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976067,Developer expertise;Empirical studies;Software network analysis,Collaboration;Computer bugs;Control systems;Correlation;Data collection;Measurement;Software,graph theory;public domain software;software development management;software metrics,Eclipse;Firefox;clearly-defined contributor roles;contributor collaborations;contributor community;developer expertise;expertise metrics;graph hierarchy-based approach;multiple project facets;open-source projects;software projects,,3,,50,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
An Empirical Study of the Effects of Expert Knowledge on Bug Reports,D. Huo; T. Ding; C. McMillan; M. Gethers,"Dept. of Comput. Sci. & Eng., Univ. of Notre Dame, Notre Dame, IN, USA",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,1,10,"Bug reports are crucial software artifacts for both software maintenance researchers and practitioners. A typical use of bug reports by researchers is to evaluate automated software maintenance tools: a large repository of reports is used as input for a tool, and metrics are calculated from the tool's output. But this process is quite different from practitioners, who distinguish between reports written by experts such as programmers, and reports written by non-experts such as users. Practitioners recognize that the content of a bug report depends on its author's expert knowledge. In this paper, we present an empirical study of the textual difference between bug reports written by experts and non-experts. We find that a significance difference exists, and that this difference has a significant impact on the results from a state-of-the-art feature location tool. Our recommendation is that researchers evaluate maintenance tools using different sets of bug reports for experts and non-experts.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.22,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976066,bug reports;empirical study;expert knowledge,Computer bugs;Information retrieval;Maintenance engineering;Measurement;Semantics;Software maintenance,program debugging;software maintenance;software metrics,automated software maintenance tool evaluation;bug report content;empirical analysis;expert knowledge;feature location tool;large-report repository;software artifacts;software maintenance practitioners;software maintenance researchers;software metrics;textual difference,,3,,85,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
Writing Acceptable Patches: An Empirical Study of Open Source Project Patches,Y. Tao; D. Han; S. Kim,,2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,271,280,"Software developers submit patches to handle tens or even hundreds of bugs reported daily. However, not all submitted patches can be directly integrated into the code base, since they might not pass patch review that is adopted in most software projects. As the result of patch review, incoming patches can be rejected or asked for resubmission after improvement. Both scenarios interrupt the workflow of patch writers and reviewers, increase their workload, and potentially delay the general development process. In this paper, we aim to help developers write acceptable patches to avoid patch rejection and resubmission. To this end, we derive a comprehensive list of patch rejection reasons from a manual inspection of 300 rejected Eclipse and Mozilla patches, a large-scale online survey of Eclipse and Mozilla developers, and the literature. We also investigate which patch-rejection reasons are more decisive and which are difficult to judge from the perspective of patch reviewers. Our findings include 1) suboptimal solution and incomplete fix are the most frequent patch-rejection reasons 2) whether a patch introduces new bugs is very important yet very difficult to judge 3) reviewers reject a large patch not solely because of its size, but mainly because of the underlying reasons that induce its large size, such as the involvement of unnecessary changes 4) reviewers consider certain problems to be much more destructive than patch writers expect, such as the inconsistency of documentation in a patch and 5) bad timing of patch submission and a lack of communication with team members can also result in a negative patch review.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.49,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976093,empirical study;patch,Computer bugs;Documentation;Encoding;Guidelines;Inspection;Manuals,program debugging;program diagnostics;software development management,Eclipse developers;Eclipse patches;Mozilla developers;Mozilla patches;acceptable patch writing;codebase;open source project patches;patch rejection;patch resubmission;patch reviewers;software bugs;software developers;software development process;software projects,,6,,38,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
An Empirical Study of the Energy Consumption of Android Applications,D. Li; S. Hao; J. Gui; W. G. J. Halfond,"Dept. of Comput. Sci., Univ. of Southern California, Los Angeles, CA, USA",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,121,130,"Energy is a critical resource for smartphones. However, developers who create apps for these platforms lack quantitative and objective information about the behavior of apps with respect to energy consumption. In this paper, we describe the results of our source-line level energy consumption study of 405 real-world market applications. Based on our study, we discover several interesting observations. For example, we find on average apps spend 61% of their energy in idle states, network is the most energy consuming component, and only a few APIs dominate non-idle energy consumption. The results of this study provide developers with objective information about how energy is consumed by a broad sample of mobile applications and can guide them in their efforts of improving the energy efficiency of their applications.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.34,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976078,Empirical study;Energy;Mobile applications,Androids;Energy consumption;Energy measurement;Humanoid robots;Optimization;Sensors;Smart phones,Android (operating system);application program interfaces;energy conservation;power aware computing;smart phones,API;android applications;energy consumption;energy efficiency;mobile applications;nonidle energy consumption;real-world market applications;smartphones;source-line level energy consumption,,34,,30,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
A Slice-Based Estimation Approach for Maintenance Effort,H. W. Alomari; M. L. Collard; J. I. Maletic,"Fac. of Inf. Technol., Jerash Univ., Jerash, Jordan",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,81,90,"Program slicing is used as a basis for an approach to estimate maintenance effort. A case study of the GNU Linux kernel with over 900 versions spanning 17 years of history is presented. For each version a system dictionary is built using a lightweight slicing approach and encodes the forward decomposition static slice profiles for all variables in all the files in the system. Changes to the system are then modeled at the behavioral level using the difference between the system dictionaries of two versions. The three different granularities of slice (i.e., line, function, and file) are analyzed. We use a direct extension of srcML to represent computed change information. The retrieved information reflects the fact that additional knowledge of the differences can be automatically derived to help maintainers understand code changes. We consider the hypotheses: (1) The structured format helps create traceability links between the changes and other software artifacts. (2) This model is predictive of maintenance effort. The results demonstrate that the approach accurately predicts effort in a scalable manner.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.30,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976074,effort estimation;program slicing;software maintenance;software metrics,Dictionaries;Encoding;Estimation;Linux;Maintenance engineering;Open source software,Linux;information retrieval;operating system kernels;program slicing;software maintenance,GNU Linux kernel;computed change information;forward decomposition static slice profiles;information retrieval;lightweight slicing approach;maintenance effort estimation;slice granularities;software artifacts;srcML;structured format;system dictionaries;traceability links,,1,,45,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
How Does Exception Handling Behavior Evolve? An Exploratory Study in Java and C# Applications,N. Cacho; E. A. Barbosa; J. Araujo; F. Pranto; A. Garcia; T. Cesar; E. Soares; A. Cassio; T. Filipe; I. Garcia,"Dept. of Inf. & Appl. Math., Fed. Univ. of Rio Grande do Norte, Natal, Brazil",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,31,40,"Exception handling mechanisms (EHM) were conceived as a means to improve maintainability and reliability of programs that have to deal with exceptional situations. Amongst the different implementations of built-in EHM, we classify them in two main categories: reliability-driven and maintenance-driven. Some programming languages, such as Java, provide built-in exception handling mechanisms that promote reliability-driven EHMs. Maintenance-driven EHMs, on the other hand, promote software maintainability by not forcing developers to specify exception handling constraints. Most of modern languages, such as C#, Ruby, Python and many others support this approach. Developers usually have to choose between maintainability-driven and reliability-driven approaches to structure exception handling in their applications. However, there is still little empirical knowledge about the impact that adopting these mechanisms have on software robustness and maintenance. This paper addressed this gap by conducting an empirical study aimed at understanding the relationship between changes in Java and C# programs and their robustness. In particular, we evaluated how changes in the normal and exceptional code were related to exception handling faults. We applied a change impact analysis and a control flow analysis in 116 versions of 16 C# programs and 112 versions of 16 Java programs.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.25,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976069,Exception Handling;change impact analysis;maintenance;reliability,Java;Measurement;Robustness;Servers;Software;Software reliability,C language;Java;exception handling;software maintenance;software reliability,C# programs;Java programs;built-in EHM implementations;change impact analysis;control flow analysis;empirical analysis;exception handling behavior;exception handling constraints;exception handling faults;exceptional code;maintenance-driven EHM;normal code;program maintainability improvement;program reliability improvement;programming languages;reliability-driven EHM;software maintainability;software robustness,,4,,29,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
Prevalence and Maintenance of Automated Functional Tests for Web Applications,L. Christophe; R. Stevens; C. D. Roover; W. D. Meuter,"Software Languages Lab., Vrije Univ. Brussel, Brussels, Belgium",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,141,150,"Functional testing requires executing particular sequences of user actions. Test automation tools enable scripting user actions such that they can be repeated more easily. SELENIUM, for instance, enables testing Web applications through scripts that interact with a Web browser and assert properties about its observable state. However, little is known about how common such tests are in practice. We therefore present a cross-sectional quantitative study of the prevalence of SELENIUM-based tests among open-source Web applications, and of the extent to which such tests are used within individual applications. Automating functional tests also brings about the problem of maintaining test scripts. As the system under test evolves, its test scripts are bound to break. Even less is known about the way test scripts change over time. We therefore also present a longitudinal quantitative study of whether and for how long test scripts are maintained, as well as a longitudinal qualitative study of the kind of changes they undergo. To the former's end, we propose two new metrics based on whether a commit to the application's version repository touches a test file. To the latter's end, we propose to categorize the changes within each commit based on the elements of the test upon which they operate. As such, we are able to identify the elements of a test that are most prone to change.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.36,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976080,Functional testing;Selenium;Test automation,Browsers;Graphical user interfaces;Java;Maintenance engineering;Measurement;Testing,program testing;public domain software;software maintenance,SELENIUM-based tests;Web application testing;Web browser;application version repository;automated functional test maintenance;automated functional test prevalence;cross-sectional quantitative study;longitudinal quantitative study;observable state;open-source Web applications;property assertion;software metrics;test automation tools;test files;test script maintenance;user action scripting;user action sequences,,6,,24,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
Enhancing Clone-and-Own with Systematic Reuse for Developing Software Variants,S. Fischer; L. Linsbauer; R. E. Lopez-Herrejon; A. Egyed,"Johannes Kepler Univ., Linz, Austria",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,391,400,"To keep pace with the increasing demand for custom-tailored software systems, companies often apply a practice called clone-and-own, whereby a new variant of a software system is built by coping and adapting existing variants. Instead of a single and configurable system, clone-and-own leads to ad hoc product portfolios of multiple yet similar variants that soon become impossible to maintain effectively. Clone-and-own has widespread industrial use because it requires no major upfront investments and is intuitive, but it lacks a methodology for systematic reuse. In this work we propose ECCO (Extraction and Composition for Clone-and-Own), a novel approach to enhance clone and-own that actively supports the development and maintenance of software product variants. A software engineer selects the desired features and ECCO finds the proper software artifacts to reuse and then provides guidance during the manual completion by hinting which software artifacts may need adaptation. We evaluated our approach on 6 case studies, covering 402 variants having up to 344KLOC, and found that precision and recall of composed products quickly reach a near optimum (>95% reuse).",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.61,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976105,clone-and-own;feature interactions;features;product variants;reuse,Color;Feature extraction;Java;Manuals;Portfolios;Software;Solids,investment;software maintenance;software reusability,ECCO approach;ad hoc product portfolios;clone-and-own enhancement;custom-tailored software systems;extraction and composition for clone-and-own approach;software artifacts;software product variant maintenance;software variant development;systematic reuse,,13,,16,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
Scaling Testing of Refactoring Engines,M. Mongiovi; G. Mendes; R. Gheyi; G. Soares; M. Ribeiro,"Fed. Univ. of Campina Grande, Campina Grande, Brazil",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,371,380,"Proving refactoring sound with respect to a formal semantics is considered a challenge. In practice, developers write test cases to check their refactoring implementations. However, it is difficult and time consuming to have a good test suite since it requires complex inputs (programs) and an oracle to check whether it is possible to apply the transformation. If it is possible, the resulting program must preserve the observable behavior. There are some automated techniques for testing refactoring engines. Nevertheless, they may have limitations related to the program generator (exhaustiveness, setup, expressiveness), automation (types of oracles, bug categorization), time consumption or kinds of refactorings that can be tested. In this paper, we extend our previous technique to test refactoring engines. We improve expressiveness of the program generator for testing more kinds of refactorings, such as Extract Function. Moreover, developers just need to specify the input's structure in a declarative language. They may also set the technique to skip some consecutive test inputs to improve performance. We evaluate our technique in 18 refactoring implementations of Java (Eclipse and JRRT) and C (Eclipse). We identify 76 bugs (53 new bugs) related to compilation errors, behavioral changes, and overly strong conditions. We also compare the impact of the skip on the time consumption and bug detection in our technique. By using a skip of 25 in the program generator, it reduces in 96% the time to test the refactoring implementations while missing only 3.9% of the bugs. In a few seconds, it finds the first failure related to compilation error or behavioral change.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.59,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976103,Refactoring;automated testing;program generation,Automatic programming;Automation;Computer bugs;Engines;Java;Metals;Testing,C language;Java;automatic programming;program compilers;program debugging;program testing;software maintenance,C language;Eclipse;JRRT;Java language;automated techniques;behavioral changes;bug categorization;compilation errors;complex inputs;consecutive test inputs;declarative language;extract function;formal semantics;input structure;oracle types;performance improvement;program automation;program exhaustiveness;program generator expressiveness improvement;program setup;refactoring engine testing;refactoring implementations;refactoring types;scaling testing;test suite;test time reduction;time consumption,,0,,25,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
On Analyzing the Topology of Commit Histories in Decentralized Version Control Systems,M. Biazzini; M. Monperrus; B. Baudry,,2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,261,270,"Empirical analysis of software repositories usually deals with linear histories derived from centralized versioning systems. Decentralized version control systems allow a much richer structure of commit histories, which presents features that are typical of complex graph models. In this paper we bring some evidences of how the very structure of these commit histories carries relevant information about the distributed development process. By means of a novel data structure that we formally define, we analyze the topological characteristics of commit graphs of a sample of GIT projects. Our findings point out the existence of common recurrent structural patterns which identically occur in different projects and can be consider building blocks of distributed collaborative development.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.48,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976092,Decentralized Version Control Systems;Git;Graph Topology;Sofware Repository Mining,Collaboration;Control systems;Data structures;History;Measurement;Software;Topology,data structures;distributed processing;graph theory;program diagnostics;software engineering,centralized versioning systems;commit graph topological characteristics;commit history topology;complex graph models;data structure;decentralized version control systems;distributed collaborative development;distributed development process;linear histories;recurrent structural patterns;software repository empirical analysis,,5,,16,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
Refactoring Fat Interfaces Using a Genetic Algorithm,D. Romano; S. Raemaekers; M. Pinzger,"Software Eng. Res. Group, Delft Univ. of Technol., Delft, Netherlands",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,351,360,"Recent studies have shown that the violation of the Interface Segregation Principle (ISP) is critical for maintaining and evolving software systems. Fat interfaces (i.e., interfaces violating the ISP) change more frequently and degrade the quality of the components coupled to them. According to the ISP the interfaces' design should force no client to depend on methods it does not invoke. Fat interfaces should be split into smaller interfaces exposing only the methods invoked by groups of clients. However, applying the ISP is a challenging task when fat interfaces are invoked differently by many clients. In this paper, we formulate the problem of applying the ISP as a multi-objective clustering problem and we propose a genetic algorithm to solve it. We evaluate the capability of the proposed genetic algorithm with 42,318 public Java APIs whose clients' usage has been mined from the Maven repository. The results of this study show that the genetic algorithm outperforms other search based approaches (i.e., random and simulated annealing approaches) in splitting the APIs according to the ISP.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.57,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976101,APIs;Interface Segregation Principle;genetic algorithms;refactoring;search-based software engineering,Biological cells;Genetic algorithms;Measurement;Simulated annealing;Sociology;Statistics,Java;application program interfaces;genetic algorithms;pattern clustering;random processes;simulated annealing;software engineering,ISP;Maven repository;fat interfaces;genetic algorithm;interface segregation principle;multiobjective clustering problem;public Java API;random annealing;simulated annealing;software system,,1,,33,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
Mining Co-change Information to Understand When Build Changes Are Necessary,S. Mcintosh; B. Adams; M. Nagappan; A. E. Hassan,"Sch. of Comput., Queen's Univ., Kingston, ON, Canada",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,241,250,"As a software project ages, its source code is modified to add new features, restructure existing ones, and fix defects. These source code changes often induce changes in the build system, i.e., the system that specifies how source code is translated into deliverables. However, since developers are often not familiar with the complex and occasionally archaic technologies used to specify build systems, they may not be able to identify when their source code changes require accompanying build system changes. This can cause build breakages that slow development progress and impact other developers, testers, or even users. In this paper, we mine the source and test code changes that required accompanying build changes in order to better understand this co-change relationship. We build random forest classifiers using language-agnostic and language-specific code change characteristics to explain when code-accompanying build changes are necessary based on historical trends. Case studies of the Mozilla C++ system, the Lucene and Eclipse open source Java systems, and the IBM Jazz proprietary Java system indicate that our classifiers can accurately explain when build co-changes are necessary with an AUC of 0.60-0.88. Unsurprisingly, our highly accurate C++ classifiers (AUC of 0.88) derive much of their explanatory power from indicators of structural change (e.g., was a new source file added?). On the other hand, our Java classifiers are less accurate (AUC of 0.60-0.78) because roughly 75% of Java build co-changes do not coincide with changes to the structure of a system, but rather are instigated by concerns related to release engineering, quality assurance, and general build maintenance.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.46,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976090,Build systems;mining software repositories;software evolution,Data mining;Java;Libraries;Maintenance engineering;Software;Testing;Training,C++ language;Java;data mining;program compilers;source code (software),C++ classifiers;Eclipse open source Java systems;IBM Jazz proprietary;Java classifiers;Lucene open source Java systems;Mozilla C++ system;archaic technologies;language agnostic code;language specific code;mining cochange information;random forest classifiers;software project;source code,,9,,28,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
Smelling Faults in Spreadsheets,R. Abreu; J. Cunha; J. P. Fernandes; P. Martins; A. Perez; J. Saraiva,"HASLab, Univ. do Porto, Porto, Portugal",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,111,120,"Despite being staggeringly error prone, spreadsheets are a highly flexible programming environment that is widely used in industry. In fact, spreadsheets are widely adopted for decision making, and decisions taken upon wrong (spreadsheet-based) assumptions may have serious economical impacts on businesses, among other consequences. This paper proposes a technique to automatically pinpoint potential faults in spreadsheets. It combines a catalog of spreadsheet smells that provide a first indication of a potential fault, with a generic spectrum-based fault localization strategy in order to improve (in terms of accuracy and false positive rate) on these initial results. Our technique has been implemented in a tool which helps users detecting faults. To validate the proposed technique, we consider a well-known and well-documented catalog of faulty spreadsheets. Our experiments yield two main results: we were able to distinguish between smells that can point to faulty cells from smells and those that are not capable of doing so, and we provide a technique capable of detecting a significant number of errors: two thirds of the cells labeled as faulty are in fact (documented) errors.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.33,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976077,,Catalogs;Companies;Electronic mail;Fault detection;Google;Software;Vectors,decision making;fault diagnosis;software fault tolerance;spreadsheet programs,decision making;fault detection;faulty spreadsheet catalog;flexible programming environment;generic spectrum-based fault localization strategy;pinpoint potential faults,,14,,38,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
"CSCC: Simple, Efficient, Context Sensitive Code Completion",M. Asaduzzaman; C. K. Roy; K. A. Schneider; D. Hou,"Dept. of Comput. Sci., Univ. of Saskatchewan, Saskatoon, SK, Canada",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,71,80,"Code Completion helps developers learn APIs and frees them from remembering every detail. In this paper, we describe a novel technique called CSCC (Context Sensitive Code Completion) for improving the performance of API method call completion. CSCC is context sensitive in that it uses new sources of information as the context of a target method call. CSCC indexes method calls in code examples by their contexts. To recommend completion proposals, CSCC ranks candidate methods by the similarities between their contexts and the context of the target call. Evaluation using a set of subject systems and five popular state of-the-art techniques suggests that CSCC performs better than existing type or example-based code completion systems. We also investigate how the different contextual elements of the target call benefit CSCC.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.29,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976073,code completion;code example;recommendation;simhash,Context;FCC;Hamming distance;Indexes;Libraries;Proposals;Receivers,application program interfaces;software engineering,API method call completion;CSCC indexes method;context sensitive code completion;example-based code completion systems;type-based code completion systems,,9,,31,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
"Recommending Clones for Refactoring Using Design, Context, and History",W. Wang; M. W. Godfrey,"Sch. of Comput. Sci., Univ. of Waterloo, Waterloo, ON, Canada",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,331,340,"Developers know that copy-pasting code (aka code cloning) is often a convenient shortcut to achieving a design goal, albeit one that carries risks to the code quality over time. However, deciding which, if any, clones should be eliminated within an existing system is a daunting task. Fixing a clone usually means performing an invasive refactoring, and not all clones may be worth the effort, cost, and risk that such a change entails. Furthermore, sometimes cloning fulfils a useful design role, and should not be refactored at al. And clone detection tools often return very large result sets, making it hard to choose which clones should be investigated and possibly removed. In this paper, we propose an automated approach to recommend clones for refactoring by training a decision tree-based classifier. We analyze more than 600 clone instances in three medium-to large-sized open source projects, and we collect features that are associated with the source code, the context, and the history of clone instances. Our approach achieves a precision of around 80% in recommending clone refactoring instances for each target system, and similarly good precision is achieved in cross-project evaluation. By recommending which clones are appropriate for refactoring, our approach allows for better resource allocation for refactoring itself after obtaining clone detection results, and can thus lead to improved clone management in practice.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.55,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976099,Clone Management;Code Refactoring;Software Clones;Software Recommendation System,Cloning;Context;Detectors;Feature extraction;History;Software systems,decision trees;pattern classification;software maintenance,clone detection;clone instance context;clone instance history;clone management;clone refactoring instances;code cloning;decision tree-based classifier;open source projects;resource allocation;source code,,5,,48,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
Empirical Analysis of the Relationship between CC and SLOC in a Large Corpus of Java Methods,D. Landman; A. Serebrenik; J. Vinju,"Centrum Wiskunde & Inf., Amsterdam, Netherlands",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,221,230,"Measuring the internal quality of source code is one of the traditional goals of making software development into an engineering discipline. Cyclomatic Complexity (CC) is an often used source code quality metric, next to Source Lines of Code (SLOC). However, the use of the CC metric is challenged by the repeated claim that CC is redundant with respect to SLOC due to strong linear correlation. We test this claim by studying a corpus of 17.8M methods in 13K open-source Java projects. Our results show that direct linear correlation between SLOC and CC is only moderate, as caused by high variance. We observe that aggregating CC and SLOC over larger units of code improves the correlation, which explains reported results of strong linear correlation in literature. We suggest that the primary cause of correlation is the aggregation. Our conclusion is that there is no strong linear correlation between CC and SLOC of Java methods, so we do not conclude that CC is redundant with SLOC. This conclusion contradicts earlier claims from literature, but concurs with the widely accepted practice of measuring of CC next to SLOC.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.44,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976088,cylcomatic complexity;emperical research;software quality,Complexity theory;Correlation;Java;Measurement;Software;Transforms,Java;public domain software;software metrics;software quality;source code (software),CC;Java methods;SLOC;cyclomatic complexity;internal source code quality measurement;open-source Java projects;software development;source code quality metric;source lines-of-code;strong linear correlation,,5,,44,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
Understanding Log Lines Using Development Knowledge,W. Shang; M. Nagappan; A. E. Hassan; Z. M. Jiang,"Sch. of Comput., Queen's Univ., Kingston, ON, Canada",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,21,30,"Logs are generated by output statements that developers insert into the code. By recording the system behaviour during runtime, logs play an important role in the maintenance of large software systems. The rich nature of logs has introduced a new market of log management applications (e.g., Splunk, XpoLog and log stash) that assist in storing, querying and analyzing logs. Moreover, recent research has demonstrated the importance of logs in operating, understanding and improving software systems. Thus log maintenance is an important task for the developers. However, all too often practitioners (i.e., operators and administrators) are left without any support to help them unravel the meaning and impact of specific log lines. By spending over 100 human hours and manually examining all the email threads in the mailing list for three open source systems (Hadoop, Cassandra and Zookeeper) and performing web search on sampled logging statements, we found 15 email inquiries and 73 inquiries from web search about different log lines. We identified that five types of development knowledge that are often sought from the logs by practitioners: meaning, cause, context, impact and solution. Due to the frequency and nature of log lines about which real customers inquire, documenting all the log lines or identifying which ones to document is not efficient. Hence in this paper we propose an on-demand approach, which associates the development knowledge present in various development repositories (e.g., code commits and issues reports) with the log lines. Our case studies show that the derived development knowledge can be used to resolve real-life inquiries about logs.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.24,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976068,Program understanding;Software Logs;Software maintenance,Context;Electronic mail;Engines;Google;Knowledge engineering;Software systems;Web search,Internet;public domain software;software maintenance;system monitoring,Web search;development knowledge;log lines;log maintenance;open source systems,,5,,37,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
An Empirical Study of Delays in the Integration of Addressed Issues,D. A. d. Costa; S. L. Abebe; S. Mcintosh; U. Kulesza; A. E. Hassan,"Dept. of Inf. & Appl. Math. (DIMAp), Fed. Univ. of Rio Grande do Norte-UFRN, Natal, Brazil",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,281,290,"Predicting the time required to address an issue (i.e., a feature, bug fix, or enhancement) has long been the goal of many software engineering researchers. However, after an issue has been addressed, it must be integrated into an official release to become visible to users. In theory, issues should be integrated into releases soon after they are addressed. Yet in practice, the integration of an addressed issue might be delayed. For instance, an addressed issue might be delayed in order to assess the impact that it may have on the system as a whole. While one can often speculate, it is not always clear why some addressed issues are integrated immediately, while others are delayed. In this paper, we empirically study the integration of 20,995 addressed issues from the Argo UML, Eclipse, and Fire fox projects. Our results indicate that: (i) despite being addressed well before the release date, the integration of 34% to 60% of addressed issues in systems with traditional release cycle, and 98% of addressed issues in systems with rapid release cycle were delayed by one or more releases, (ii) using information derived from the addressed issues, we are able to accurately predict the release in which an addressed issue will be integrated, achieving a Receiver Operator Curve (ROC) area of above 0.74, and (iii) the workload of integrators is the most influential factor in our integration delay models. Our results indicate that integration can introduce non-negligible delays that prevent addressed issues from being delivered to users. Thus, solely focusing on the time to address an issue is not enough to truly assess how long it takes for users to see that the issue has been addressed in the software system.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.50,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976094,,Databases;Delays;Educational institutions;Receivers;Software;Unified modeling language,sensitivity analysis;software engineering,ArgoUML project;Eclipse project;Firefox project;ROC area;addressed issue integration;empirical analysis;influential factor;integration delay models;integrator workload;nonnegligible delays;receiver operator curve area;release cycle;software engineering;software system,,5,,36,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
How Does Code Obfuscation Impact Energy Usage?,C. Sahin; P. Tornquist; R. Mckenna; Z. Pearson; J. Clause,"Comput. & Inf. Sci. Dept., Univ. of Delaware, Newark, DE, USA",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,131,140,"Software piracy is an important concern for application developers. Such concerns are especially relevant in mobile application development, where piracy rates can approach 90%. The most commonly used approach by mobile developers for preventing piracy is code obfuscation. However, the decision to apply such transformations is currently made without regard to the impacts of obfuscations on another area of increasing concern for mobile application developers: energy consumption. Because both software piracy and battery life are important concerns, mobile application developers must strike a balance between protecting their applications and preserving the battery lives of their users' devices. To help them make such choices, we conducted an empirical study of the effects of 18 code obfuscations on the amount of energy consumed by executing a total of 15 usage scenarios spread across 11 Android applications. The results of the study indicate that, while obfuscations can have a statistically significant impact on energy usage and are significantly more likely to increase energy usage than to decrease energy usage, the magnitudes of such impacts are unlikely to impact mobile application users.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.35,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976079,Code Obfuscation;Empirical Study;Energy,Androids;Batteries;Calculators;Energy consumption;Humanoid robots;Mobile communication;Power measurement,computer crime;energy consumption;mobile computing;source code (software),battery life;code obfuscation;energy consumption;energy usage;mobile application development;mobile developer;piracy rate;software piracy,,18,,26,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
An Exploratory Study on Self-Admitted Technical Debt,A. Potdar; E. Shihab,"Dept. of Software Eng., Rochester Inst. of Technol., Rochester, NY, USA",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,91,100,"Throughout a software development life cycle, developers knowingly commit code that is either incomplete, requires rework, produces errors, or is a temporary workaround. Such incomplete or temporary workarounds are commonly referred to as 'technical debt'. Our experience indicates that self-admitted technical debt is common in software projects and may negatively impact software maintenance, however, to date very little is known about them. Therefore, in this paper, we use source-code comments in four large open source software projects-Eclipse, Chromium OS, Apache HTTP Server, and ArgoUML to identify self-admitted technical debt. Using the identified technical debt, we study 1) the amount of self-admitted technical debt found in these projects, 2) why this self-admitted technical debt was introduced into the software projects and 3) how likely is the self-admitted technical debt to be removed after their introduction. We find that the amount of self-admitted technical debt exists in 2.4%-31% of the files. Furthermore, we find that developers with higher experience tend to introduce most of the self-admitted technical debt and that time pressures and complexity of the code do not correlate with the amount of self-admitted technical debt. Lastly, although self-admitted technical debt is meant to be addressed or removed in the future, only between 26.3%-63.5% of self-admitted technical debt gets removed from projects after introduction.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.31,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976075,Software comments;Technical debt,Chromium;Complexity theory;Computer hacking;Correlation;Java;Software maintenance,project management;public domain software;software maintenance;software management;software quality,Apache HTTP Server;ArgoUML;Chromium OS;Eclipse;open source software projects;self-admitted technical debt;software maintenance;software quality;source-code comments,,19,,22,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
Why Do Automated Builds Break? An Empirical Study,N. Kerzazi; F. Khomh; B. Adams,"R&D Dept., Payza.com, Montreal, QC, Canada",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,41,50,"To detect integration errors as quickly as possible, organizations use automated build systems. Such systems ensure that (1) the developers are able to integrate their parts into an executable whole, (2) the testers are able to test the built system, (3) and the release engineers are able to leverage the generated build to produce the upcoming release. The flipside of automated builds is that any incorrect change can break the build, and hence testing and releasing, and (even worse) block other developers from continuing their work, delaying the project even further. To measure the impact of such build breakage, this empirical study analyzes 3,214 builds produced in a large software company over a period of 6 months. We found a high ratio of build breakage (17.9%), and also quantified the cost of such build breakage as more than 336.18 man-hours. Interviews with 28 software engineers from the company helped to understand the circumstances under which builds are broken and the effects of build breakages on the collaboration and coordination of teams. We quantitatively investigated the main factors impacting build breakage and found that build failures correlate with the number of simultaneous contributors on branches, the type of work items performed on a branch, and the roles played by the stakeholders of the builds (for example developers vs. Integrators).",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.26,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976070,Automated Builds;Data Mining;Empirical Software Engineering;Software Quality,Collaboration;Companies;Context;Interviews;Software;Statistical analysis,error detection;program testing;software quality,automated build systems;build breakage;build failures;integration error detection;software company;software quality,,11,,23,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
On the Use of Stack Traces to Improve Text Retrieval-Based Bug Localization,L. Moreno; J. J. Treadway; A. Marcus; W. Shen,"Dept. of Comput. Sci., Univ. of Texas at Dallas, Richardson, TX, USA",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,151,160,"Many bug localization techniques rely on Text Retrieval (TR) models. The most successful approaches have been proven to be the ones combining TR techniques with static analysis, dynamic analysis, and/or software repositories information. Dynamic software analysis and software repositories mining bring a significant overhead, as they require instrumenting and executing the software, and analyzing large amounts of data, respectively. We propose a new static technique, named Lobster (Locating Bugs using Stack Traces and text Retrieval), which is meant to improve TR-based bug localization without the overhead associated with dynamic analysis and repository mining. Specifically, we use the stack traces submitted in a bug report to compute the similarity between their code elements and the source code of a software system. We combine the stack trace based similarity and the textual similarity provided by TR techniques to retrieve code elements relevant to bug reports. We empirically evaluated Lobster using 155 bug reports containing stack traces from 14 open source software systems. We used Lucene, an optimized version of VSM, as baseline of comparison. The results show that, in average, Lobster improves or maintains the effectiveness of Lucene-based bug localization in 82% of the cases.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.37,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976081,bug localization;stack traces;static analysis;text retrieval,Conferences;Software maintenance,information retrieval;program debugging;text analysis,TR models;TR techniques;bug localization techniques;dynamic analysis;improve text retrieval;software analysis;software repositories information;software repositories mining;software system;source code;stack traces;static analysis;textual similarity,,8,,29,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
Maintenance Patterns of Large-Scale PHP Web Applications,P. Kyriakakis; A. Chatzigeorgiou,"Sch. of Sci. & Technol., Hellenic Open Univ., Patras, Greece",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,381,390,"Scripting languages such as PHP have been criticized as inadequate for supporting maintenance of large-scale software projects. In this paper we attempt to provide insight into the way that five large and well-known PHP applications evolved over time. Several aspects of their history are examined including the amount of unused code, the removal of functions, the use of libraries, the stability of their interfaces, the migration to object-orientation and the evolution of complexity. The results suggest that these systems undergo systematic maintenance which is driven by targeted design decisions and evolution is by no means hindered by the underlying programming language.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.60,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976104,PHP;scripting language;software evolution;software libraries;survival analysis;web applications,Communities;Java;Libraries;Maintenance engineering;Programming;Software systems,Internet;programming languages;software maintenance,PHP Web applications;maintenance pattern;programming language;scripting languages;software project maintenance,,5,,21,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
Refactoring Java Concurrent Programs Based on Synchronization Requirement Analysis,B. Tao; J. Qian,"Coll. of Comput. Sci. & Technol., Nanjing Univ. of Aeronaut. & Astronaut., Nanjing, China",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,361,370,"Writing high quality concurrent programs is challenging. A concurrent program that is not well-written may suffer from coarse synchronization problems, e.g., overly-large critical sections, overly-coarse locks, and etc. These coarse synchronizations may introduce unnecessary lock contention and thereby affect the parallel execution of running threads. To optimize them, people suggest use refactorings, e.g., Split Lock refactoring and Split Critical Section refactoring, to gradually evolve the synchronization code for better parallelism. However, manually identifying the refactoring opportunities is difficult and by-hand code transformations are error-prone. To reduce the manual efforts, this paper proposes an automated refactoring approach for Java concurrent programs based on synchronization requirement analysis. It can automatically analyze the existing synchronization code to identify synchronization requirements. Bases on these requirements, we can find Split Lock, Split Critical Section, and Convert to Atomic refactoring opportunities and then make proper code transformation for each of them. Our experiment shows that the approach does find effective refactoring opportunities in real projects and can transform the refactorable code correctly. This indicates the approach could be helpful for concurrent program evolution.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.58,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976102,Java;concurrency;refactoring;synchronization,Algorithm design and analysis;Concurrent computing;Frequency synchronization;Java;Programming;Shape;Synchronization,Java;formal verification;software maintenance,coarse synchronization problems;hand code transformations;parallel execution;refactoring Java concurrent programs;split critical section refactoring;split lock refactoring;synchronization code;synchronization requirement analysis,,2,,23,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
How Developers' Collaborations Identified from Different Sources Tell Us about Code Changes,S. Panichella; G. Bavota; M. D. Penta; G. Canfora; G. Antoniol,"Dept. of Eng., Univ. of Sannio, Benevento, Italy",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,251,260,"Written communications recorded through channels such as mailing lists or issue trackers, but also code co-changes, have been used to identify emerging collaborations in software projects. Also, such data has been used to identify the relation between developers' roles in communication networks and source code changes, or to identify mentors aiding newcomers to evolve the software project. However, results of such analyses may be different depending on the communication channel being mined. This paper investigates how collaboration links vary and complement each other when they are identified through data from three different kinds of communication channels, i.e., mailing lists, issue trackers, and IRC chat logs. Also, the study investigates how such links overlap with links mined from code changes, and how the use of different sources would influence (i) the identification of project mentors, and (ii) the presence of a correlation between the social role of a developer and her changes. Results of a study conducted on seven open source projects indicate that the overlap of communication links between the various sources is relatively low, and that the application of networks obtained from different sources may lead to different results.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.47,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976091,Developer Social Network;Developers;Empirical Study,Birds;Communication channels;Electronic mail;Measurement;Software;Welding,program diagnostics;public domain software;software development management,IRC chat logs;communication networks;developer collaborations;issue trackers;mailing lists;open source projects;project mentors;source code changes;written communications,,5,,37,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
Clonepedia: Summarizing Code Clones by Common Syntactic Context for Software Maintenance,Y. Lin; Z. Xing; X. Peng; Y. Liu; J. Sun; W. Zhao; J. Dong,"Sch. of Comput. Sci., Fudan Univ., Shanghai, China",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,341,350,"Code clones have to be made explicit and be managed in software maintenance. Researchers have developed many clone detection tools to detect and analyze code clones in software systems. These tools report code clones as similar code fragments in source files. However, clone-related maintenance tasks (e.g., refactorings) often involve a group of code clones appearing in larger syntactic context (e.g., code clones in sibling classes or code clones calling similar methods). Given a list of low-level code-fragment clones, developers have to manually summarize from bottom up low-level code clones that are relevant to the syntactic context of a maintenance task. In this paper, we present a clone summarization technique to summarize code clones with respect to their common syntactic context. The clone summarization allows developers to locate and maintain code clones in a top-down manner by type hierarchy and usage dependencies. We have implemented our approach in the Clonepedia tool and conducted a user study on JHotDraw with 16 developers. Our results show that Clonepedia users can better locate and refactor code clones, compared with developers using the Clone Detective tool.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.56,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976100,Clone Summarization;Code Clone;Syntactic Pattern,Abstracts;Cloning;Context;Maintenance engineering;Ontologies;Production facilities;Syntactics,software maintenance;source code (software),Clonepedia tool;JHotDraw;clone detection tools;clone-related maintenance tasks;code clone analysis;code clone detection;code clone summarization technique;common syntactic context;low-level code-fragment clones;software maintenance;software systems;type hierarchy;usage dependencies,,0,,29,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
Is Popularity a Measure of Quality? An Analysis of Maven Components,H. Sajnani; V. Saini; J. Ossher; C. V. Lopes,"Bren Sch. of Inf. & Comput. Sci., Univ. of California, Irvine, Irvine, CA, USA",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,231,240,"One of the perceived values of open source software is the idea that many eyes can increase code quality and reduce the amount of bugs. This perception, however, has been questioned by some due the lack of supporting evidence. This paper presents an empirical analysis focusing on the relationship between the utilization of open source components and their engineering quality. In this study, we determine the popularity of 2,406 Maven components by calculating their usage across 55,191 open source Java projects. As a proxy of code quality for a component, we calculate (i) its defect density using the set of bug patterns reported by Find Bugs, and (ii) 9 popular software quality metrics from the SQO-OSS quality model. We then look for correlations between (i) popularity and defect density, and (ii) popularity and software quality metrics. In most of the cases, no correlations were found. In cases where minor correlations exist, they are driven by component size. Statistically speaking, and using the methods in this study, the Maven repository does not seem to support the ""many eyeballs"" effect. We conjecture that the utilization of open source components is driven by factors other than their engineering quality, an interpretation that is supported by the findings in this study.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.45,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976089,,Complexity theory;Computer bugs;Correlation;Couplings;Java;Measurement;Software quality,Java;program debugging;public domain software;software metrics;software quality,FindBugs;Maven components analysis;Maven repository;SQO-OSS quality model;bug patterns;bugs;code quality;defect density;engineering quality;open source Java projects;open source components;open source software;software quality metrics,,6,,43,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
EnTagRec: An Enhanced Tag Recommendation System for Software Information Sites,S. Wang; D. Lo; B. Vasilescu; A. Serebrenik,"Sch. of Inf. Syst., Singapore Manage. Univ., Singapore, Singapore",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,291,300,"Software engineers share experiences with modern technologies by means of software information sites, such as Stack Overflow. These sites allow developers to label posted content, referred to as software objects, with short descriptions, known as tags. However, tags assigned to objects tend to be noisy and some objects are not well tagged. To improve the quality of tags in software information sites, we propose EnTagRec, an automatic tag recommender based on historical tag assignments to software objects and we evaluate its performance on four software information sites, Stack Overflow, Ask Ubuntu, Ask Different, and Free code. We observe that that EnTagRec achieves Recall@5 scores of 0.805, 0.815, 0.88 and 0.64, and Recall@10 scores of 0.868, 0.876, 0.944 and 0.753, on Stack Overflow, Ask Ubuntu, Ask Different, and Free code, respectively. In terms of Recall@5 and Recall@10, averaging across the 4 datasets, EnTagRec improves Tag Combine, which is the state of the art approach, by 27.3% and 12.9% respectively.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.51,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976095,recommendation systems;software information sites;tagging,Amplitude shift keying;Bayes methods;Java;Linux;Software;Training;Training data,Web sites;operating systems (computers);public domain software;recommender systems;software maintenance;software reusability,EnTagRec;Recall@S scores;TagCombine;ask Ubuntu;ask different;automatic tag recommender;component reuse;enhanced tag recommendation system;freecode;historical tag assignments;online media;open source repositories;software creation;software information sites;software maintenance;software objects;stack overflow,,26,,41,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
Do They Really Smell Bad? A Study on Developers' Perception of Bad Code Smells,F. Palomba; G. Bavota; M. D. Penta; R. Oliveto; A. D. Lucia,"Univ. of Salerno, Salerno, Italy",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,101,110,"In the last decade several catalogues have been defined to characterize bad code smells, i.e., symptoms of poor design and implementation choices. On top of such catalogues, researchers have defined methods and tools to automatically detect and/or remove bad smells. Nevertheless, there is an ongoing debate regarding the extent to which developers perceive bad smells as serious design problems. Indeed, there seems to be a gap between theory and practice, i.e., what is believed to be a problem (theory) and what is actually a problem (practice). This paper presents a study aimed at providing empirical evidence on how developers perceive bad smells. In this study, we showed to developers code entities -- belonging to three systems -- affected and not by bad smells, and we asked them to indicate whether the code contains a potential design problem, and if any, the nature and severity of the problem. The study involved both original developers from the three projects and outsiders, namely industrial developers and Master's students. The results provide insights on characteristics of bad smells not yet explored sufficiently. Also, our findings could guide future research on approaches for the detection and removal of bad smells.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.32,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976076,Code Smells;Empirical Study,Complexity theory;Context;Encoding;Iron;Open source software;Unified modeling language,software engineering;source code (software),bad code smells;developer perception;industrial developers;masters students,,26,,27,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
A Fine-Grained Analysis on the Evolutionary Coupling of Cloned Code,M. Mondal; C. K. Roy; K. A. Schneider,"Dept. of Comput. Sci., Univ. of Saskatchewan, Saskatoon, SK, Canada",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,51,60,"Code clones are identical or similar code fragments in a code base. A group of code fragments that are similar to one another forms a clone class. Clone fragments from the same clone class often need to be changed together consistently and thus, they exhibit evolutionary coupling. Evolutionary coupling among clone fragments within a clone class has already been investigated and reported. However, a change to a clone fragment of a clone class may also trigger changes to non-cloned code as well as to clone fragments of other clone classes. Such coupling information is equally important for the proper management of clones during software maintenance. Unfortunately, there are no such studies reported in the literature. In this paper, we describe a large scale empirical study that we conduct to examine whether a clone fragment from a particular clone class exhibits evolutionary coupling with non-clone fragments and/or with clone fragments of other clone classes. Our experimental results on thousands of revisions of six diverse subject systems written in two programming languages indicate the presence of such couplings. We consider both exact and near-miss clones in our study. By analyzing the evolutionary couplings of a particular clone fragment from a particular clone class, we are able to predict its three types of co-change candidates with considerable accuracy in terms of precision and recall. These co-change candidates are: (1) non-clone fragments, (2) clone fragments from clone classes other than its own class, and (3) other clone fragments from its own clone class. Thus, we can improve existing clone tracking techniques so that they can also infer and suggest which non-clone fragments as well as which clone fragments from other clone classes might need to be co-changed correspondingly when modifying a clone fragment from a particular clone class.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.27,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976071,Association Rule;Clone Tracking;Co-change Candidate;Code Clones;Evolutionary Coupling,Association rules;Cloning;Couplings;Java;Software maintenance;Software systems,software maintenance,clone fragment;clone tracking techniques;cloned code evolutionary coupling;co-change candidates;exact clones;fine-grained analysis;near-miss clones;programming languages;software maintenance,,2,,37,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
On the Effectiveness of Information Retrieval Based Bug Localization for C Programs,R. K. Saha; J. Lawall; S. Khurshid; D. E. Perry,"Univ. of Texas at Austin, Austin, TX, USA",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,161,170,"Localizing bugs is important, difficult, and expensive, especially for large software projects. To address this problem, information retrieval (IR) based bug localization has increasingly been used to suggest potential buggy files given a bug report. To date, researchers have proposed a number of IR techniques for bug localization and empirically evaluated them to understand their effectiveness. However, virtually all of the evaluations have been limited to the projects written in object-oriented programming languages, particularly Java. Therefore, the effectiveness of these techniques for other widely used languages such as C is still unknown. In this paper, we create a benchmark dataset consisting of more than 7,500 bug reports from five popular C projects and rigorously evaluate our recently introduced IR-based bug localization tool using this dataset. Our results indicate that although the IR-relevant properties of C and Java programs are different, IR-based bug localization in C software at the file level is overall as effective as in Java software. However, we also find that the recent advance of using program structure information in performing bug localization gives less of a benefit for C software than for Java software.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.38,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976082,Bug Localization;Information Retrieval;Search,Accuracy;Java;Kernel;Linux;Measurement,C language;Java;information retrieval;object-oriented programming;program debugging,C programs;Java programs;bug localization;buggy files;information retrieval;object-oriented programming languages;software projects,,4,,22,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
Mining API Usage Examples from Test Code,Z. Zhu; Y. Zou; B. Xie; Y. Jin; Z. Lin; L. Zhang,"Sch. of Electron. Eng. & Comput. Sci., Peking Univ., Beijing, China",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,301,310,"Lack of effective usage examples in API documents has been proven to be a great obstacle to API learning. To deal with this issue, several approaches have been proposed to automatically extract usage examples from client code or related web pages, which are unfortunately not available for newly released API libraries. In this paper, we propose a novel approach to mining API usage examples from test code. Although test code can be a good source of usage examples, the issue of multiple test scenarios might lead to repetitive and interdependent API usages in a test method, which make it complicated and difficult to extract API usage examples. To address this issue, we study the JUnit test code and summarize a set of test code patterns. We employ a code pattern based heuristic slicing approach to separate test scenarios into code examples. Then we cluster the similar usage examples for recommendation. An evaluation on four open source software libraries demonstrates that the accuracy of our approach is much higher than the state-of-art approach eXoaDoc on test code. Furthermore, we have developed an Eclipse plug in tool Use Tec.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.52,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976096,API;code patterns;code slicing;test code;usage example,Arrays;Classification algorithms;Clustering algorithms;Data mining;Libraries;Web pages,application program interfaces;data mining;object-oriented methods;program testing;public domain software;software libraries,API usage example mining;Eclipse plugin tool;JUnit test code;UsETeC;eXoaDoc;heuristic slicing approach;open source software libraries;test code patterns;usage example cluster,,3,,32,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
CoMoGen: An Approach to Locate Relevant Task Context by Combining Search and Navigation,K. Kevic; T. Fritz; D. C. Shepherd,"Dept. of Inf., Univ. of Zurich, Zurich, Switzerland",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,61,70,"Developers spend a substantial amount of time searching and navigating source code to locate the relevant places for performing a change task. While the searching and navigating are highly intertwined and related, most current approaches focus either on search or on navigation support for developers, keeping the two distinct. In this paper, we present an approach called CoMoGen that combines search and navigation by expanding, ranking and visualizing search results with navigation context. In an experimental analysis we found that our approach is able to generate small task-relevant context models that locates more relevant search results than state-of-the-art and state-of-the-practice search approaches. A small, preliminary user study with ten participants further yields promising preliminary findings that CoMoGen supports developers in better understanding and assessing the relevance of search results and in reducing navigation steps.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.28,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976072,,Conferences;Navigation;Software maintenance;Visualization,information retrieval;search engines,CoMoGen;relevant task context;search and navigation;task-relevant context model,,0,,53,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
Compositional Vector Space Models for Improved Bug Localization,S. Wang; D. Lo; J. Lawall,"Sch. of Inf. Syst., Singapore Manage. Univ., Singapore, Singapore",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,171,180,"Software developers and maintainers often need to locate code units responsible for a particular bug. A number of Information Retrieval (IR) techniques have been proposed to map natural language bug descriptions to the associated code units. The vector space model (VSM) with the standard tf-idf weighting scheme (VSM<sub>natural</sub>), has been shown to outperform nine other state-of-the-art IR techniques. However, there are multiple VSM variants with different weighting schemes, and their relative performance differs for different software systems. Based on this observation, we propose to compose various VSM variants, modelling their composition as an optimization problem. We propose a genetic algorithm (GA) based approach to explore the space of possible compositions and output a heuristically near-optimal composite model. We have evaluated our approach against several baselines on thousands of bug reports from AspectJ, Eclipse, and SWT. On average, our approach (VSM <sub>composite</sub>) improves hit at 5 (Hit@5), mean average precision (MAP), and mean reciprocal rank (MRR) scores of VSM<sub>natural</sub> by 18.4%, 20.6%, and 10.5% respectively. We also integrate our compositional model with AmaLgam, which is a state-of-art bug localization technique. The resultant model named AmaLgam<sub>composite</sub> on average can improve Hit@5, MAP, and MRR scores of AmaLgam by 8.0%, 14.4% and 6.5% respectively.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.39,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976083,bug localization;composite model;genetic algorithm;information retrieval,Biological cells;Genetic algorithms;Sociology;Standards;Statistics;Training;Vectors,genetic algorithms;information retrieval;natural language processing;program debugging;software maintenance;vectors,AmaLgam;AspectJ;Eclipse;Hit@5;IR techniques;MAP;MRR scores;SWT;VSM variants;VSM<sub>natural</sub>;bug reports;code units;compositional model;compositional vector space model;genetic algorithm based approach;improved bug localization;information retrieval techniques;natural language bug descriptions;near-optimal composite model;optimization problem;software developers;software maintainers;software systems;standard tf-idf weighting scheme;vector space model,,12,,46,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
Combining Text Mining and Data Mining for Bug Report Classification,Y. Zhou; Y. Tong; R. Gu; H. Gall,"Coll. of Comput. Sci., Nanjing Univ. of Aeronaut. & Astronaut., Nanjing, China",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,311,320,"Misclassification of bug reports inevitably sacrifices the performance of bug prediction models. Manual examinations can help reduce the noise but bring a heavy burden for developers instead. In this paper, we propose a hybrid approach by combining both text mining and data mining techniques of bug report data to automate the prediction process. The first stage leverages text mining techniques to analyze the summary parts of bug reports and classifies them into three levels of probability. The extracted features and some other structured features of bug reports are then fed into the machine learner in the second stage. Data grafting techniques are employed to bridge the two stages. Comparative experiments with previous studies on the same data -- three large-scale open source projects -- consistently achieve a reasonable enhancement (from 77.4% to 81.7%, 73.9% to 80.2% and 87.4% to 93.7%, respectively) over their best results in terms of overall performance. Additional comparative empirical experiments on other two popular open source repositories confirm the findings and demonstrate the benefits of our approach.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.53,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976097,,Bayes methods;Feature extraction;Predictive models;Software;Text mining;Training,data mining;learning (artificial intelligence);program debugging;public domain software;text analysis,bug prediction models;bug report classification;data grafting techniques;data mining techniques;hybrid approach;large-scale open source projects;machine learner;open source repositories;summary parts;text mining techniques,,8,,44,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
Boosting Bug-Report-Oriented Fault Localization with Segmentation and Stack-Trace Analysis,C. P. Wong; Y. Xiong; H. Zhang; D. Hao; L. Zhang; H. Mei,"Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,181,190,"To deal with post-release bugs, many software projects set up public bug repositories for users all over the world to report bugs that they have encountered. Recently, researchers have proposed various information retrieval based approaches to localizing faults based on bug reports. In these approaches, source files are processed as single units, where noise in large files may affect the accuracy of fault localization. Furthermore, bug reports often contain stack-trace information, but existing approaches often treat this information as plain text. In this paper, we propose to use segmentation and stack-trace analysis to improve the performance of bug localization. Specifically, given a bug report, we divide each source code file into a series of segments and use the segment most similar to the bug report to represent the file. We also analyze the bug report to identify possible faulty files in a stack trace and favor these files in our retrieval. According to our empirical results, our approach is able to significantly improve Bug Locator, a representative fault localization approach, on all the three software projects (i.e., Eclipse, AspectJ, and SWT) used in our empirical evaluation. Furthermore, segmentation and stack-trace analysis are complementary to each other for boosting the performance of bug-report-oriented fault localization.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.40,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976084,bug report;fault localization;feature location;information retrieval,Computer bugs;Information retrieval;Java;Logistics;Measurement;Noise;Software,fault diagnosis;information retrieval;program debugging;program diagnostics;source code (software),AspectJ;Eclipse;SWT;boosting bug-report-oriented fault localization;bug localization;bug locator;bug reportq;faulty files;information retrieval;post-release bugs;public bug repository;representative fault localization approach;software projects;source code file;source files;stack-trace analysis;stack-trace information,,10,,46,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
Evaluating Modern Clone Detection Tools,J. Svajlenko; C. K. Roy,"Dept. of Comput. Sci., Univ. of Saskatchewan, Saskatoon, SK, Canada",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,321,330,"Many clone detection tools and techniques have been introduced in the literature, and these tools have been used to manage clones and study their effects on software maintenance and evolution. However, the performance of these modern tools is not well known, especially recall. In this paper, we evaluate and compare the recall of eleven modern clone detection tools using four benchmark frameworks, including: (1) Bellon's Framework, (2) our modification to Bellon's Framework to improve the accuracy of its clone matching metrics, (3) Murakamki et al.'s extension of Bellon's Framework which adds type 3 gap awareness to the framework, and (4) our Mutation and Injection Framework. Bellon's Framework uses a curated corpus of manually validated clones detected by tools contemporary to 2002. In contrast, our Mutation and Injection Framework synthesizes a corpus of artificial clones using a cloning taxonomy produced in 2009. While still very popular in the clone community, there is some concern that Bellon's corpus may not be accurate for modern clone detection tools. We investigate the accuracy of the frameworks by (1) checking for anomalies in their results, (2) checking for agreement between the frameworks, and (3) checking for agreement with our expectations of these tools. Our expectations are researched and flexible. While expectations may contain inaccuracies, they are valuable for identifying possible inaccuracies in a benchmark. We find anomalies in the results of Bellon's Framework, and disagreement with both our expectations and the Mutation Framework. We conclude that Bellon's Framework may not be accurate for modern tools, and that an update of its corpus with clones detected by the modern tools is warranted. The results of the Mutation Framework agree with our expectations in most cases. We suggest that it is a good solution for evaluating modern tools.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.54,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976098,bellon's benchmark;benchmark;clone detection;modern;mutation and injection framework;precision;recall,Accuracy;Benchmark testing;Cloning;Java;Manuals;Measurement;Software systems,data mining;program testing;software maintenance;source code (software),artificial clones;clone community;clone detection tools;clone matching metrics;software maintenance,,19,,22,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
Learning to Combine Multiple Ranking Metrics for Fault Localization,J. Xuan; M. Monperrus,"INRIA Lille - Nord Eur., Lille, France",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,191,200,"Fault localization is an inevitable step in software debugging. Spectrum-based fault localization consists in computing a ranking metric on execution traces to identify faulty source code. Existing empirical studies on fault localization show that there is no optimal ranking metric for all faults in practice. In this paper, we propose Multric, a learning-based approach to combining multiple ranking metrics for effective fault localization. In Multric, a suspiciousness score of a program entity is a combination of existing ranking metrics. Multric consists two major phases: learning and ranking. Based on training faults, Multric builds a ranking model by learning from pairs of faulty and non-faulty source code elements. When a new fault appears, Multric computes the final ranking with the learned model. Experiments are conducted on 5386 seeded faults in ten open-source Java programs. We empirically compare Multric against four widely-studied metrics and three recently-proposed one. Our experimental results show that Multric localizes faults more effectively than state-of-art metrics, such as Tarantula, Ochiai, and Ample.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.41,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976085,Fault localization;learning to rank;multiple ranking metrics,Computational modeling;Debugging;Java;Measurement;Object oriented modeling;Training;Training data,Java;learning (artificial intelligence);program debugging;public domain software;software fault tolerance;source code (software),Multric;faulty source code identification;learning-based approach;multiple ranking metrics;nonfaulty source code elements;open-source Java programs;program entity;software debugging;spectrum-based fault localization;training faults,,21,,35,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
Pinso: Precise Isolation of Concurrency Bugs via Delta Triaging,B. Liu; Z. Qi; B. Wang; R. Ma,"Dept. of Comput. Sci. & Eng., Shanghai Jiao Tong Univ., Shanghai, China",2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,201,210,"Concurrent programs are known to be difficult to test and maintain. These programs often fail because of concurrency bugs caused by non-deterministic interleavings among shared memory accesses. Even though a concurrency bug can be detected, it is still hard to isolate the root cause of the bug, due to the challenge in understanding the complex thread interleavings or schedules. In this paper, we propose a practical and precise isolation technique for concurrent bugs called Pinso that seeks to exploit the non-deterministic nature of concurrency bugs and accurately find the root causes of program error, to further help developers maintain concurrent programs. Pinso profiles runtime inter-thread interleavings based on a set of summarized memory access patterns, and then, isolates suspicious interleaving patterns in the triaging phase. Using a filtration-oriented scheduler, Pinso effectively eliminates false positives that are irrelevant to the bug. We evaluate Pinso with 11 real-world concurrency bugs, including single- and multi-variable violation, from sever/desktop concurrent applications (MySQL, Apache, and several others). Experiments indicate that our tool accurately isolates the root causes of all the bugs.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.42,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976086,Concurrency bug;Software testing and debugging,Computer bugs;Concurrent computing;History;Instruction sets;Schedules;Synchronization;Testing,concurrency control;program debugging;program testing;scheduling;shared memory systems,Pinso profiles;complex thread interleavings;concurrency bug precise isolation technique;concurrent programs;delta triaging;filtration-oriented scheduler;inter-thread interleavings;memory access patterns;multivariable violation;program error;shared memory accesses;single-variable violation;software testing,,1,,37,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
Quantifying the Encapsulation of Implemented Software Architectures,E. Bouwers; A. v. Deursen; J. Visser,,2014 IEEE International Conference on Software Maintenance and Evolution,20141206,2014,,,211,220,"Applying encapsulation techniques lead to software systems in which the majority of changes are localized, which reduces maintenance and testing effort. In the evaluation of implemented software architectures, metrics can be used to provide an indication of the degree of encapsulation within a system and to serve as a basis for an informed discussion about how well-suited the system is for expected changes. Current literature shows that over 40 different architecture-level metrics are available to quantify the encapsulation, but empirical validation of these metrics against changes in a system is not available. In this paper we investigate twelve existing architecture metrics for their ability to quantify the encapsulation of an implemented architecture. We correlate the values of the metrics against the ratio of local change over time using the history of ten open-source systems. In the design of our experiment we ensure that the values of the existing metrics are representative for the time period which is analyzed. Our study shows that one of the suitable architecture metrics can be considered a valid indicator for the degree of encapsulation of systems. We discuss the implications of our findings both for the research into architecture-level metrics and for software architecture evaluations in industry.",1063-6773;10636773,Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4,10.1109/ICSME.2014.43,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976087,,Charge coupled devices;Computer architecture;Correlation;Encapsulation;Measurement;Software;Software architecture,program testing;public domain software;software architecture;software maintenance;software metrics,architecture-level metrics;implemented software architecture encapsulation;maintenance effort;open-source systems;software architecture evaluations;software systems;testing effort,,1,,27,,,,Sept. 29 2014-Oct. 3 2014,,IEEE,IEEE Conferences,,9
An empirical study of bugs in test code,A. Vahabzadeh; A. M. Fard; A. Mesbah,"University of British Columbia, Vancouver, Canada",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,101,110,"Testing aims at detecting (regression) bugs in production code. However, testing code is just as likely to contain bugs as the code it tests. Buggy test cases can silently miss bugs in the production code or loudly ring false alarms when the production code is correct. We present the first empirical study of bugs in test code to characterize their prevalence and root cause categories. We mine the bug repositories and version control systems of 211 Apache Software Foundation (ASF) projects and find 5,556 test-related bug reports. We (1) compare properties of test bugs with production bugs, such as active time and fixing effort needed, and (2) qualitatively study 443 randomly sampled test bug reports in detail and categorize them based on their impact and root causes. Our results show that (1) around half of all the projects had bugs in their test code; (2) the majority of test bugs are false alarms, i.e., test fails while the production code is correct, while a minority of these bugs result in silent horrors, i.e., test passes while the production code is incorrect; (3) incorrect and missing assertions are the dominant root cause of silent horror bugs; (4) semantic (25%), flaky (21%), environment-related (18%) bugs are the dominant root cause categories of false alarms; (5) the majority of false alarm bugs happen in the exercise portion of the tests, and (6) developers contribute more actively to fixing test bugs and test bugs are fixed sooner compared to production bugs. In addition, we evaluate whether existing bug detection tools can detect bugs in test code.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332456,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332456,Bugs;empirical study;test code,Computer bugs;Control systems;Data collection;Data mining;Production;Software;Testing,configuration management;program debugging;program testing,ASF projects;Apache Software Foundation projects;bug detection tools;bug repositories;false alarm bugs;production bugs;production code;randomly sampled test bug reports;root cause categories;silent horror bugs;test code bugs;test-related bug reports;version control systems,,6,,33,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Deterministic dynamic race detection across program versions,S. V. Poluri; M. K. Ramanathan,"Indian Institute of Science, India",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,181,190,"Dynamic race detectors operate by analyzing execution traces of programs to detect races in multithreaded programs. As the thread interleavings influence these traces, the sets of races detected across multiple runs of the detector can vary. This non-determinism without any change in program source and input can reduce programmer confidence in using the detector. From an organizational perspective, a defect needs to be reported consistently until it is fixed. Non-determinism complicates the work flow and the problem is further exacerbated with modifications to the program.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332464,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332464,,Benchmark testing;Detectors;Instruction sets;Performance analysis;Schedules;Synchronization;Transforms,Java;multi-threading;program diagnostics;public domain software;shared memory systems,DJIT+;FastTrack;STABLER;deterministic dynamic race detection;open-source multithreaded Java program;program source;program version;shared memory accesses,,,,46,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
GreenAdvisor: A tool for analyzing the impact of software evolution on energy consumption,K. Aggarwal; A. Hindle; E. Stroulia,"Department of Computing Science, University of Alberta, Edmonton, Canada",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,311,320,"Change-impact analysis, namely _ã–identifying the potential consequences of a change_ãù is an important and well studied problem in software evolution. Any change may potentially affect an application's behaviour, performance, and energy consumption profile. Our previous work demonstrated that changes to the system-call profile of an application correlated with changes to the application's energy-consumption profile. This paper evaluates and describes GreenAdvisor, a first of its kind tool that systematically records and analyzes an application's system calls to predict whether the energy-consumption profile of an application has changed. The GreenAdvisor tool was distributed to numerous software teams, whose members were surveyed about their experience using GreenAdvisor while developing Android applications to examine the energy-consumption impact of selected commits from the teams' projects. GreenAdvisor was evaluated against commits of these teams' projects. The two studies confirm the usefulness of our tool in assisting developers analyze and understand the energy-consumption profile changes of a new version. Based on our study findings, we constructed an improved prediction model to forecast the direction of the change, when a change in the energy-consumption profile is anticipated. This work can potentially be extremely useful to developers who currently have no similar tools.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332477,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332477,Software energy consumption;application software;energy efficiency;software tools,Data mining;Decision making;Energy consumption;Energy measurement;Hardware;Libraries;Software,energy consumption;power aware computing;software maintenance,Android applications;GreenAdvisor tool;application system calls;commits;energy-consumption impact;energy-consumption profile changes;software evolution,,3,,26,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
A decision support system to refactor class cycles,T. D. Oyetoyan; D. S. Cruzes; C. Thurmann-Nielsen,"Computer and Information Science, Norwegian University of Science and Technology, Trondheim, Norway",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,231,240,"Many studies show that real-world systems are riddled with large dependency cycles among software classes. Dependency cycles are claimed to affect quality factors such as testability, extensibility, modifiability, and reusability. Recent studies reveal that most defects are concentrated in classes that are in and near cycles. In this paper, we (1) propose a new metric: IRCRSS based on the Class Reachability Set Size (CRSS) to identify the reduction ratio between the CRSS of a class and its interfaces, and (2) presents a cycle-breaking decision support system (CB-DSS) that implements existing design approaches in combination with class edge contextual data. Evaluations of multiple systems show that (1) the IRCRSS metric can be used to identify fewer classes as candidates for breaking large cycles, thus reducing refactoring effort, and (2) the CB-DSS can assist software engineers to plan restructuring of classes involved in complex dependency cycles.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332469,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332469,CRSS;Dependency cycle;decision support system;refactoring;software quality,Couplings;Decision support systems;Measurement;Software quality;Software systems;Testing,decision support systems;software libraries;software maintenance,CB-DSS;IRCRSS metric;class edge contextual data;class reachability set size;cycle-breaking decision support system;software class cycle refactoring,,2,,37,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Impact assessment for vulnerabilities in open-source software libraries,H. Plate; S. E. Ponta; A. Sabetta,"SAP Labs France, Mougins, France",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,411,420,"Software applications integrate more and more open-source software (OSS) to benefit from code reuse. As a drawback, each vulnerability discovered in bundled OSS may potentially affect the application that includes it. Upon the disclosure of every new vulnerability, the application vendor has to assess whether such vulnerability is exploitable in the particular usage context of the applications, and needs to determine whether customers require an urgent patch containing a non-vulnerable version of the OSS. Unfortunately, current decision making relies mostly on natural-language vulnerability descriptions and expert knowledge, and is therefore difficult, time-consuming, and error-prone. This paper proposes a novel approach to support the impact assessment based on the analysis of code changes introduced by security fixes. We describe our approach using an illustrative example and perform a comparison with both proprietary and open-source state-of-the-art solutions. Finally we report on our experience with a sample application and two industrial development projects.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332492,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332492,,Engines;Java;Libraries;Open source software;Runtime;Security,decision making;public domain software;software libraries,OSS;decision making;natural-language vulnerability description;open-source software library,,2,,6,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
A comparative study on the bug-proneness of different types of code clones,M. Mondal; C. K. Roy; K. A. Schneider,"Department of Computer Science, University of Saskatchewan, Canada",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,91,100,"Code clones are defined to be the exactly or nearly similar code fragments in a software system's code-base. The existing clone related studies reveal that code clones are likely to introduce bugs and inconsistencies in the code-base. However, although there are different types of clones, it is still unknown which types of clones have a higher likeliness of introducing bugs to the software systems and so, should be considered more important for managing with techniques such as refactoring or tracking. With this focus, we performed a study that compared the bug-proneness of the major clone-types: Type 1, Type 2, and Type 3. According to our experimental results on thousands of revisions of seven diverse subject systems, Type 3 clones exhibit the highest bug-proneness among the three clone-types. The bug-proneness of Type 1 clones is the lowest. Also, Type 3 clones have the highest likeliness of being co-changed consistently while experiencing bug-fixing changes. Moreover, the Type 3 clones that experience bug-fixes have a higher possibility of evolving following a Similarity Preserving Change Pattern (SPCP) compared to the bug-fix clones of the other two clone-types. From the experimental results it is clear that Type 3 clones should be given a higher priority than the other two clone-types when making clone management decisions. We believe that our study provides useful implications for ranking clones for refactoring and tracking.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332455,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332455,,Cloning;Computer bugs;Java;Maintenance engineering;Software systems;Terminology,decision making;program debugging;software maintenance;source code (software),SPCP;bug-fixing change;bug-proneness;clone management decision making;clone ranking;code clones;code fragments;refactoring;similarity preserving change pattern;software system code-base;type 1 clone;type 2 clone;type 3 clone,,7,,54,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Practical and accurate pinpointing of configuration errors using static analysis,Z. Dong; A. Andrzejak; K. Shao,"Institute of Computer Science, Heidelberg University, Germany",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,171,180,"Software misconfigurations are responsible for a substantial part of today's system failures, causing about one-quarter of all customer-reported issues. Identifying their root causes can be costly in terms of time and human resources. We present an approach to automatically pinpoint such defects without error reproduction. It uses static analysis to infer the correlation degree between each configuration option and program sites affected by an exception. The only run-time information required by our approach is the stack trace of a failure. This is an essential advantage compared to existing approaches which require to reproduce errors or to provide testing oracles. We evaluate our approach on 29 errors from 4 configurable software programs, namely JChord, Randoop, Hadoop, and Hbase. Our approach can successfully diagnose 27 out of 29 errors. For 20 errors, the failure-inducing configuration option is ranked first.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332463,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332463,Automated debugging;Configuration errors;Static analysis,Accuracy;Computer crashes;Computer science;Correlation;Debugging;Indexes;Software,program diagnostics;program testing;system recovery,Hadoop;Hbase;JChord;Randoop;configuration error pinpointing;correlation degree;failure stack trace;failure-inducing configuration option;program sites;software misconfiguration;static analysis;system failures;testing oracles,,4,,38,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
What are the characteristics of high-rated apps? A case study on free Android Applications,Y. Tian; M. Nagappan; D. Lo; A. E. Hassan,"Singapore Management University, Singapore",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,301,310,"The tremendous rate of growth in the mobile app market over the past few years has attracted many developers to build mobile apps. However, while there is no shortage of stories of how lone developers have made great fortunes from their apps, the majority of developers are struggling to break even. For those struggling developers, knowing the _ã–DNA_ãù (i.e., characteristics) of high-rated apps is the first step towards successful development and evolution of their apps. In this paper, we investigate 28 factors along eight dimensions to understand how high-rated apps are different from low-rated apps. We also investigate what are the most influential factors by applying a random-forest classifier to identify high-rated apps. Through a case study on 1,492 high-rated and low-rated free apps mined from the Google Play store, we find that high-rated apps are statistically significantly different in 17 out of the 28 factors that we considered. Our experiment also shows that the size of an app, the number of promotional images that the app displays on its web store page, and the target SDK version of an app are the most influential factors.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332476,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332476,,Androids;Complexity theory;DNA;Humanoid robots;Libraries;Measurement;Mobile communication,mobile computing;pattern classification,DNA;Google Play store;SDK app version;Web store page;app size;free Android applications;high-rated apps characteristics;low-rated apps;mobile app market;promotional image;random-forest classifier,,13,,48,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Uncovering dependence clusters and linchpin functions,D. Binkley; êÅ. Beszê©des; S. Islam; J. Jêçsz; B. Vancsics,"Loyola University Maryland, Baltimore, USA",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,141,150,"Dependence clusters are (maximal) collections of mutually dependent source code entities according to some dependence relation. Their presence in software complicates many maintenance activities including testing, refactoring, and feature extraction. Despite several studies finding them common in production code, their formation, identification, and overall structure are not well understood, partly because of challenges in approximating true dependences between program entities. Previous research has considered two approximate dependence relations: a fine-grained statement-level relation using control and data dependences from a program's System Dependence Graph and a coarser relation based on function-level control-flow reachability. In principal, the first is more expensive and more precise than the second. Using a collection of twenty programs, we present an empirical investigation of the clusters identified by these two approaches. In support of the analysis, we consider a hybrid cluster type that works at the coarser function-level but is based on the higher-precision statement-level dependences. The three types of clusters are compared based on their slice sets using two clustering metrics. We also perform extensive analysis of the programs to identify linchpin functions - functions primarily responsible for holding a cluster together. Results include evidence that the less expensive, coarser approaches can often be used as effective proxies for the more expensive, finer-grained approaches. Finally, the linchpin analysis shows that linchpin functions can be effectively and automatically identified.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332460,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332460,,Complexity theory;Flow graphs;Maintenance engineering;Measurement;Software maintenance;Testing,feature extraction;program testing;software maintenance;source code (software),coarser function-level;feature extraction;fine-grained statement-level relation;function-level control-flow reachability;linchpin function;program entity;software refactoring;software testing;source code entity;system dependence graph,,,,33,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Challenges for maintenance of PLC-software and its related hardware for automated production systems: Selected industrial Case Studies,B. Vogel-Heuser; J. Fischer; S. Rê_sch; S. Feldmann; S. Ulewicz,"Institute of Automation and Information Systems, Technische Universit&#x00E4;t M&#x00FC;nchen, 85748 Garching b. M&#x00FC;nchen, Germany",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,362,371,"The specific challenges for maintenance of software and its related hardware for the domain of automated Production Systems is discussed. Presenting four industrial case studies from renowned and world market leading German machine and plant manufacturing companies, these challenges and different solution approaches are introduced with a focus on software architectures to support modularity as a basis for maintaining long-living automated Production Systems. Additionally, most critical aspects hindering classical approaches from software engineering to be successful, e.g., modes of operation and fault handling, are discussed. In the last decades, research in the field of software engineering for automated Production Systems (aPS) has been focusing on developing domain specific model-driven engineering approaches supporting the development process, but mostly neglecting the operation, maintenance and re-engineering aspects. However, the success of model-driven engineering in aPS industry has been limited because the effort to introduce model-driven engineering and to change the entire existing legacy software is estimated as too high and the benefit as too low against the background of customer specific solutions expecting a low degree of reuse.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332487,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332487,automated production systems;control software;factory automation;fault handling;modes of operation;software architecture;software maintenance,Automation;IEC Standards;Maintenance engineering;Production systems;Software;Software architecture;Unified modeling language,machinery production industries;production engineering computing;programmable controllers;software architecture;software fault tolerance;software maintenance,German machine and plant manufacturing companies;PLC-software maintenance;aPS industry;automated production systems;customer specific solutions;domain specific model-driven engineering approach;fault handling;industrial case studies;legacy software;software architectures;software engineering;software re-engineering,,3,,23,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
"System specific, source code transformations",G. Santos; N. Anquetil; A. Etien; S. Ducasse; M. T. Valente,"RMoD Team, INRIA Lille Nord Europe, University of Lille, CRIStAL, UMR 9189, Villeneuve d'Ascq, France",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,221,230,"During its lifetime, a software system might undergo a major transformation effort in its structure, for example to migrate to a new architecture or bring some drastic improvements to the system. Particularly in this context, we found evidences that some sequences of code changes are made in a systematic way. These sequences are composed of small code transformations (e.g., create a class, move a method) which are repeatedly applied to groups of related entities (e.g., a class and some of its methods). A typical example consists in the systematic introduction of a Factory design pattern on the classes of a package. We define these sequences as transformation patterns. In this paper, we identify examples of transformation patterns in real world software systems and study their properties: (i) they are specific to a system; (ii) they were applied manually; (iii) they were not always applied to all the software entities which could have been transformed; (iv) they were sometimes complex; and (v) they were not always applied in one shot but over several releases. These results suggest that transformation patterns could benefit from automated support in their application. From this study, we propose as future work to develop a macro recorder, a tool with which a developer records a sequence of code transformations and then automatically applies them in other parts of the system as a customizable, large-scale transformation operator.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332468,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332468,Code Transformation;Rearchitecting;Refactoring Tools;Restructuring;Software Maintenance,Computer architecture;Context;Maintenance engineering;Production facilities;Software systems;Systematics,software maintenance;source code (software),code change sequence;evolution;macro recorder;software system;source code transformation;system specific transformation;transformation operator,,2,,32,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Exploring API method parameter recommendations,M. Asaduzzaman; C. K. Roy; S. Monir; K. A. Schneider,"Department of Computer Science, University of Saskatchewan, Saskatoon, Canada",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,271,280,"A number of techniques have been developed that support method call completion. However, there has been little research on the problem of method parameter completion. In this paper, we first present a study that helps us to understand how developers complete method parameters. Based on our observations, we developed a recommendation technique, called Parc, that collects parameter usage context using a source code localness property that suggests that developers tend to collocate related code fragments. Parc uses previous code examples together with contextual and static type analysis to recommend method parameters. Evaluating our technique against the only available state-of-the-art tool using a number of subject systems and different Java libraries shows that our approach has potential. We also explore the parameter recommendation support provided by the Eclipse Java Development Tools (JDT). Finally, we discuss limitations of our proposed technique and outline future research directions.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332473,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332473,API methods;Code completion;Method parameter recommendations;Recommendations,Arrays;Context;Documentation;Java;Libraries;Receivers;Software,Java;application program interfaces;program diagnostics;programming environments;software libraries;source code (software),API method parameter recommendations;Eclipse Java Development Tools;JDT;Java libraries;Parc;code fragments;contextual analysis;parameter usage context;source code localness property;static type analysis;support method call completion,,3,,30,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Is this code written in English? A study of the natural language of comments and identifiers in practice,T. Pawelka; E. Juergens,"Technische Universit&#x00E4;t M&#x00FC;nchen, Germany",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,401,410,"Comments and identifiers are the main source of documentation of source-code and are therefore an integral part of the development and the maintenance of a program. As English is the world language, most comments and identifiers are written in English. However, if they are in any other language, a developer without knowledge of this language will almost perceive the code to be undocumented or even obfuscated. In absence of industrial data, academia is not aware of the extent of the problem of non-English comments and identifiers in practice. In this paper, we propose an approach for the language identification of source-code comments and identifiers. With the approach, a large-scale study has been conducted of the natural language of source-code comments and identifiers, analyzing multiple open-source and industry systems. The results show that a significant amount of the industry projects contain comments and identifiers in more than one language, whereas none of the analyzed open-source systems has this problem.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332491,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332491,,Documentation;Industries;Maintenance engineering;Natural languages;Open source software;Programming;Radiation detectors,natural language processing;public domain software;software maintenance;source code (software),English;identifiers;industry project;industry system;language identification;natural language;open-source system;program development;program maintenance;source-code comments;source-code documentation,,1,,20,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Four eyes are better than two: On the impact of code reviews on software quality,G. Bavota; B. Russo,"Faculty of Computer Science, Free University of Bozen-Bolzano, Italy",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,81,90,"Code review is advocated as one of the best practices to improve software quality and reduce the likelihood of introducing defects during code change activities. Recent research has shown how code components having a high review coverage (i.e., a high proportion of reviewed changes) tend to be less involved in post-release fixing activities. Yet the relationship between code review and bug introduction or the overall software quality is still largely unexplored.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332454,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332454,Code Review;Empirical Studies;Mining Software Repositories,Androids;Computer bugs;Couplings;Data mining;History;Humanoid robots;Software quality,software quality;source code (software),bug introduction;code change activities;code components;code review;postrelease fixing activities;review coverage;software quality,,4,,34,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Investigating naming convention adherence in Java references,S. Butler; M. Wermelinger; Y. Yu,"Computing and Communications Department, The Open University, Walton Hall, Milton Keynes MK7 6AA, United Kingdom",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,41,50,"Naming conventions can help the readability and comprehension of code, and thus the onboarding of new developers. Conventions also provide cues that help developers and tools extract information from identifier names to support software maintenance. Tools exist to automatically check naming conventions but they are often limited to simple checks, e.g. regarding typography. The adherence to more elaborate conventions, such as the use of noun and verbal phrases in names, is not checked. We present Nominal, a naming convention checking library for Java that allows the declarative specification of conventions regarding typography and the use of abbreviations and phrases. To test Nominal, and to investigate the extent to which developers follow conventions, we extract 3.5 million reference - field, formal argument and local variable - name declarations from 60 FLOSS projects and determine their adherence to two well-known Java naming convention guidelines that give developers scope to choose a variety of forms of name, and sometimes offer conflicting advice. We found developers largely follow naming conventions, but adherence to specific conventions varies widely.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332450,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332450,,Ciphers;Data mining;Engines;Guidelines;Java;Software;Terminology,Java;formal specification;naming services;software libraries;software maintenance;source code (software),FLOSS projects;Java references;Nominal;abbreviation;code comprehension;code readability;convention declarative specification;field;formal argument;identifier names;local variable;name declarations;naming convention adherence;naming convention checking library;phrase;software maintenance;typography,,2,,23,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Does software modernization deliver what it aimed for? A post modernization analysis of five software modernization case studies,R. Khadka; P. Shrestha; B. Klein; A. Saeidi; J. Hage; S. Jansen; E. van Dis; M. Bruntink,"Utrecht University, The Netherlands",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,477,486,"Software modernization has been extensively researched, primarily focusing on observing the associated phenomena, and providing technical solutions to facilitate the modernization process. Software modernization is claimed to be successful when the modernization is completed using those technical solutions. Very limited research, if any, is reported with an aim at documenting the post-modernization impacts, i.e., whether any of the pre-modernization business goals are in fact achieved after modernization. In this research, we attempt to address this relative absence of empirical study through five retrospective software modernization case studies. We use an explanatory case study approach to document the pre-modernization business goals, and to decide whether those goals have been achieved. The intended benefits for each of the five cases we considered were all (partially) met, and in most cases fully. Moreover, many cases exhibited a number of unintended benefits, and some reported detrimental effects of modernization.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332499,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332499,,Companies;Interviews;Maintenance engineering;Software maintenance;Software systems,software engineering;systems re-engineering,post modernization analysis;post-modernization impact documentation;premodernization business goals;software modernization;technical solutions,,,,53,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Investigating code review quality: Do people and participation matter?,O. Kononenko; O. Baysal; L. Guerrouj; Y. Cao; M. W. Godfrey,"David R. Cheriton School of Computer Science, University of Waterloo, Canada",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,111,120,"Code review is an essential element of any mature software development project; it aims at evaluating code contributions submitted by developers. In principle, code review should improve the quality of code changes (patches) before they are committed to the project's master repository. In practice, bugs are sometimes unwittingly introduced during this process. In this paper, we report on an empirical study investigating code review quality for Mozilla, a large open-source project. We explore the relationships between the reviewers' code inspections and a set of factors, both personal and social in nature, that might affect the quality of such inspections. We applied the SZZ algorithm to detect bug-inducing changes that were then linked to the code review information extracted from the issue tracking system. We found that 54% of the reviewed changes introduced bugs in the code. Our findings also showed that both personal metrics, such as reviewer workload and experience, and participation metrics, such as the number of involved developers, are associated with the quality of the code review process.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332457,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332457,Code review;Mozilla;bug-inducing changes;code review quality;empirical study;mining software repositories,Androids;Computer bugs;Control systems;Data mining;Electronic mail;Humanoid robots;Software,program debugging;project management;public domain software;software development management;software metrics;software quality;software reviews,Mozilla;SZZ algorithm;bug-inducing change detection;code change quality;code review process;code review quality;open-source project;personal metrics;project master repository;reviewer code inspections;reviewer workload;software development project,,7,,43,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Program specialization and verification using file format specifications,R. K. Medicherla; R. Komondoor; S. Narendran,"TCS Limited, Bangalore, India",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,191,200,"Programs that process data that reside in files are widely used in varied domains, such as banking, healthcare, and web-traffic analysis. Precise static analysis of these programs in the context of software transformation and verification tasks is a challenging problem. Our key insight is that static analysis of file-processing programs can be made more useful if knowledge of the input file formats of these programs is made available to the analysis. We instantiate this idea to solve two practical problems - specializing the code of a program to a given _ã–restricted_ãù input file format, and verifying if a program _ã–conforms_ãù to a given input file format. We then discuss an implementation of our approach, and also empirical results on a set of real and realistic programs. The results are very encouraging in the terms of both scalability as well as precision of the approach.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332465,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332465,,Automata;Banking;Context;Layout;Medical services;Software;Standards,program diagnostics;program verification,file format specification;file-processing program;program specialization;program verification;software transformation;software verification;static analysis,,,,41,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
On the role of developer's scattered changes in bug prediction,D. Di Nucci; F. Palomba; S. Siravo; G. Bavota; R. Oliveto; A. De Lucia,"University of Salerno, Fisciano, Italy",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,241,250,"The importance of human-related factors in the introduction of bugs has recently been the subject of a number of empirical studies. However, such factors have not been captured yet in bug prediction models which simply exploit product metrics or process metrics based on the number and type of changes or on the number of developers working on a software component. Previous studies have demonstrated that focused developers are less prone to introduce defects than non focused developers. According to this observation, software components changed by focused developers should also be less error prone than software components changed by less focused developers. In this paper we capture this observation by measuring the structural and semantic scattering of changes performed by the developers working on a software component and use these two measures to build a bug prediction model. Such a model has been evaluated on five open source systems and compared with two competitive prediction models: the first exploits the number of developers working on a code component in a given time period as predictor, while the second is based on the concept of code change entropy. The achieved results show the superiority of our model with respect to the two competitive approaches, and the complementarity of the defined scattering measures with respect to standard predictors commonly used in the literature.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332470,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332470,,Complexity theory;Computer bugs;Entropy;Measurement;Predictive models;Scattering;Software,human factors;program debugging;public domain software,bug prediction model;code change entropy;human-related factor;open source system;process metrics;product metrics;semantic scattering;software component,,1,,43,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Software history under the lens: A study on why and how developers examine it,M. Codoban; S. S. Ragavan; D. Dig; B. Bailey,"Oregon State University, USA",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,1,10,"Despite software history being indispensable for developers, there is little empirical knowledge about how they examine software history. Without such knowledge, researchers and tool builders are in danger of making wrong assumptions and building inadequate tools. In this paper we present an in-depth empirical study about the motivations developers have for examining software history, the strategies they use, and the challenges they encounter. To learn these, we interviewed 14 experienced developers from industry, and then extended our findings by surveying 217 developers. We found that history does not begin with the latest commit but with uncommitted changes. Moreover, we found that developers had different motivations for examining recent and old history. Based on these findings we propose 3-LENS HISTORY, a novel unified model for reasoning about software history.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332446,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332446,human aspects of software evolution;software change management;software history;user studies,Context;Encoding;History;Industries;Interviews;Lenses;Software,human factors;software houses;software management,software change management;software history;software industry,,5,,64,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Forked and integrated variants in an open-source firmware project,Å_. St„Ñnciulescu; S. Schulze; A. W„ósowski,"IT University of Copenhagen, Denmark",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,151,160,"Code cloning has been reported both on small (code fragments) and large (entire projects) scale. Cloning-in-the-large, or forking, is gaining ground as a reuse mechanism thanks to availability of better tools for maintaining forked project variants, hereunder distributed version control systems and interactive source management platforms such as Github. We study advantages and disadvantages of forking using the case of Marlin, an open source firmware for 3D printers. We find that many problems and advantages of cloning do translate to forking. Interestingly, the Marlin community uses both forking and integrated variability management (conditional compilation) to create variants and features. Thus, studying it increases our understanding of the choice between integrated and clone-based variant management. It also allows us to observe mechanisms governing source code maturation, in particular when, why and how feature implementations are migrated from forks to the main integrated platform. We believe that this understanding will ultimately help development of tools mixing clone-based and integrated variant management, combining the advantages of both.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332461,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332461,,Cloning;Computer architecture;Context;Control systems;Maintenance engineering;Printers;Three-dimensional displays,configuration management;firmware;interactive systems;project management;public domain software;source code (software);three-dimensional printing,3D printers;Marlin;clone-based variant management;code cloning;code fragment;conditional compilation;distributed version control systems;forked project variant maintenance;integrated variability management;integrated variant;interactive source management platform;open-source firmware project;source code maturation,,4,,36,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
How can i improve my app? Classifying user reviews for software maintenance and evolution,S. Panichella; A. Di Sorbo; E. Guzman; C. A. Visaggio; G. Canfora; H. C. Gall,"University of Zurich, Switzerland",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,281,290,"App Stores, such as Google Play or the Apple Store, allow users to provide feedback on apps by posting review comments and giving star ratings. These platforms constitute a useful electronic mean in which application developers and users can productively exchange information about apps. Previous research showed that users feedback contains usage scenarios, bug reports and feature requests, that can help app developers to accomplish software maintenance and evolution tasks. However, in the case of the most popular apps, the large amount of received feedback, its unstructured nature and varying quality can make the identification of useful user feedback a very challenging task. In this paper we present a taxonomy to classify app reviews into categories relevant to software maintenance and evolution, as well as an approach that merges three techniques: (1) Natural Language Processing, (2) Text Analysis and (3) Sentiment Analysis to automatically classify app reviews into the proposed categories. We show that the combined use of these techniques allows to achieve better results (a precision of 75% and a recall of 74%) than results obtained using each technique individually (precision of 70% and a recall of 67%).",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332474,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332474,Mobile Applications;Natural Language Processing;Sentiment Analysis;Text classification;User Reviews,Feature extraction;Maintenance engineering;Mobile communication;Natural language processing;Software maintenance;Taxonomy;Text analysis,natural language processing;pattern classification;software maintenance;text analysis,app review classification;app stores;natural language processing;review comments;sentiment analysis;software evolution;software maintenance;star ratings;text analysis;user feedback identification;user review classification,,27,1,39,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Developing a model of loop actions by mining loop characteristics from a large code corpus,X. Wang; L. Pollock; K. Vijay-Shanker,"Computer and Information Sciences, University of Delaware, Newark, 19716 USA",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,51,60,"Some high level algorithmic steps require more than one statement to implement, but are not large enough to be a method on their own. Specifically, many algorithmic steps (e.g., count, compare pairs of elements, find the maximum) are implemented as loop structures, which lack the higher level abstraction of the action being performed, and can negatively affect both human readers and automatic tools. Additionally, in a study of 14,317 projects, we found that less than 20% of loops are documented to help readers. In this paper, we present a novel automatic approach to identify the high level action implemented by a given loop. We leverage the available, large source of high-quality open source projects to mine loop characteristics and develop an action identification model. We use the model and feature vectors extracted from loop code to automatically identify the high level actions implemented by loops. We have evaluated the accuracy of the loop action identification and coverage of the model over 7159 open source programs. The results show great promise for this approach to automatically insert internal comments and provide additional higher level naming for loop actions to be used by tools such as code search.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332451,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332451,abstraction;documentation generation;mining code patterns,Computational modeling;Feature extraction;Generators;Java;Pragmatics;Syntactics;Terminology,data mining;feature extraction;program diagnostics;public domain software;software tools,action identification model;automatic tools;code search;feature vector extraction;high level algorithmic steps;high-quality open source projects;human readers;large code corpus;loop action identification;loop action model;loop characteristics mining;loop code;loop structures;open source programs,,3,,39,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Reverse engineering a visual age application,H. M. Sneed; C. Verhoef,"Technical University of Dresden, Germany",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,487,496,"This paper is an industrial case study of how a VisualAge application system on an IBM mainframe was reverse engineered into a system reference repository. The starting point was the code fragments generated by the VisualAge interactive development tool. The results of the reverse engineering process were a use case documentation, a module documentation and a system reference repository. In these documents, the names of the data and functions were extended to be more understandable. The process was in the end fully automated and took three months to implement. The resulting documentation is now being used as a basis for re-implementing the system in Java.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332500,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332500,Data Dictionary;Post Documentation;Pseudo Code;Re-implementing Code;Renaming variables;Repository;Reverse Engineering;Use cases;VisualAge,Computer architecture;Documentation;Government;Java;Reverse engineering;Software;User interfaces,Java;interactive systems;programming environments;reverse engineering,IBM mainframe;Java;VisualAge application system;VisualAge interactive development tool;code fragments;module documentation;reverse engineering;system reference repository;use case documentation,,1,,32,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Inter-smell relations in industrial and open source systems: A replication and comparative analysis,A. Yamashita; M. Zanoni; F. A. Fontana; B. Walter,"Department of Information Technology, Oslo and Akershus University College of Applied Sciences, Norway",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,121,130,"The presence of anti-patterns and code smells can affect adversely software evolution and quality. Recent work has shown that code smells that appear together in the same file (i.e., collocated smells) can interact with each other, leading to various types of maintenance issues and/or to the intensification of negative effects. It has also been found that code smell interactions can occur across coupled files (i.e., coupled smells), with comparable negative effects as the interaction of same-file (collocated) smells. Different inter-smell relations have been described in previous work, yet only few studies have evaluated them empirically. This study attempts to replicate the findings from previous work on inter-smell relations by analyzing larger systems, and by including both industrial and open source ones. We also include the analysis of coupled smells in addition to collocated smells, to achieve a more complete picture of inter-smell relations. Our results suggest that if coupled smells are not considered, one may risk increasing the number of false negatives when analysing inter-smells. A major finding is that patterns of inter-smell relations vary between open source and industrial systems, suggesting that contextual variables should be considered in further studies on code smells.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332458,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332458,bad smells;code smells;inter-smell relations,Correlation;Maintenance engineering;Measurement;Principal component analysis;Software;Surgery;Yttrium,public domain software;software maintenance;software performance evaluation;software quality,code smell interaction;inter-smell relation;open source system;software evolution;software maintenance;software quality,,4,,41,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
An empirical study on the handling of crash reports in a large software company: An experience report,A. Maiga; A. Hamou-Lhadj; M. Nayrolles; K. Koochekian Sabor; A. Larsson,"SBA Research Lab, ECE, Concordia University, Montreal, QC, Canada",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,342,351,"In this paper, we report on an empirical study we have conducted at Ericsson to understand the handling of crash reports (CRs). The study was performed on a dataset of CRs spanning over two years of activities on one of Ericsson's largest systems (+4 Million LOC). CRs at Ericsson are divided into two types: Internal and External. Internal CRs are reported within the organization after the integration and system testing phase. External CRs are submitted by customers and caused mainly by field failures. We examine the proportion and severity of internal CRs and that of external CRs. A large number of external (and severe) CRs could indicate flaws in the testing phase. Failing to react quickly to external CRs, on the other hand, may expose Ericsson to fines and penalties due to the Working Level Agreements (WLA) that Ericsson has with its customers. Moreover, we contrast the time it takes to handle each type of CRs with the dual aim to understand the similarities and differences as well as the factors that impact the handling of each type of CRs. Our results show that (a) it takes more time to fix external CRs compared to internal CRs, (b) the severity attribute is used inconsistently through organizational units, (c) assignment time of internal CRs is less than that of external CRs, (d) More than 50% of CRs are not answered within the organization's fixing time requirements defined in WLA.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332485,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332485,Empirical Studies;Industrial Systems;Mining Crash Reports;Software Maintenance,Companies;Computer crashes;Data mining;Maintenance engineering;Software;Testing,DP industry;organisational aspects;program testing;software maintenance;system recovery,CR;Ericsson;WLA;crash report handling;external CR;field failures;internal CR;maintenance activities;organizational units;severity attribute;software company;system testing phase;working level agreements,,,,27,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
An empirical evaluation of ant build maintenance using Formiga,R. Hardt; E. V. Munson,"Department of Computer Science, University of Wisconsin-Eau Claire, USA",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,201,210,"As a software project evolves, so does its build system. Significant effort is necessary to maintain the build system to cope with this evolution, in part because changes to source code often require parallel changes in the build system. Our tool, Formiga, is a build maintenance and dependency discovery tool for the Ant build system. Formiga's primary uses are to automate build changes as the source code is updated, to identify the build dependencies within a software project, and to assist with build refactoring. Formiga is implemented as an IDE plugin, which allows it to recognize when project resources are updated and automatically update the build system accordingly. A controlled experiment was conducted to assess Formiga's ability to assist developers with build maintenance. Subjects responded to scenarios in which various forms of build maintenance and/or knowledge about deliverables and their contents were requested. Subjects completed eleven different build maintenance tasks in both an experimental condition using Formiga and a control condition using only conventional IDE services. The study used a balanced design relative to both task order and use of Formiga. This design also ensured that order balancing was not confounded with the subjects' level of Ant expertise. Formiga was shown to significantly reduce the time required to perform build maintenance while increasing the correctness with which it can be performed for both novice and experienced developers.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332466,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332466,,Complexity theory;Computer science;Electrical engineering;Libraries;Maintenance engineering;Runtime;Software,project management;software development management;software maintenance;source code (software),Ant build maintenance;Ant build system;Ant expertise;Formiga;IDE plugin;IDE services;build refactoring;control condition;dependency discovery tool;software project;source code,,3,,13,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
How do developers react to API evolution? The Pharo ecosystem case,A. Hora; R. Robbes; N. Anquetil; A. Etien; S. Ducasse; M. T. Valente,"ASERG Group, Department of Computer Science (DCC), Federal University of Minas Gerais, Brazil",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,251,260,"Software engineering research now considers that no system is an island, but it is part of an ecosystem involving other systems, developers, users, hardware, ... When one system (e.g., a framework) evolves, its clients often need to adapt. Client developers might need to adapt to functionalities, client systems might need to be adapted to a new API, client users might need to adapt to a new User Interface. The consequences of such changes are yet unclear, what proportion of the ecosystem might be expected to react, how long might it take for a change to diffuse in the ecosystem, do all clients react in the same way? This paper reports on an exploratory study aimed at observing API evolution and its impact on a large-scale software ecosystem, Pharo, which has about 3,600 distinct systems, more than 2,800 contributors, and six years of evolution. We analyze 118 API changes and answer research questions regarding the magnitude, duration, extension, and consistency of such changes in the ecosystem. The results of this study help to characterize the impact of API evolution in large software ecosystems, and provide the basis to better understand how such impact can be alleviated.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332471,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332471,,Association rules;Computer science;Context;Ecosystems;History;Open source software,application program interfaces;software engineering;user interfaces,API evolution;Pharo ecosystem case;software ecosystems;software engineering research;user interface,,9,,37,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Do automatic refactorings improve maintainability? An industrial case study,G. SzÅ«ke; C. Nagy; P. HegedÅ±s; R. Ferenc; T. Gyimê_thy,"Department of Software Engineering, University of Szeged, Hungary",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,429,438,"Refactoring is often treated as the main remedy against the unavoidable code erosion happening during software evolution. Studies show that refactoring is indeed an elemental part of the developers' arsenal. However, empirical studies about the impact of refactorings on software maintainability still did not reach a consensus. Moreover, most of these empirical investigations are carried out on open-source projects where distinguishing refactoring operations from other development activities is a challenge in itself. We had a chance to work together with several software development companies in a project where they got extra budget to improve their source code by performing refactoring operations. Taking advantage of this controlled environment, we collected a large amount of data during a refactoring phase where the developers used a (semi)automatic refactoring tool. By measuring the maintainability of the involved subject systems before and after the refactorings, we got valuable insights into the effect of these refactorings on large-scale industrial projects. All but one company, who applied a special refactoring strategy, achieved a maintainability improvement at the end of the refactoring phase, but even that one company suffered from the negative impact of only one type of refactoring.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332494,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332494,ISO/IEC 25010;automatic refactoring;coding issues;software maintainability,Companies;Complexity theory;Encoding;Measurement;Object oriented modeling;Software systems,DP industry;project management;public domain software;software maintenance;source code (software),automatic refactoring;code erosion;industrial projects;open-source projects;software development companies;software evolution;software maintainability;source code,,1,,33,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
To fix or to learn? How production bias affects developers' information foraging during debugging,D. Piorkowski; S. D. Fleming; C. Scaffidi; M. Burnett; I. Kwan; A. Z. Henley; J. Macbeth; C. Hill; A. Horvath,"Oregon State University, Corvallis, USA",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,11,20,"Developers performing maintenance activities must balance their efforts to learn the code vs. their efforts to actually change it. This balancing act is consistent with the _ã–production bias_ãù that, according to Carroll's minimalist learning theory, generally affects software users during everyday tasks. This suggests that developers' focus on efficiency should have marked effects on how they forage for the information they think they need to fix bugs. To investigate how developers balance fixing versus learning during debugging, we conducted the first empirical investigation of the interplay between production bias and information foraging. Our theory-based study involved 11 participants: half tasked with fixing a bug, and half tasked with learning enough to help someone else fix it. Despite the subtlety of difference between their tasks, participants foraged remarkably differently-making foraging decisions from different types of _ã–patches,_ãù with different types of information, and succeeding with different foraging tactics.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332447,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332447,Debugging;information foraging;theory meets tools,Debugging;Encoding;Interviews;Maintenance engineering;Navigation;Production;Software,program debugging;software maintenance,Carroll minimalist learning theory;bug fixing;debugging;developer information foraging;maintenance activities;production bias,,3,,46,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Towards automating dynamic analysis for behavioral design pattern detection,A. De Lucia; V. Deufemia; C. Gravino; M. Risi,"Department of Management and Information Technology, University of Salerno, Fisciano, Italy",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,161,170,"The detection of behavioral design patterns is more accurate when a dynamic analysis is performed on the candidate instances identified statically. Such a dynamic analysis requires the monitoring of the candidate instances at run-time through the execution of a set of test cases. However, the definition of such test cases is a time-consuming task if performed manually, even more, when the number of candidate instances is high and they include many false positives. In this paper we present the results of an empirical study aiming at assessing the effectiveness of dynamic analysis based on automatically generated test cases in behavioral design pattern detection. The study considered three behavioral design patterns, namely State, Strategy, and Observer, and three publicly available software systems, namely JHotDraw 5.1, QuickUML 2001, and MapperXML 1.9.7. The results show that dynamic analysis based on automatically generated test cases improves the precision of design pattern detection tools based on static analysis only. As expected, this improvement in precision is achieved at the expenses of recall, so we also compared the results achieved with automatically generated test cases with the more expensive but also more accurate results achieved with manually built test cases. The results of this analysis allowed us to highlight costs and benefits of automating dynamic analysis for design pattern detection.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332462,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332462,Dynamic analysis;design pattern detection;test case generation,Data mining;Instruments;Java;Monitoring;Runtime;Software systems,Unified Modeling Language;XML;object-oriented programming;program diagnostics;system monitoring,JHotDraw 5.1;MapperXML 1.9.7;QuickUML 2001;automating dynamic analysis;behavioral design pattern detection;static analysis,,,,39,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Web usage patterns of developers,C. S. Corley; F. Lois; S. Quezada,"ABB Corporate Research, Raleigh, NC, USA",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,381,390,"Developers often rely on the web-based tools for troubleshooting, collaboration, issue tracking, code reviewing, documentation viewing, and a myriad of other uses. Developers also use the web for non-development purposes, such as reading news or social media. In this paper we explore whether web usage is detriment to a developer's focus on work from a sample over 150 developers. Additionally, we investigate if highly-focused developers use the web differently than other developers. Our qualitative findings suggest highly-focused developers use the web differently, but we are unable to predict a developer's focused based on web usage alone. Further quantitative findings suggest that web usage does not have a negative impact on a developer's focus.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332489,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332489,developer focus;interruptions;personal software process;web activity,Blogs;Buildings;Collaboration;Debugging;Encoding;Heating;Software,Internet;programming environments;software engineering,Web usage pattern;Web-based tool;code reviewing;documentation viewing;troubleshooting,,1,,19,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
User reviews matter! Tracking crowdsourced reviews to support evolution of successful apps,F. Palomba; M. Linares-Vêçsquez; G. Bavota; R. Oliveto; M. Di Penta; D. Poshyvanyk; A. De Lucia,"University of Salerno, Fisciano, Italy",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,291,300,"Nowadays software applications, and especially mobile apps, undergo frequent release updates through app stores. After installing/updating apps, users can post reviews and provide ratings, expressing their level of satisfaction with apps, and possibly pointing out bugs or desired features. In this paper we show-by performing a study on 100 Android apps-how developers addressing user reviews increase their app's success in terms of ratings. Specifically, we devise an approach, named CRISTAL, for tracing informative crowd reviews onto source code changes, and for monitoring the extent to which developers accommodate crowd requests and follow-up user reactions as reflected in their ratings. The results indicate that developers implementing user reviews are rewarded in terms of ratings. This poses the need for specialized recommendation systems aimed at analyzing informative crowd reviews and prioritizing feedback to be satisfied in order to increase the apps success.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332475,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332475,,Androids;Entropy;Feature extraction;Humanoid robots;Joining processes;Monitoring;Planning,mobile computing;recommender systems;source code (software),Android apps;CRISTAL;app stores;crowd request;crowdsourced review tracking;informative crowd review tracing;mobile apps;ratings;source code change;specialized recommendation systems;user reaction;user review,,15,,38,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Delta extraction: An abstraction technique to comprehend why two objects could be related,N. Nitta; T. Matsuoka,"Graduate School of Natural Science, Konan University, Kobe, Japan",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,61,70,"In an execution of a large scale program, even a simple observable behavior may be generated by a wide range of the source code. To comprehend how such a behavior is implemented in the code, a debugger would be helpful. However, when using a debugger, developers often encounter several types of cumbersome tasks and are often confused by the huge and complicated runtime information. To support such a debugger-based comprehension task, we propose an abstraction technique of runtime information, named delta, and present a delta extraction and visualization tool. Basically, a delta is defined for two linked objects in an object-oriented program's execution. It intuitively represents the reason why these objects could be related in the execution, and it can hide the details of how these objects were related. We have conducted experiments on four subject tasks from two real-world systems to evaluate how appropriately an extracted delta can answer the `why' question and how long the tool can reduce the working time to answer the question. The results show that each delta can successfully answer the question and a tens-of-minutes to one-hour debugger-based task can be reduced by extracting a delta.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332452,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332452,back-in-time debugging;debugger-based program comprehension;dynamic analysis;trace compression,Containers;Context;Debugging;Electronic mail;Java;Runtime;Visualization,object-oriented programming;program debugging,delta extraction;object-oriented program execution;source code;visualization tool,,1,,18,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Evaluating clone detection tools with BigCloneBench,J. Svajlenko; C. K. Roy,"Department of Computer Science, University of Saskatchewan, Canada",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,131,140,"Many clone detection tools have been proposed in the literature. However, our knowledge of their performance in real software systems is limited, particularly their recall. In this paper, we use our big data clone benchmark, BigCloneBench, to evaluate the recall of ten clone detection tools. BigCloneBench is a collection of eight million validated clones within IJaDataset-2.0, a big data software repository containing 25,000 open-source Java systems. BigCloneBench contains both intra-project and inter-project clones of the four primary clone types. We use this benchmark to evaluate the recall of the tools per clone type and across the entire range of clone syntactical similarity. We evaluate the tools for both single-system and cross-project detection scenarios. Using multiple clone-matching metrics, we evaluate the quality of the tools' reporting of the benchmark clones with respect to refactoring and automatic clone analysis use-cases. We compare these real-world results against our Mutation and Injection Framework, a synthetic benchmark, to reveal deeper understanding of the tools. We found that the tools have strong recall for Type-1 and Type-2 clones, as well as Type-3 clones with high syntactical similarity. The tools have weaker detection of clones with lower syntactical similarity.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332459,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332459,,Benchmark testing;Big data;Cloning;Data mining;Java;Software systems,Big Data;Java;software maintenance;software performance evaluation;source code (software),Big data software repository;BigCloneBench;automatic clone analysis;clone detection tool;clone syntactical similarity;multiple clone-matching metrics;open-source Java system;software refactoring,,10,,31,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
How developers detect and fix performance bottlenecks in Android apps,M. Linares-Vêçsquez; C. Vendome; Q. Luo; D. Poshyvanyk,"The College of William and Mary, Williamsburg, VA, USA",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,352,361,"Performance of rapidly evolving mobile apps is one of the top concerns for users and developers nowadays. Despite the efforts of researchers and mobile API designers to provide developers with guidelines and best practices for improving the performance of mobile apps, performance bottlenecks are still a significant and frequent complaint that impacts the ratings and apps' chances for success. However, little research has been done into understanding actual developers' practices for detecting and fixing performance bottlenecks in mobile apps. In this paper, we present the results of an empirical study aimed at studying and understanding these practices by surveying 485 open source Android app and library developers, and manually analyzing performance bugs and fixes in their app repositories hosted on GitHub. The paper categorizes actual practices and tools used by real developers while dealing with performance issues. In general, our findings indicate that developers heavily rely on user reviews and manual execution of the apps for detecting performance bugs. While developers also use available tools to detect performance bottlenecks, these tools are mostly for profiling and do not help in detecting and fixing performance issues automatically.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332486,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332486,Android;Bottlenecks;Developers;Performance,Androids;Computer bugs;Humanoid robots;Manuals;Mobile communication;Smart phones;Testing,Android (operating system);application program interfaces;mobile computing;software performance evaluation,GitHub;app repositories;library developers;mobile API designers;mobile apps;open source Android app;performance bottleneck detection;performance bugs;user reviews,,6,,68,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Scripting parametric refactorings in Java to retrofit design patterns,J. Kim; D. Batory; D. Dig,"University of Texas at Austin, 78712, USA",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,211,220,"Retrofitting design patterns into a program by hand is tedious and error-prone. A programmer must distinguish refactorings that are provided by an Integrated Development Environment (IDE) from those that must be realized manually, determine a precise sequence of refactorings to apply, and perform this sequence repetitively to a laborious degree. We designed, implemented, and evaluated Reflective Refactoring (R<sup>2</sup>), a Java package to automate the creation of classical design patterns (Visitor, Abstract Factory, etc.), their inverses, and variants. We encoded 18 out of 23 Gang-of-Four design patterns as R<sup>2</sup> scripts and explain why the remaining are inappropriate for refactoring engines. We evaluate the productivity and scalability of R<sup>2</sup> with a case study of 6 real-world applications. In one case, R<sup>2</sup> automatically created a Visitor with 276 visit methods by invoking 554 Eclipse refactorings in 10 minutes - an achievement that could not be done manually. R<sup>2</sup> also sheds light on why refactoring correctness, expressiveness, and speed are critical issues for scripting in next-generation refactoring engines.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332467,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332467,,DVD;Graphics;Manuals,Java;object-oriented methods;programming environments;software maintenance,Eclipse refactoring;IDE;Java;R<sup>2</sup>;abstract factory;design pattern retrofitting;integrated development environment;next-generation refactoring engine;parametric refactoring scripting;refactoring correctness;refactoring expressiveness;refactoring speed;reflective refactoring;time 10 min;visitor,,2,,64,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Who should review this change?: Putting text and file location analyses together for more accurate recommendations,X. Xia; D. Lo; X. Wang; X. Yang,"College of Computer Science and Technology, Zhejiang University, Hangzhou, China",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,261,270,"Software code review is a process of developers inspecting new code changes made by others, to evaluate their quality and identify and fix defects, before integrating them to the main branch of a version control system. Modern Code Review (MCR), a lightweight and tool-based variant of conventional code review, is widely adopted in both open source and proprietary software projects. One challenge that impacts MCR is the assignment of appropriate developers to review a code change. Considering that there could be hundreds of potential code reviewers in a software project, picking suitable reviewers is not a straightforward task. A prior study by Thongtanunam et al. showed that the difficulty in selecting suitable reviewers may delay the review process by an average of 12 days. In this paper, to address the challenge of assigning suitable reviewers to changes, we propose a hybrid and incremental approach Tie which utilizes the advantages of both Text mIning and a filE location-based approach. To do this, Tie integrates an incremental text mining model which analyzes the textual contents in a review request, and a similarity model which measures the similarity of changed file paths and reviewed file paths. We perform a large-scale experiment on four open source projects, namely Android, OpenStack, QT, and LibreOffice, containing a total of 42,045 reviews. The experimental results show that on average Tie can achieve top-1, top-5, and top-10 accuracies, and Mean Reciprocal Rank (MRR) of 0.52, 0.79, 0.85, and 0.64 for the four projects, which improves the state-of-the-art approach RevFinder, proposed by Thongtanunam et al., by 61%, 23%, 8%, and 37%, respectively.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332472,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332472,Modern Code Review;Path Similarity;Recommendation System;Text Mining,Accuracy;Analytical models;Computational modeling;Control systems;Feature extraction;Software;Text mining,configuration management;data mining;public domain software;text analysis,Android;LibreOffice;MCR;MRR;OpenStack;QT;TIE;filE location-based approach;mean reciprocal rank;modern code review;open source;software code review;software project;text mining model;textual content analysis;version control system,,6,,36,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
An empirical evaluation of the effectiveness of inspection scenarios developed from a defect repository,K. Kasubuchi; S. Morisaki; A. Yoshida; C. Ogawa,"Research and Development Center, SCREEN Holdings Co., LTD, Fushimi, Kyoto, Japan",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,439,448,"Abstracting and summarizing high-severity defects detected during inspections of previous software versions could lead to effective inspection scenarios in a subsequent version in software maintenance and evolution. We conducted an empirical evaluation of 456 defects detected from the requirement specification inspections conducted during the development of industrial software. The defects were collected from an earlier version, which included 59 high-severity defects, and from a later version, which included 48 high-severity defects. The results of the evaluation showed that nine defect types and their corresponding inspection scenarios were obtained by abstracting and summarizing 45 defects in the earlier version. The results of the evaluation also showed that 46 of the high-severity defects in the later version could be potentially detected using the obtained inspection scenarios. The study also investigated which inspection scenarios can be obtained by the checklist proposed in the value-based review (VBR). It was difficult to obtain five of the inspection scenarios using the VBR checklist. Furthermore, to investigate the effectiveness of cluster analysis for inspection scenario development, the 59 high-severity defects in the earlier version were clustered into similar defect groups by a clustering algorithm. The results indicated that cluster analysis can be a guide for selecting similar defects and help in the tasks of abstracting and summarizing defects.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332495,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332495,Software inspection;defect abstraction;prioritizing inspection scenarios,Inspection;Research and development;Software maintenance;Stakeholders;Taxonomy;Yttrium,formal specification;inspection;pattern clustering;program diagnostics;software maintenance,VBR checklist;cluster analysis;clustering algorithm;high-severity defects;inspection scenario development;requirement specification inspections;software defect repository;software evolution;software inspection scenarios;software maintenance;value-based review,,,,19,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Developers' perception of co-change patterns: An empirical study,L. L. Silva; M. T. Valente; M. de A. Maia; N. Anquetil,"Department of Computer Science, Federal University of Minas Gerais, Brazil",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,21,30,"Co-change clusters are groups of classes that frequently change together. They are proposed as an alternative modular view, which can be used to assess the traditional decomposition of systems in packages. To investigate developer's perception of co-change clusters, we report in this paper a study with experts on six systems, implemented in two languages. We mine 102 co-change clusters from the version history of such systems, which are classified in three patterns regarding their projection to the package structure: Encapsulated, Crosscutting, and Octopus. We then collect the perception of expert developers on such clusters, aiming to ask two central questions: (a) what concerns and changes are captured by the extracted clusters? (b) do the extracted clusters reveal design anomalies? We conclude that Encapsulated Clusters are often viewed as healthy designs and that Crosscutting Clusters tend to be associated to design anomalies. Octopus Clusters are normally associated to expected class distributions, which are not easy to implement in an encapsulated way, according to the interviewed developers.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332448,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332448,,Clustering algorithms;Java;Maintenance engineering;Open source software;Partitioning algorithms;Pattern matching,object-oriented programming;pattern clustering;public domain software;software packages,cochange pattern;crosscutting cluster;octopus cluster;package structure,,1,,41,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Identifying wasted effort in the field via developer interaction data,G. Balogh; G. Antal; êÅ. Beszê©des; L. Vidêçcs; T. Gyimê_thy; êÅ. Z. Vê©gh,"Department of Software Engineering, University of Szeged, Hungary",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,391,400,"During software projects, several parts of the source code are usually re-written due to imperfect solutions before the code is released. This wasted effort is of central interest to the project management to assure on-time delivery. Although the amount of thrown-away code can be measured from version control systems, stakeholders are more interested in productivity dynamics that reflect the constant change in a software project. In this paper we present a field study of measuring the productivity of a medium-sized J2EE project. We propose a productivity analysis method where productivity is expressed through dynamic profiles - the so-called Micro-Productivity Profiles (MPPs). They can be used to characterize various constituents of software projects such as components, phases and teams. We collected detailed traces of developers' actions using an Eclipse IDE plug-in for seven months of software development throughout two milestones. We present and evaluate profiles of two important axes of the development process: by milestone and by application layers. MPPs can be an aid to take project control actions and help in planning future projects. Based on the experiments, project stakeholders identified several points to improve the development process. It is also acknowledged, that profiles show additional information compared to a naive diff-based approach.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332490,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332490,,Productivity;Project management;Security;Software;Software measurement;Stakeholders;User interfaces,programming environments;project management;software engineering;software management,Eclipse IDE plugin;MPP;medium-sized J2EE project;microproductivity profile;productivity analysis method;software development;software project management;source code,,,,24,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Modeling changeset topics for feature location,C. S. Corley; K. L. Kashuda; N. A. Kraft,"The University of Alabama, Tuscaloosa, USA",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,71,80,"Feature location is a program comprehension activity in which a developer inspects source code to locate the classes or methods that implement a feature of interest. Many feature location techniques (FLTs) are based on text retrieval models, and in such FLTs it is typical for the models to be trained on source code snapshots. However, source code evolution leads to model obsolescence and thus to the need to retrain the model from the latest snapshot. In this paper, we introduce a topic-modeling-based FLT in which the model is built incrementally from source code history. By training an online learning algorithm using changesets, the FLT maintains an up-to-date model without incurring the non-trivial computational cost associated with retraining traditional FLTs. Overall, we studied over 600 defects and features from 4 open-source Java projects. We also present a historical simulation that demonstrates how the FLT performs as a project evolves. Our results indicate that the accuracy of a changeset-based FLT is similar to that of a snapshot-based FLT, but without the retraining costs.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332453,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332453,changesets;feature location;mining software repositories;program comprehension;topic modeling,Accuracy;Computational modeling;Feature extraction;Indexes;Search engines;Software;Standards,Java;public domain software;source code (software);text analysis,feature location;feature location technique;modeling changeset topic;online learning algorithm;open-source Java project;program comprehension activity;source code;source code evolution;source code snapshot;text retrieval model;topic-modeling-based FLT,,,,42,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
When and why developers adopt and change software licenses,C. Vendome; M. Linares-Vêçsquez; G. Bavota; M. Di Penta; D. M. German; D. Poshyvanyk,"The College of William and Mary, VA, USA",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,31,40,"Software licenses legally govern the way in which developers can use, modify, and redistribute a particular system. While previous studies either investigated licensing through mining software repositories or studied licensing through FOSS reuse, we aim at understanding the rationale behind developers' decisions for choosing or changing software licensing by surveying open source developers. In this paper, we analyze when developers consider licensing, the reasons why developers pick a license for their project, and the factors that influence licensing changes. Additionally, we explore the licensing-related problems that developers experienced and expectations they have for licensing support from forges (e.g., GitHub). Our investigation involves, on one hand, the analysis of the commit history of 16,221 Java open source projects to identify the commits where licenses were added or changed. On the other hand, it consisted of a survey-in which 138 developers informed their involvement in licensing-related decisions and 52 provided deeper insights about the rationale behind the actions that they had undertaken. The results indicate that developers adopt licenses early in the project's development and change licensing after some period of development (if at all). We also found that developers have inherent biases with respect to software licensing. Additionally, reuse-whether by a non-contributor or for commercial purposes-is a dominant reason why developers change licenses of their systems. Finally, we discuss potential areas of research that could ameliorate the difficulties that software developers are facing with regard to licensing issues of their software systems.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332449,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332449,Empirical Studies;Mining Software Repositories;Software Licenses,Data mining;History;Java;Law;Licenses;Software,Java;public domain software,FOSS reuse;Java open source project;software license;software repository mining,,8,,31,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Query by example in large-scale code repositories,V. Balachandran,"VMware, Bangalore, India",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,467,476,"Searching code samples in a code repository is an important part of program comprehension. Most of the existing tools for code search support syntactic element search and regular expression pattern search. However, they are text-based and hence cannot handle queries which are syntactic patterns. The proposed solutions for querying syntactic patterns using specialized query languages present a steep learning curve for users. The querying would be more user-friendly if the syntactic pattern can be formulated in the underlying programming language (as a sample code snippet) instead of a specialized query language. In this paper, we propose a solution for the query by example problem using Abstract Syntax Tree (AST) structural similarity match. The query snippet is converted to an AST, then its subtrees are compared against AST subtrees of source files in the repository and the similarity values of matching subtrees are aggregated to arrive at a relevance score for each of the source files. To scale this approach to large code repositories, we use locality-sensitive hash functions and numerical vector approximation of trees. Our experimental evaluation involves running control queries against a real project. The results show that our algorithm can achieve high precision (0.73) and recall (0.81) and scale to large code repositories without compromising quality.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332498,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332498,,Approximation algorithms;Approximation methods;Euclidean distance;Java;Search engines;Syntactics;Vegetation,approximation theory;file organisation;query languages;query processing;source code (software);trees (mathematics);vectors,AST structural similarity match;AST subtrees;abstract syntax tree structural similarity match;code repositories;code sample searching;learning curve;locality-sensitive hash function;program comprehension;programming language;query by example;query snippet;regular expression pattern search;specialized query languages;syntactic element search;syntactic pattern querying;tree numerical vector approximation,,1,,45,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,9
Code smells in spreadsheet formulas revisited on an industrial dataset,B. Jansen; F. Hermans,"Delft University of Technology, The Netherlands",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,372,380,"In previous work, code smells have been adapted to be applicable on spreadsheet formulas. The smell detection algorithm used in this earlier study was validated on a small dataset of industrial spreadsheets by interviewing the users of these spreadsheets and asking them about their opinion about the found smells. In this paper a more in depth validation of the algorithm is done by analyzing a set of spreadsheets of which users indicated whether or not they are smelly. This new dataset gives us the unique possibility to get more insight in how we can distinguish `bad' spreadsheets from `good' spreadsheets. We do that in two ways: For both the smelly and non smelly spreadsheets we 1) have calculated the metrics that detect the smells and 2) have calculated metrics with respect to size, level of coupling, and the use of functions. The results show that indeed the metrics for the smells decrease in spreadsheets that are not smelly. With respect to size we found to our surprise that the improved spreadsheets were not smaller, but bigger. With regard to coupling and the use of functions both datasets are similar. It indicates that it is difficult to use metrics with respect to size, degree of coupling or use of functions to draw conclusions on the complexity of a spreadsheet.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332488,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332488,,Companies;Complexity theory;Couplings;Length measurement;Programming;Standards,software engineering;spreadsheet programs,code smell detection algorithm;industrial spreadsheet;spreadsheet formula,,4,,13,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,8
Efficient regression testing based on test history: An industrial evaluation,E. D. Ekelund; E. Engstrê_m,"Axis Communications AB, Sweden",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,449,457,"Due to changes in the development practices at Axis Communications, towards continuous integration, faster regression testing feedback is needed. The current automated regression test suite takes approximately seven hours to run which prevents developers from integrating code changes several times a day as preferred. Therefore we want to implement a highly selective yet accurate regression testing strategy. Traditional code coverage based techniques are not applicable due to the size and complexity of the software under test. Instead we decided to select tests based on regression test history. We developed a tool, the Difference Engine, which parses and analyzes results from previous test runs and outputs regression test recommendations. The Difference Engine correlates code and test cases at package level and recommends test cases that are strongly correlated to recently changed packages. We evaluated the technique with respect to correctness, precision, recall and efficiency. Our results are promising. On average the tool manages to identify 80% of the relevant tests while recommending only 4% of the test cases in the full regression test suite.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332496,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332496,continuous integration;industrial evaluation;regression testing,Context;Correlation;Data mining;Difference engines;History;Software;Testing,program testing;statistical testing,Axis Communications;automated regression test suite;code coverage based techniques;continuous integration;correctness;difference engine;industrial evaluation;precision;recall;regression testing feedback;regression testing strategy;software complexity;test history,,3,,13,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,8
Migrating legacy control software to multi-core hardware,M. Wahler; R. Eidenbenz; C. Franke; Y. A. Pignolet,"ABB Corporate Research, Baden-Daettwil, Switzerland",2015 IEEE International Conference on Software Maintenance and Evolution (ICSME),20151123,2015,,,458,466,"This paper reports on a case study on analyzing, structuring and re-using real-time control algorithms which represent a significant amount of intellectual property. As a starting point, legacy code written in ADA together with a Windows-based testing framework is available. The goal is to migrate the code onto a real-time multi-core platform taking advantage of technological progress. We present a tool-supported three-step approach for such legacy control software: identifying and isolating the control algorithms, preparing these algorithms and their information exchange for execution within a modern execution framework for Linux written in C++, and validating the solution by a) performing regression testing to ensure partial correctness and b) validating its real-time properties.",,Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3,10.1109/ICSM.2015.7332497,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332497,,Feature extraction;Hardware;Maintenance engineering;Real-time systems;Software;Software algorithms;Testing,Ada;C++ language;Linux;industrial property;multiprocessing systems;program testing;real-time systems;software maintenance,ADA;C++;Linux;Windows-based testing framework;intellectual property;legacy code;legacy control software migration;multicore hardware;real-time control algorithm analysis;real-time control algorithm reusing;real-time control algorithm structuring;regression testing;tool-supported three-step approach,,1,,20,,,,Sept. 29 2015-Oct. 1 2015,,IEEE,IEEE Conferences,,8
_ã–Automated Debugging Considered Harmful_ãù Considered Harmful: A User Study Revisiting the Usefulness of Spectra-Based Fault Localization Techniques with Professionals Using Real Bugs from Large Systems,X. Xia; L. Bao; D. Lo; S. Li,"Coll. of Comput. Sci. & Technol., Zhejiang Univ., Hangzhou, China",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,267,278,"Due to the complexity of software systems, bugs are inevitable. Software debugging is tedious and time consuming. To help developers perform this crucial task, a number of spectra-based fault localization techniques have been proposed. In general, spectra-based fault localization helps developers to find the location of a bug given its symptoms (e.g., program failures). A previous study by Parnin and Orso however implies that several assumptions made by existing work on spectra-based fault localization do not hold in practice, which hinders the practical usage of these tools. Moreover, a recent study by Xie et al. claims that spectra-based fault localization can potentially ""weaken programmers' abilities in fault detection"".Unfortunately, these studies are performed either using only 2 bugs from small systems (Parnin and Orso's study) or synthetic bugs injected into toy programs (Xie et al.'s study), only involve students, and use dated spectra-based fault localization tools. Thus, the question whether spectra-based fault localization techniques can help professionals to improve their debugging efficiency in a reasonably large project is still insufficiently answered. In this paper, we perform a more realistic investigation of how professionals can use and benefit from spectra-based fault localization techniques. We perform a user study of spectra-based fault localization with a total of 16 real bugs from 4 reasonably large open-source projects, with 36 professionals, amounting to 80 recorded debugging hours. The 36 professionals are divided into 3 groups, i.e., those that use an accurate fault localization tool, use a mediocre fault localization tool, and do not use any fault localization tool. Our study finds that both the accurate and mediocre spectra-based fault localization tools can help professionals to save their debugging time, and the improvements are statistically significant and substantial. We also discuss implications of our findings to future dire- tions of spectra-based fault localization.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.67,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816473,Automated Debugging;Empirical Study;Spectra-Based Fault Localization;User Study,Computer bugs;Debugging;Java;Open source software;Outsourcing;Software maintenance,program debugging;program diagnostics;public domain software;software fault tolerance;software tools,debugging time;fault detection;mediocre spectra-based fault localization tools;open-source projects;program failures;software debugging;software system complexity,,4,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,11
A Comprehensive Study on the Energy Efficiency of Java_ã_s Thread-Safe Collections,G. Pinto; K. Liu; F. Castor; Y. D. Liu,"IFPA, Brazil",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,20,31,"Java programmers are served with numerous choices of collections, varying from simple sequential ordered lists to sophisticated hashtable implementations. These choices are well-known to have different characteristics in terms of performance, scalability, and thread-safety, and most of them are well studied. This paper analyzes an additional dimension, energy efficiency. We conducted an empirical investigation of 16 collection implementations (13 thread-safe, 3 non-thread-safe) grouped under 3 commonly used forms of collections (lists, sets, and mappings). Using micro-and real world-benchmarks (Tomcat and Xalan), we show that our results are meaningful and impactful. In general, we observed that simple design decisions can greatly impact energy consumption. In particular, we found that using a newer hashtable version can yield a 2.19x energy savings in the micro-benchmarks and up to 17% in the real world-benchmarks, when compared to the old associative implementation. Also, we observed that different implementations of the same thread-safe collection can have widely different energy consumption behaviors. This variation also applies to the different operations that each collection implements, e.g, a collection implementation that performs traversals very efficiently can be more than an order of magnitude less efficient than another implementation of the same collection when it comes to insertions.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.34,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816451,,Data structures;Energy consumption;Energy measurement;Java;Optimization;Programming;Servers,Java;energy conservation;object-oriented programming,Java programmers;Java thread-safe collections;Tomcat benchmark;Xalan benchmark;energy consumption;energy efficiency,,1,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,11
Inferring Links between Concerns and Methods with Multi-abstraction Vector Space Model,Y. Zhang; D. Lo; X. Xia; T. D. B. Le; G. Scanniello; J. Sun,"Coll. of Comput. Sci. & Technol., Zhejiang Univ., Hangzhou, China",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,110,121,"Concern localization refers to the process of locating code units that match a particular textual description. It takes as input textual documents such as bug reports and feature requests and outputs a list of candidate code units that are relevant to the bug reports or feature requests. Many information retrieval (IR) based concern localization techniques have been proposed in the literature. These techniques typically represent code units and textual descriptions as a bag of tokens at one level of abstraction, e.g., each token is a word, or each token is a topic. In this work, we propose a multi-abstraction concern localization technique named MULAB. MULAB represents a code unit and a textual description at multiple abstraction levels. Similarity of a textual description and a code unit is now made by considering all these abstraction levels. We combine a vector space model and multiple topic models to compute the similarity and apply a genetic algorithm to infer semi-optimal topic model configurations. We have evaluated our solution on 136 concerns from 8 open source Java software systems. The experimental results show that MULAB outperforms the state-of-art baseline PR, which is proposed by Scanniello et al. in terms of effectiveness and rank.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.51,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816459,Concern Localization;Multi-Abstraction;Text Retrieval;Topic Modeling,Computational modeling;Computer bugs;Genetic algorithms;Java;Sociology;Software systems;Statistics,Java;genetic algorithms;inference mechanisms;information retrieval;pattern matching;public domain software;software maintenance;source code (software);text analysis;vectors,IR;MULAB;code unit location;concern localization;genetic algorithm;information retrieval;link inference;multiabstraction vector space model;open source Java software system;software maintenance;textual description matching;topic model configuration inference,,3,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,11
Smells Like Teen Spirit: Improving Bug Prediction Performance Using the Intensity of Code Smells,F. Palomba; M. Zanoni; F. A. Fontana; A. D. Lucia; R. Oliveto,"Univ. of Salerno, Fisciano, Italy",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,244,255,"Code smells are symptoms of poor design and implementation choices. Previous studies empirically assessed the impact of smells on code quality and clearly indicate their negative impact on maintainability, including a higher bug-proneness of components affected by code smells. In this paper we capture previous findings on bug-proneness to build a specialized bug prediction model for smelly classes. Specifically, we evaluate the contribution of a measure of the severity of code smells (i.e., code smell intensity) by adding it to existing bug prediction models and comparing the results of the new model against the baseline model. Results indicate that the accuracy of a bug prediction model increases by adding the code smell intensity as predictor. We also evaluate the actual gain provided by the intensity index with respect to the other metrics in the model, including the ones used to compute the code smell intensity. We observe that the intensity index is much more important as compared to other metrics used for predicting the buggyness of smelly classes.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.27,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816471,Bug Prediction;Code Smells,Computational modeling;Computer bugs;Context;Indexes;Measurement;Object oriented modeling;Predictive models,program debugging;software performance evaluation;source code (software),bug prediction performance improvement;bug-proneness;code smell intensity index,,3,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,11
Accessing Inaccessible Android APIs: An Empirical Study,L. Li; T. F. Bissyandê©; Y. L. Traon; J. Klein,"Interdiscipl. Centre for Security, Univ. of Luxembourg, Luxembourg City, Luxembourg",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,411,422,"As Android becomes a de-facto choice of development platform for mobile apps, developers extensively leverage its accompanying Software Development Kit to quickly build their apps. This SDK comes with a set of APIs which developers may find limited in comparison to what system apps can do or what framework developers are preparing to harness capabilities of new generation devices. Thus, developers may attempt to explore in advance the normally ""inaccessible"" APIs for building unique API-based functionality in their app. The Android programming model is unique in its kind. Inaccessible APIs, which however are used by developers, constitute yet another specificity of Android development, and is worth investigating to understand what they are, how they evolve over time, and who uses them. To that end, in this work, we empirically investigate 17 important releases of the Android framework source code base, and we find that inaccessible APIs are commonly implemented in the Android framework, which are further neither forward nor backward compatible. Moreover, a small set of inaccessible APIs can eventually become publicly accessible, while most of them are removed during the evolution, resulting in risks for such apps that have leveraged inaccessible APIs. Finally, we show that inaccessible APIs are indeed accessed by third-party apps, and the official Google Play store has tolerated the proliferation of apps leveraging inaccessible API methods.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.35,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816486,,Androids;Ecosystems;Google;Humanoid robots;Libraries;Runtime;Software,Android (operating system);application program interfaces;authorisation;mobile computing;risk management;smart phones;software engineering;source code (software),API-based functionality;Android programming model;SDK;application program interface;inaccessible Android API;mobile app risk;software development kit;source code base,,1,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,11
Maintenance Effort Estimation for Open Source Software: A Systematic Literature Review,H. Wu; L. Shi; C. Chen; Q. Wang; B. Boehm,"Lab. for Internet Software Technol., Inst. of Software, Beijing, China",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,32,43,"Open Source Software (OSS) is distributed and maintained collaboratively by developers all over the world. However, frequent personnel turnover and lack of organizational management makes it difficult to capture the actual development effort. Various OSS maintenance effort estimation approaches have been developed to provide a way to understand and estimate development effort. The goal of this study is to identify the current state of art of the existing maintenance effort estimation approaches for OSS. We performed a systematic literature review on the relevant studies published in the period between 2000-2015 by both automatic and manual searches from different sources. We derived a set of keywords from the research questions and established selection criteria to carefully choose the papers to evaluate. 29 out of 3,312 papers were selected based on a well designed selection process. Our results show that the commonly used OSS maintenance effort estimation methods are actual effort estimation and maintenance activity time prediction, the most commonly used metrics and factors for actual effort estimation are source code measurements and people related metrics, the most commonly mentioned activity for maintenance activity time prediction is bug fixing. Accuracy measures and cross validation is used for validating the estimation models. Based on the above findings, we identified the issues in evaluation methods for actual maintenance effort estimations and the needs for quantitative OSS maintenance effort inference from size-related metrics. Meanwhile, we highlighted individual contribution and performance measurement as a novel and promising research area.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.87,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816452,,Data mining;Estimation;Maintenance engineering;Measurement;Planning;Protocols;Software,program debugging;public domain software;software maintenance;software metrics,OSS;bug fixing;maintenance activity time prediction;maintenance effort estimation;open source software;people related metrics;source code measurements,,1,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,11
A Taxonomy for Program Metamodels in Program Reverse Engineering,H. Washizaki; Y. G. Guê©hê©neuc; F. Khomh,"Dept. of Comput. Sci. & Eng., Waseda Univ., Tokyo, Japan",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,44,55,"To support program comprehension, maintenance, and evolution, metamodels are frequently used during program reverse engineering activities to describe and analyze constituents of a program and their relations. Reverse engineering tools often define their own metamodels according to the intended purposes and features. Although each metamodel has its own advantages, its limitations may be addressed by other metamodels. Existing works have evaluated and compared metamodels and tools, but none have considered all the possible characteristics and limitations to provide a comprehensive guideline for classifying, comparing, reusing, and extending program metamodels. To aid practitioners and researchers in classifying, comparing, reusing, and extending program metamodels and their corresponding reverse engineering tools according to the intended goals, we establish a conceptual framework with definitions of program metamodels and related concepts. Then this framework is used to provide a comprehensive taxonomy, named Program Metamodel TAxonomy (ProMeTA), which incorporates newly identified characteristics into those stated in previous works, which were identified via a systematic literature survey on program metamodels, while keeping the orthogonality of the entire taxonomy. Additionally, we validate the taxonomy in terms of its orthogonality and usefulness through the classification of popular metamodels.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.82,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816453,program comprehension and analysis;program metamodels;reverse engineering;taxonomy,Biological system modeling;Data mining;Grammar;Reverse engineering;Syntactics;Taxonomy;Unified modeling language,pattern classification;program diagnostics;reverse engineering;software maintenance,ProMeTA;comprehensive taxonomy;program comprehension;program evolution;program maintenance;program metamodel taxonomy;program reverse engineering tools,,,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,11
An Empirical Study on the Characteristics of Python Fine-Grained Source Code Change Types,W. Lin; Z. Chen; W. Ma; L. Chen; L. Xu; B. Xu,"State Key Lab. for Novel Software Technol., Nanjing Univ., Nanjing, China",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,188,199,"Software has been changing during its whole life cycle. Therefore, identification of source code changes becomes a key issue in software evolution analysis. However, few current change analysis research focus on dynamic language software. In this paper, we pay attention to the fine-grained source code changes of Python software. We implement an automatic tool named PyCT to extract 77 kinds of fine-grained source code change types from commit history information. We conduct an empirical study on ten popular Python projects from five domains, with 132294 commits, to investigate the characteristics of dynamic software source code changes. Analyzing the source code changes in four aspects, we distill 11 findings, which are summarized into two insights on software evolution: change prediction and fault code fix. In addition, we provide direct evidence on how developers use and change dynamic features. Our results provide useful guidance and insights for improving the understanding of source code evolution of dynamic language software.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.25,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816466,Python;fine-grained change types;software evolution,Computer bugs;Data mining;Feature extraction;Heuristic algorithms;Maintenance engineering;Software;Taxonomy,high level languages;software fault tolerance;software maintenance;source code (software),PyCT;Python software;automatic tool;change prediction;dynamic language software;dynamic software source code changes;fault code fix;fine-grained source code change types;software evolution analysis;software life cycle;source code evolution,,,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,11
"On the Reaction to Deprecation of 25,357 Clients of 4+1 Popular Java APIs",A. A. Sawant; R. Robbes; A. Bacchelli,"Delft Univ. of Technol., Delft, Netherlands",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,400,410,"Application Programming Interfaces (APIs) are a tremendous resource-that is, when they are stable. Several studies have shown that this is unfortunately not the case. Of those, a large-scale study of API changes in the Pharo Smalltalk ecosystem documented several findings about API deprecations and their impact on API clients. We conduct a partial replication of this study, considering more than 25,000 clients of five popular Java APIs on GitHub. This work addresses several shortcomings of the previous study, namely: a study of several distinct API clients in a popular, statically-typed language, with more accurate version information. We compare and contrast our findings with the previous study and highlight new ones, particularly on the API client update practices and the startling similarities between reaction behavior in Smalltalk and Java.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.64,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816485,API;deprecation;mining software repositories,Documentation;Ecosystems;History;Java;Libraries;Programming;Software,Java;public domain software,GitHub;Pharo Smalltalk ecosystem;application programming interfaces;popular Java APIs,,1,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
TechLand: Assisting Technology Landscape Inquiries with Insights from Stack Overflow,C. Chen; Z. Xing; L. Han,"Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore, Singapore",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,356,366,"Understanding the technology landscape is crucial for the success of the software-engineering project or organization. However, it can be difficult, even for experienced developers, due to the proliferation of similar technologies, the complex and often implicit dependencies among technologies, and the rapid development in which technology landscape evolves. Developers currently rely on online documents such as tutorials and blogs to find out best available technologies, technology correlations, and technology trends. Although helpful, online documents often lack objective, consistent summary of the technology landscape. In this paper, we present the TechLand system for assisting technology landscape inquiries with categorical, relational and trending knowledge of technologies that is aggregated from millions of Stack Overflow questions mentioning the relevant technologies. We implement the TechLand system and evaluate the usefulness of the system against the community answers to 100 technology questions on Stack Overflow and by field deployment and a lab study. Our evaluation shows that the TechLand system can assist developers in technology landscape inquiries by providing direct, objective, and aggregated information about available technologies, technology correlations and technology trends. Developers currently rely on online documents such as tutorials and blogs to find out best available technologies, technology correlations, and technology trends. Although helpful, online documents often lack objective, consistent summary of the technology landscape. In this paper, we present the TechLand system for assisting technology landscape inquiries with categorical, relational and trending knowledge of technologies that is aggregated from millions of Stack Overflow questions mentioning the relevant technologies. We implement the TechLand system and evaluate the usefulness of the system against the community answers to 100 technology questions on Stack Overflow and b- field deployment and a lab study. Our evaluation shows that the TechLand system can assist developers in technology landscape inquiries by providing direct, objective, and aggregated information about available technologies, technology correlations and technology trends.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.17,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816481,Associative Network;Exploration;Information Visualization;Stack Overflow,Correlation;Data visualization;Google;Java;Libraries;Market research,software engineering,TechLand system;software engineering organization;software engineering project;stack overflow;technology landscape,,1,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
Inferring Computational State Machine Models from Program Executions,N. Walkinshaw; M. Hall,"Dept. of Comput. Sci., Univ. of Leicester, Leicester, UK",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,122,132,"The challenge of inferring state machines from log data or execution traces is well-established, and has led to the development of several powerful techniques. Current approaches tend to focus on the inference of conventional finite state machines or, in few cases, state machines with guards. However, these machines are ultimately only partial, because they fail to model how any underlying variables are computed during the course of an execution, they are not computational. In this paper we introduce a technique based upon Genetic Programming to infer these data transformation functions, which in turn render inferred automata fully computational. Instead of merely determining whether or not a sequence is possible, they can be simulated, and be used to compute the variable values throughout the course of an execution. We demonstrate the approach by using a Cross-Validation study to reverse-engineer complete (computational) EFSMs from traces of established implementations.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.74,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816460,Genetic Programming;Reverse Engineering;State Machines,Automata;Computational modeling;Data models;Genetic programming;Inference algorithms;Sociology;Training,finite state machines;genetic algorithms;program diagnostics;reverse engineering,computational state machine models;data transformation functions;finite state machines;fully computational automata;genetic programming;log data;program executions;reverse-engineer complete EFSM;state machines,,1,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
Learning to Extract API Mentions from Informal Natural Language Discussions,D. Ye; Z. Xing; C. Y. Foo; J. Li; N. Kapre,"Sch. of Comput. Sci. & Eng., Nanyang Technol. Univ., Singapore, Singapore",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,389,399,"When discussing programming issues on social platforms (e.g, Stack Overflow, Twitter), developers often mention APIs in natural language texts. Extracting API mentions in natural language texts is a prerequisite for effective indexing and searching for API-related information in software engineering social content. However, the informal nature of social discussions creates two fundamental challenges for API extraction: common-word polysemy and sentence-format variations. Common-word polysemy refers to the ambiguity between the API sense of a common word and the normal sense of the word (e.g., append, apply and merge). Sentence-format variations refer to the lack of consistent sentence writing format for inferring API mentions. Existing API extraction techniques fall short to address these two challenges, because they assume distinct API naming conventions (e.g., camel case, underscore) or structured sentence format (e.g., code-like phrase, API annotation, or full API name). In this paper, we propose a semi-supervised machine-learning approach that exploits name synonyms and rich semantic context of API mentions to extract API mentions in informal social text. The key innovation of our approach is to exploit two complementary unsupervised language models learned from the abundant unlabeled text to model sentence-format variations and to train a robust model with a small set of labeled data and an iterative self-training process. The evaluation of 1,205 API mentions of the three libraries (Pandas, Numpy, and Matplotlib) in Stack Overflow texts shows that our approach significantly outperforms existing API extraction techniques based on language-convention and sentence-format heuristics and our earlier machine-learning based method for named-entity recognition.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.11,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816484,,Context;Feature extraction;Joining processes;Libraries;Natural languages;Software engineering;Standards,application program interfaces;indexing;learning (artificial intelligence);natural languages;social networking (online);software engineering;text analysis,API mention extraction;API naming conventions;API-related information;common-word polysemy;indexing;informal natural language discussions;named-entity recognition;natural language texts;semisupervised machine-learning;sentence-format variations;social platforms;software engineering social content;stack overflow texts,,,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
Who is Who in the Mailing List? Comparing Six Disambiguation Heuristics to Identify Multiple Addresses of a Participant,I. S. Wiese; J. T. d. Silva; I. Steinmacher; C. Treude; M. A. Gerosa,"Comput. Sci. Dept., Fed. Univ. of Technol. - Parana (UTFPR), Curitiba, Brazil",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,345,355,"Many software projects adopt mailing lists for the communication of developers and users. Researchers have been mining the history of such lists to study communities' behavior, organization, and evolution. A potential threat of this kind of study is that users often use multiple email addresses to interact in a single mailing list. This can affect the results and tools, when, for example, extracting social networks. This issue is particularly relevant for popular and long-term Open Source Software (OSS) projects, which attract participation of thousands of people. Researchers have proposed heuristics to identify multiple email addresses from the same participant, however there are few studies analyzing the effectiveness of these heuristics. In addition, many studies still do not use any heuristics for authors' disambiguation, which can compromise the results. In this paper, we compare six heuristics from the literature using data from 150 mailing lists from Apache Software Foundation projects. We found that the heuristics proposed by Oliva et al. and a Naiê_ve heuristic outperformed the others in most cases, when considering the F-measure metric. We also found that the time window and the size of the dataset influence the effectiveness of each heuristic. These results may help researchers and tool developers to choose the most appropriate heuristic to use, besides highlighting the necessity of dealing with identity disambiguation, mainly in open source software communities with a large number of participants.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.13,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816480,Apache Software Foundation;Email address disambiguation;mailing lists;mining software repositories,Birds;Computer science;Data mining;Electronic mail;History;Social network services;Software,electronic mail;project management;public domain software;software engineering;software management,F-measure metric;OSS project;disambiguation heuristics;email address;mailing list;open source software project,,2,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
Evolving NoSQL Databases without Downtime,K. Saur; T. DumitraÅÈ; M. Hicks,,2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,166,176,"NoSQL databases like Redis, Cassandra, and Mon-goDB are increasingly popular because they are flexible, lightweight, and easy to work with. Applications that use these databases will evolve over time, sometimes necessitating (or preferring) a change to the format or organization of the data. The problem we address in this paper is: How can we support the evolution of high-availability applications and their NoSQL data online, without excessive delays or interruptions, even in the presence of backward-incompatible data format changes? We present KVolve, an extension to the popular Redis NoSQL database, as a solution to this problem. KVolve permits a developer to submit an upgrade specification that defines how to transform existing data to the newest version. This transformation is applied lazily as applications interact with the database, thus avoiding long pause times. We demonstrate that KVolve is expressive enough to support substantial practical updates, including format changes to RedisFS, a Redis-backed file system, while imposing essentially no overhead in general use and minimal pause times during updates.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.47,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816464,,Arrays;Benchmark testing;Encoding;Relational databases;Servers;Software,SQL;formal specification;relational databases,KVolve extension;NoSQL database;Redis-backed file system;RedisFS;format change;software developer;upgrade specification,,1,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
Understanding Variable Code: Reducing the Complexity by Integrating Variability Information,D. Lê_demann; N. Asad; K. Schmid; C. Voges,"Univ. of Bremen, Bremen, Germany",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,312,322,"Software product lines often use preprocessor statements as a basis for representing variability, which makes understanding the artifacts rather complex. An approach that has been proposed in the past to improve the understanding of code with preprocessor statements is formal concept analysis. This approach has been applied to a number of causes in reengineering. However, the lattices constructed by this approach can become rather large and complex. Hence, any approach that helps to reduce them can be beneficial to understanding the preprocessor-dependencies contained in the code. Here, we show how consistency analysis both within code variability and between code and a variability model can be used to reduce the complexity of a lattice, supporting the analysis of product-line code. We apply our approach to Linux, one of the largest open-source product lines, and analyze both multiple versions and different architectures. We show that our approach typically leads to reductions of the concept lattice and identify situations in which the savings can be rather significant. This leads to a reduction of any efforts for followup analysis or reverse engineering.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.58,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816477,linux;software product line;variability,Analytical models;Complexity theory;Context;Data preprocessing;Formal concept analysis;Lattices;Linux,Linux;formal concept analysis;public domain software;software architecture;software product lines,Linux;architectures;code understanding;code variability;complexity reduction;concept lattice;consistency analysis;followup analysis;formal concept analysis;open-source product lines;preprocessor statements;preprocessor-dependencies;product-line code analysis;reengineering;reverse engineering;software product lines;variable code,,,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
Comparing Quality Metrics for Cloned and Non Cloned Java Methods: A Large Scale Empirical Study,V. Saini; H. Sajnani; C. Lopes,,2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,256,266,"In this paper, we conduct a large scale statistical study to explore if there exists any difference between the quality of cloned methods and non cloned methods. The dataset consists of 4,421 open source Java projects containing 644,830 cloned and 842,052 non cloned methods. The study uses 27 software metrics as a proxy for quality, spanning across complexity, modularity, and documentation (code-comments) categories. We did not find any statistically significant difference (p0.1) between the quality of cloned and non cloned methods for most of the metrics, except for 3 metrics. We, however, found that the cloned methods are on an average 20% smaller than the non cloned methods.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.94,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816472,Code Clones;Open Source Software;Quality Metrics,Cloning;Complexity theory;Computer bugs;Java;Measurement;Software quality,Java;public domain software;software metrics;software quality;source code (software);system documentation,code-comments categories;documentation categories;modularity categories;noncloned Java;open source Java projects;quality metrics;software metrics;spanning across complexity categories,,,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
An Empirical Evaluation of Models of Programmer Navigation,A. Singh; A. Z. Henley; S. D. Fleming; M. V. Luong,"Dept. of Comput. Sci., Univ. of Memphis, Memphis, TN, USA",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,9,19,"In this paper, we report an evaluation study of predictive models of programmer navigation. In particular, we compared two operationalizations of navigation from the literature (click-based versus view-based) to see which more accurately records a developer's navigation behaviors. Moreover, we also compared the predictive accuracy of seven models of programmer navigation from the literature, including ones based on navigation history and code-structural relationships. To address our research goals, we performed a controlled laboratory study of the navigation behavior of 10 participants engaged in software evolution tasks. The study was a partial replication of a previous comprehensive evaluation of predictive models by Piorkowski et al., and also served to test the generalizability of their results. Key findings of the study included that the click-based navigations agreed closely with those reported by human observers, whereas view-based navigations diverged significantly. Furthermore, our data showed that the predictive model based on recency was significantly more accurate than the other models, suggesting the strong potential for tools that leverage recency-type models. Finally, our model-accuracy results had a strong correlation with the Piorkowski results, however, our results differed in several noteworthy ways, potentially caused by differences in task type and code familiarity.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.84,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816450,,Batteries;Debugging;History;Navigation;Observers;Predictive models;Software,program debugging;software maintenance;source code (software),click-based navigation;code familiarity;code-structural relationships;human observers;navigation history;navigation operationalisation;programmer navigation models;recency-type models;software evolution;task type;view-based navigation,,,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
ICON: Inferring Temporal Constraints from Natural Language API Descriptions,R. Pandita; K. Taneja; L. Williams; T. Tung,,2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,378,388,"Temporal constraints of an Application Programming Interface (API) are the allowed sequences of method invocations in the API governing the secure and robust operation of client software using the API. These constraints are typically described informally in natural language API documents, and therefore are not amenable to existing constraint-checking tools. Manually identifying and writing formal temporal constraints from API documents can be prohibitively time-consuming and error-prone. To address this issue, we propose ICON: an approach based on Machine Learning (ML) and Natural Language Processing (NLP) for identifying and inferring formal temporal constraints. To evaluate our approach, we use ICON to infer and formalize temporal constraints from the Amazon S3 REST API, the PayPal Payment REST API, and the java.io package in the JDK API. Our results indicate that ICON can effectively identify temporal constraint sentences (from over 4000 human annotated API sentences) with the average 79.0% precision and 60.0% recall. Furthermore, our evaluation demonstrates that ICON achieves an accuracy of 70% in inferring 77 formal temporal constraints from these APIs.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.59,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816483,API;NLP;Temporal Specifications,Contracts;Dictionaries;Documentation;Natural languages;Semantics;Syntactics;Tagging,application program interfaces;learning (artificial intelligence);natural language processing,Amazon S3 REST API;ICON;JDK API;ML;NLP;PayPal Payment REST API;application program interfaces;client software;constraint-checking tools;machine learning;natural language API description;natural language processing;temporal constraints,,,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
Understanding the Factors That Impact the Popularity of GitHub Repositories,H. Borges; A. Hora; M. T. Valente,"Dept. of Comput. Sci., Fed. Univ. of Minas Gerais, Belo Horizonte, Brazil",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,334,344,"Software popularity is a valuable information to modern open source developers, who constantly want to know if their systems are attracting new users, if new releases are gaining acceptance, or if they are meeting user's expectations. In this paper, we describe a study on the popularity of software systems hosted at GitHub, which is the world's largest collection of open source software. GitHub provides an explicit way for users to manifest their satisfaction with a hosted repository: the stargazers button. In our study, we reveal the main factors that impact the number of stars of GitHub projects, including programming language and application domain. We also study the impact of new features on project popularity. Finally, we identify four main patterns of popularity growth, which are derived after clustering the time series representing the number of stars of 2,279 popular GitHub repositories. We hope our results provide valuable insights to developers and maintainers, which could help them on building and evolving systems in a competitive software market.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.31,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816479,GitHub;Open Source software;Social coding;Software Popularity,Documentation;HTML;Java;Libraries;Organizations;Software,public domain software;software reviews;source code (software);time series,GitHub Repositories;GitHub projects;open source developers;open source software;programming language;project popularity;software acceptance;software market;software system popularity;stargazers button;time series,,3,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
Evolving Requirements-to-Code Trace Links across Versions of a Software System,M. Rahimi; W. Goss; J. Cleland-Huang,"Dept. of Comput. Sci. & Eng., Univ. of Notre Dame, South Bend, IN, USA",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,99,109,"Trace links provide critical support for numerous software engineering activities including safety analysis, compliance verification, test-case selection, and impact prediction. However, as the system evolves over time, there is a tendency for the quality of trace links to degrade into a tangle of inaccurate and untrusted links. This is especially true with the links between source-code and upstream artifacts such as requirements - because developers frequently refactor and change code without updating the links. We present TLE (Trace Link Evolver), a solution for automating the evolution of trace links as changes are introduced to source code. We use a set of heuristics, open source tools, and information retrieval methods to detect common change scenarios across different versions of software. Each change scenario is then associated with a set of link evolution heuristics which are used to evolve trace links. We evaluate our approach through a controlled experiment and also through applying it across 27 releases of the Cassandra Database System. Results show that the trace links evolved using our approach are significantly more accurate than those generated using information retrieval alone.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.57,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816458,Evolution;Maintenance;Traceability,Computer science;Conferences;Crawlers;Feature extraction;Software systems,formal specification;formal verification;information retrieval;program diagnostics;public domain software;software tools;source code (software);systems analysis,TLE;information retrieval;open source tool;requirements-to-code trace link;software engineering;software system version;source code;trace link evolver;traceability;upstream artifact,,1,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
"Do Contexts Help in Phrase-Based, Statistical Source Code Migration?",A. T. Nguyen; Z. Tu; T. N. Nguyen,,2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,155,165,"Prior research showed that to migrate Java code to C# by directly applying phrase-based statistical machine translation (SMT) on the lexemes of source code produces much semantically incorrect code. In this work, we conduct empirical studies on several open-source projects to investigate the use of well-defined semantics in programming languages to guide the translation process in SMT. We have investigated five types of features forming the contexts involving the (semantic) relations among code tokens including occurrence association among code tokens, data and control dependencies among program entities, visibility constraints of entities, and the consistency in declarations and accesses of variables, fields and methods. We use the Direct Maximum Entropy (DME) approach for feature integration. Our empirical results show that as individual features added to the baseline SMT model, token association and data dependencies contribute much with highest relative improvement in semantic correctness of up to 18.3% and 18.5%, respectively. The integration of three feature types (token association, data dependencies, and visibility) into the baseline model has highest relative improvement with up to 26.4% improvement in semantic correctness. Generally, 43.5-80.7% of the total translated methods are semantically correct. Our results show a good direction of using SMT with semantic features at different levels of abstraction to improve its accuracy.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.89,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816463,Code Migration;Context Integration;Language Migration;Semantic Features;Statistical Machine Translation,C# languages;Context;Data models;Java;Semantics;Syntactics,language translation;maximum entropy methods;software engineering;source code (software),DME approach;Java code migration;SMT;direct maximum entropy approach;feature integration;phrase-based statistical machine translation;phrase-based statistical source code migration;programming languages;semantic correctness,,,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
Why are Commits Being Reverted?: A Comparative Study of Industrial and Open Source Projects,J. Shimagaki; Y. Kamei; S. McIntosh; D. Pursehouse; N. Ubayashi,"Sony Mobile Commun. Inc., Japan",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,301,311,"Software development is a cyclic process of integrating new features while introducing and fixing defects. During development, commits that modify source code files are uploaded to version control systems. Occasionally, these commits need to be reverted, i.e., the code changes need to be completely backed out of the software project. While one can often speculate about the purpose of reverted commits (e.g., the commit may have caused integration or build problems), little empirical evidence exists to substantiate such claims. The goal of this paper is to better understand why commits are reverted in large software systems. To that end, we quantitatively and qualitatively study two proprietary and four open source projects to measure: (1) the proportion of commits that are reverted, (2) the amount of time that commits that are eventually reverted linger within a codebase, and (3) the most frequent reasons why commits are reverted. Our results show that 1%-5% of the commits in the studied systems are reverted. Those commits that are eventually reverted linger within the studied codebases for 1-35 days (median). Furthermore, we identify 13 common reasons for reverting commits, and observe that the frequency of reverted commits of each reason varies broadly from project to project. A complementary qualitative analysis suggests that many reverted commits could have been avoided with better team communication and change awareness. Our findings made Sony Mobile's stakeholders aware that internally reverted commits can be reduced by paying more attention to their own changes. On the other hand, externally reverted commits could be minimized only if external stakeholders are involved to improve inter-company communication or requirements elicitation.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.83,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816476,code inspections;code review;mining software repository;revert;software evolution,Androids;Humanoid robots;Mobile communication;Mobile handsets;Software systems;Stakeholders,project management;public domain software;software engineering;software management;source code (software),industrial project;large software systems;open source project;qualitative analysis;reverted commits;software development;software project;source code;version control systems,,,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
From Quick Fixes to Slow Fixes: Reimagining Static Analysis Resolutions to Enable Design Space Exploration,T. Barik; Y. Song; B. Johnson; E. Murphy-Hill,"Comput. Sci. Dept., North Carolina State Univ., Raleigh, NC, USA",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,211,221,"Quick Fixes as implemented by IDEs today prioritize the speed of applying the fix as a primary criteria for success. In this paper, we argue that when tools over-optimize this criteria, such tools neglect other dimensions that are important to successfully applying a fix, such as being able to explore the design space of multiple fixes. This is especially true in cases where a fix only partially implements the intention of the developer. In this paper, we implement an extension to the FindBugs defect finding tool, called FixBugs, an interactive resolution approach within the Eclipse development environment that prioritizes other design criteria to the successful application of suggested fixes. Our empirical evaluation method of 12 developers suggests that FixBugs enables developers to explore alternative designs and balances the benefits of manual fixing with automated fixing, without having to compromise in either effectiveness or efficiency. Our analytic evaluation method with six usability experts identified trade-offs between FixBugs and Quick Fix, and suggests ways in which FixBugs and Quick Fix can offer complementary capabilities to better support developers.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.63,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816468,,Color;Computer bugs;Image color analysis;Java;Manuals;Software;Space exploration,program debugging;program diagnostics;software tools,Eclipse development;FindBugs defect finding tool;FixBugs;Quick Fixes;design space exploration;static analysis resolution,,1,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
Search-Based Peer Reviewers Recommendation in Modern Code Review,A. Ouni; R. G. Kula; K. Inoue,"Dept. of Comput. Sci., Osaka Univ., Suita, Japan",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,367,377,"Code review is of primary importance in modern software development. It is widely recognized that peer review is an efficient and effective practice for improving software quality and reducing defect proneness. For successful review process, peer reviewers should have a deep experience and knowledge with the code being reviewed, and familiar to work and collaborate together. However, one of the main challenging tasks in modern code review is to find the most appropriate reviewers for submitted code changes. So far, reviewers assignment is still a manual, costly and time-consuming task. In this paper, we introduce a search-based approach, namely RevRec, to provide decision-making support for code change submitters and/or reviewers assigners to identify most appropriate peer reviewers for their code changes. RevRec aims at finding reviewers to be assigned for a code change based on their expertise and collaboration in past reviews using genetic algorithm (GA). We evaluated our approach on a benchmark of three open-source software systems, Android, OpenStack, and Qt. Results indicate that RevRec accurately recommends code reviewers with up to 59% of precision and 74% of recall. Our experiments provide evidence that leveraging reviewers expertise from their prior reviews and the socio-technical aspects of the team work and collaboration is relevant in improving the performance of peer reviewers recommendation in modern code review.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.65,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816482,Code review;Reviewer recommendation;Search-based Software Engineeging,Genetic algorithms;Search problems;Sociology;Software;Software engineering;Teamwork,Android (operating system);decision making;genetic algorithms;public domain software;search problems;software quality;software reviews;source code (software);team working,Android;OpenStack;Qt;RevRec;code review;decision making support;genetic algorithm;open-source software systems;peer review;precision;recall;search-based approach;search-based peer reviewer recommendation;software development;software quality;team work socio-technical aspects,,,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
An Optimization Approach for Matching Textual Domain Models with Existing Code,T. Patil; R. Komondoor; D. D_ã_Souza; I. Bhattacharya,"CSA Dept., Indian Inst. of Sci., Bangalore, India",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,133,143,"We address the task of mapping a given textual domain model with the source code of an application which is in the same domain but was developed independently of the domain model. The key novelty of our approach is to use mathematical optimization to find a mapping between the elements in the two sides that maximizes the instances of clusters of related elements on each side being mapped to clusters of similarly related elements on the other side. We describe experiments wherein we apply our approach to the task of matching two real, open-source applications to corresponding industry-standard domain models. In comparison with previous approaches that leverage relationships, but are formulated as heuristics rather than as a principled optimization problem, our approach gives up to 40% higher precision given a desired level of recall.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.48,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816461,feature location in source code;information retrieval;model-driven software engineering,Customer relationship management;Load modeling;Manuals;Measurement;Optimization;Standards,optimisation;pattern matching;public domain software;source code (software);text analysis,cluster instance maximization;mathematical optimization;open-source application;source code;textual domain model matching,,,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
An Automated Approach for Recommending When to Stop Performance Tests,H. M. Alghmadi; M. D. Syer; W. Shang; A. E. Hassan,"Software Anal. & Intell. Lab., Queen's Univ., Kingston, ON, Canada",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,279,289,"Performance issues are often the cause of failures in today's large-scale software systems. These issues make performance testing essential during software maintenance. However, performance testing is faced with many challenges. One challenge is determining how long a performance test must run. Although performance tests often run for hours or days to uncover performance issues (e.g., memory leaks), much of the data that is generated during a performance test is repetitive. Performance analysts can stop their performance tests (to reduce the time to market and the costs of performance testing) if they know that continuing the test will not provide any new information about the system's performance. To assist performance analysts in deciding when to stop a performance test, we propose an automated approach that measures how much of the data that is generated during a performance test is repetitive. Our approach then provides a recommendation to stop the test when the data becomes highly repetitive and the repetitiveness has stabilized (i.e., little new information about the systems' performance is generated). We performed a case study on three open source systems (i.e., CloudStore, PetClinic and Dell DVD Store). Our case study shows that our approach reduces the duration of 24-hour performance tests by 75% while preserving more than 91.9% of the information about the system's performance. In addition, our approach recommends a stopping time that is close to the most cost-effective stopping time (i.e., the stopping time that minimize the duration of the test and maximizes the amount of information about the system's performance provided by performance testing).",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.46,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816474,Performance Analysts;Performance Counters Data;Performance Testing;Software Engineering,Market research;Radiation detectors;Software maintenance;Software systems;System performance;Testing;Time factors,software maintenance;software performance evaluation,large-scale software systems;performance test;software maintenance;stopping time,,1,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
Hug the Elephant: Migrating a Legacy Data Analytics Application to Hadoop Ecosystem,F. Zhu; J. Liu; S. Wang; J. Xu; L. Xu; J. Ren; D. Ye; J. Wei; T. Huang,"Inst. of Comput., China",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,177,187,"Big data applications that rely on relational databases gradually expose limitations on scalability and performance. In recent years, Hadoop ecosystem has been widely adopted as an evolving solution. This paper presents the migration of a legacy data analytics application in a provincial data center. The target platform follows ""no one size fits all"" method. Considering different workloads, data storage is hybrid with distributed file system (HDFS) and distributed NoSQL database. Beyond the architecture re-design, we focus on the problem of data model transformation from relational database to NoSQL database. We propose a query-aware approach to free developers from tedious manual work. The approach generates query-specific views (NoView) for NoSQL and re-structures the views to align with NoSQL's data model. Our results show that the migrated application achieves high scalability and high performance. We believe that our practice provides valuable insights (such as NoSQL data modeling methodology), and the techniques can be easily applied to other similar migrations.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.14,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816465,Data Model;Hadoop;Migration;NoSQL Database,Big data;Computer architecture;Data analysis;Data models;Distributed databases;Ecosystems;Relational databases,Big Data;SQL;computer centres;data analysis;distributed databases;parallel processing;query processing;relational databases;software maintenance;storage management,Big Data;HDFS;Hadoop ecosystem;data center;data storage;distributed NoSQL database;distributed file system;legacy data analytics application migration;query-aware approach;query-specific view generation;relational database,,,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
"Concepts, Operations, and Feasibility of a Projection-Based Variation Control System",S. St„Ñnciulescu; T. Berger; E. Walkingshaw; A. W„ósowski,"Univ. of Copenhagen, Copenhagen, Denmark",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,323,333,"Highly configurable software often uses preprocessor annotations to handle variability. However, understanding, maintaining, and evolving code with such annotations is difficult, mainly because a developer has to work with all variants at a time. Dedicated methods and tools that allow working on a subset of all variants could ease the engineering of highly configurable software. We investigate the potential of one kind of such tools: projection-based variation control systems. For such systems we aim to understand: (i) what end-user operations they need to support, and (ii) whether they can realize the actual evolution of real-world, highly configurable software. We conduct an experiment that investigates variability-related evolution patterns and that evaluates the feasibility of a projection-based variation control system by replaying parts of the history of a highly configurable real-world 3D printer firmware project. Among others, we show that the prototype variation control system does indeed support the evolution of a highly configurable system and that in general, it does not degrade the code.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.88,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816478,ambition;projection;projectional editing;variability management;variation control system,Calculus;Control systems;History;Printers;Prototypes;Software;Syntactics,control engineering computing;firmware;software engineering,3D printer firmware project;code evolution;code maintenance;code understanding;highly configurable software engineering;preprocessor annotation;projection-based variation control system;variability handling,,,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
Recommending Code Changes for Automatic Backporting of Linux Device Drivers,F. Thung; X. B. D. Le; D. Lo; J. Lawall,"Sch. of Inf. Syst., Singapore Manage. Univ., Singapore, Singapore",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,222,232,"Device drivers are essential components of any operating system (OS). They specify the communication protocol that allows the OS to interact with a device. However, drivers for new devices are usually created for a specific OS version. These drivers often need to be backported to the older versions to allow use of the new device. Backporting is often done manually, and is tedious and error prone. To alleviate this burden on developers, we propose an automatic recommendation system to guide the selection of backporting changes. Our approach analyzes the version history for cues to recommend candidate changes. We have performed an experiment on 100 Linux driver files and have shown that we can give a recommendation containing the correct backport for 68 of the drivers. For these 68 cases, 73.5%, 85.3%, and 88.2% of the correct recommendations are located in the Top-1, Top-2, and Top-5 positions of the recommendation lists respectively. The successful cases cover various kinds of changes including change of record access, deletion of function argument, change of a function name, change of constant, and change of if condition. Manual investigation of failed cases highlights limitations of our approach, including inability to infer complex changes, and unavailability of relevant cues in version history.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.71,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816469,Backporting;Device Drivers;Linux;Recommendation System,Conferences;Control systems;History;Kernel;Libraries;Linux,Linux;device drivers;operating systems (computers);protocols;recommender systems;software maintenance;source code (software),IF condition change;Linux device driver backporting;OS;communication protocol;constant change;function argument deletion;function name change;operating system;recommendation code;recommendation system;record access change,,2,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
An Empirical Study of Internationalization Failures in the Web,A. Alameer; W. G. J. Halfond,"Dept. of Comput. Sci., Univ. of Southern California, Los Angeles, CA, USA",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,88,98,"Web application internationalization frameworks allow businesses to more easily market and sell their products and services around the world. However, internationalization can lead to problems. Text expansion and contraction after translation may result in a distortion of the layout of the translated versions of a webpage, which can reduce their usability and aesthetics. In this paper, we investigate and report on the frequency and severity of different types of failures in webpages' user interfaces that are due to internationalization. In our study, we analyzed 449 real world internationalized webpages. Our results showed that internationalization failures occur frequently and they range significantly in terms of severity and impact on the web applications. These findings motivate and guide future work in this area.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.55,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816457,Internationalization;testing;web applications,Distortion;Encoding;Frequency measurement;HTML;Image edge detection;Layout;User interfaces,Web sites;business data processing;globalisation;international trade;language translation;natural language interfaces;text editing,Web application internationalization failures;Webpage user interfaces;business internationalization;text contraction;text expansion;text translation,,,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
A Complete Operator Library for DSL Evolution Specification,J. G. M. Mengerink; A. Serebrenik; R. R. H. Schiffelers; M. G. J. v. d. Brand,"Eindhoven Univ. of Technol., Eindhoven, Netherlands",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,144,154,"Domain-specific languages (DSLs) allow users to model systems using concepts from a specific domain. Evolution of DSLs triggers co-evolution of models developed in these languages. Manual co-evolution of the thousands of models is unfeasible, calling for an automated support. A prerequisite to automating model co-evolution with respect to DSL evolution is the ability to formally specify DSL evolution, e.g., using predefined evolution operators. Success or failure of the practical application of the operator-based approach therefore depends heavily on the operators offered by the operator library at hand. In this paper we evaluate the completeness of the state-of-the-art operator library claimed to be ""practically complete"" (which we denote as H) by using it to specify evolution of an ecosystem of 22 commercial DSLs over the period of four years. We observe that 11% of the changes cannot be specified. However, there is no guarantee that extending the library with the identified deficiencies will be sufficient to specify evolution of other DSLs. To mitigate this, we design a theoretically complete library of operators, R. We observe that 77% of the operators from R are absent from H. Of the deficiencies in H, 72% could not be revealed by means of studying the extensive industrial ecosystem above. Our study suggests that the existing operator libraries are not extensive enough to specify evolution of large model-driven software ecosystems. Since extending operator libraries on a per-case study basis does not yield satisfactory results so far, we advocate an alternative, i.e. a theoretically complete library of operators R.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.32,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816462,evolution;model driven engineering;operator based,Compounds;DSL;Ecosystems;Libraries;Manuals;Metamodeling;Semiconductor device modeling,formal specification;specification languages,DSL evolution specification;complete operator library;domain-specific languages;model-driven software ecosystems,,,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
Recovering Commit Branch of Origin from GitHub Repositories,H. M. Michaud; D. T. Guarnera; M. L. Collard; J. I. Maletic,"Dept. of Comput. Sci., Kent State Univ., Kent, WA, USA",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,290,300,"An approach to automatically recover the name of the branch where a given commit is originally made within a GitHub repository is presented and evaluated. This is a difficult task because in Git, the commit object does not store the name of the branch when it is created. Here this is termed the commit's branch of origin. Developers typically use branches in Git to group sets of changes that are related by task or concern. The approach recovers the branch of origin only within the scope of a single repository. The recovery process first uses Git's default merge commit messages and then examines the relationships between neighboring commits. The evaluation includes a simulation, an empirical examination of 40 repositories of open-source systems, and a manual verification. The evaluations show that the average accuracy exceeds 97% of all commits and the average precision exceeds 80%.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.39,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816475,Git;branching;merging;mining software repositories;version control,Computer science;Control systems;History;Manuals;Merging;Open source software,configuration management;data mining;merging;program compilers;public domain software;software libraries,GitHub repositories;MSR;automatic branch name recovery;commit grouping;commit message merging;manual verification;mining software repositories;open-source systems,,,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
A Validated Set of Smells in Model-View-Controller Architectures,M. Aniche; G. Bavota; C. Treude; A. V. Deursen; M. A. Gerosa,"Delft Univ. of Technol., Delft, Netherlands",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,233,243,"Code smells are symptoms of poor design and implementation choices that may hinder code comprehension, and possibly increase change-and defect-proneness. A vast catalogue of smells has been defined in the literature, and it includes smells that can be found in any kind of system (e.g., God Classes), regardless of their architecture. On the other hand, software systems adopting specific architectures (e.g., the Model-View-Controller pattern) can be also affected by other types of poor practices. We surveyed and interviewed 53 MVC developers to collect bad practices to avoid while working on Web MVC applications. Then, we followed an open coding procedure on the collected answers to define a catalogue of six Web MVC smells, namely Brain Repository, Fat Repository, Promiscuous Controller, Brain Controller, Laborious Repository Method, and Meddling Service. Then, we ran a study on 100 MVC projects to assess the impact of these smells on code change-and defect-proneness. In addition, we surveyed 21 developers to verify their perception of the defined smells. The achieved results show that the Web MVC smells (i) more often than not, increase change-and defect-proneness of classes, and (ii) are perceived by developers as severe problems.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.12,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816470,MVC;code smells;model-view-controller;software maintenance,Business;Computer architecture;Encoding;Interviews;Service-oriented architecture;Springs,Internet;program diagnostics;source code (software),Web MVC applications;Web MVC smells;brain controller;brain repository;code change-proneness;code comprehension;code defect-proneness;code smells;fat repository;laborious repository method;meddling service;model-view-controller architectures;model-view-controller pattern;open coding;promiscuous controller,,2,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
Automated Extraction of Mixins in Cascading Style Sheets,A. Charpentier; J. R. Falleri; L. Rê©veillêëre,"LaBRI, Univ. of Bordeaux, Talence, France",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,56,66,"Cascading style sheets (CSS) is a language that describes the presentation of web documents. CSS is widely adopted in web development and it is now common for web projects to have several thousands of CSS lines of code. Because the language lacks advanced features to allow code reuse, several languages such as Sass and Less have emerged as extensions to CSS. They provide mechanisms such as mixins to enable reuse. However, when a developer wants to migrate her web project from CSS to one of these extension languages, identifying mixins is a challenging task. In this paper, we describe an automated approach to extract mixins from CSS code. We have developed a tool that identifies mixins in CSS files and automatically generates Sass code. Our technique enables a fine-grained control on the generated code tailored to developer needs. We evaluate our approach on more than a hundred CSS files and conduct several case studies to assess its real-world relevance.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.15,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816454,CSS;code duplication;mixin,Cascading style sheets;Color;Context;HTML;Image color analysis;Lattices;Maintenance engineering,document handling;programming languages,CSS language;Sass code generation;Web documents;automated mixin extraction;cascading style sheets;code reuse,,,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
Using Topic Model to Suggest Fine-Grained Source Code Changes,H. A. Nguyen; A. T. Nguyen; T. N. Nguyen,,2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,200,210,"Prior research has shown that source code and its changes are repetitive. Several approaches have leveraged that phenomenon to detect and recommend change and fix patterns. In this paper, we propose TasC, a model that leverages the context of change tasks in development history to suggest fine-grained code change and fix at the program statement level. We use Latent Dirichlet Allocation (LDA) to capture the change task context via co-occurring program elements in the changes in a context. We also propose a novel technique for measuring the similarity of code fragments and code changes using the task context. We conducted an empirical evaluation on a large dataset of 88 open-source Java projects containing more than 200 thousand source files and 3.5 million source lines of code in their last revisions with 423 thousand changed methods. Our result shows that TasC relatively improves recommendation accuracy up to 130%-250% in comparison with the base models that do not use task context. Compared with other types of contexts, TasC outperforms the models using structural and co-change contexts.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.40,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816467,Code Recommendation;Fine-grained code changes;Statistical Models;Topic Modeling,Context;Context modeling;Electronic mail;History;Java;Open source software;Resource management,Java;public domain software;software engineering;source code (software);statistical analysis,LDA;TasC model;code fragment similarity;latent Dirichlet allocation;open-source Java project;software development;source code change;task context;topic model,,,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
The A?B*A Pattern: Undoing Style in CSS and Refactoring Opportunities It Presents,L. Punt; S. Visscher; V. Zaytsev,"Univ. of Amsterdam, Amsterdam, Netherlands",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,67,77,"Cascading Style Sheets (CSS) is a language widely used in contemporary web applications for defining the presentation semantics of web documents. Despite its relatively simple syntax, the language has a number of complex features like inheritance, cascading and specificity, which make CSS code challenging to understand and maintain. It has been noted in prior research that CSS code is prone to contain code smells which indicate design weaknesses and maintainability issues. In this paper we focus on one of those code smells called undoing style. It happens when a property is set to a value A, then overridden to another value B, possibly multiple times, and then set back to the original value of A. We refer to this pattern as the A?B*A pattern. We propose a technique that detects undoing style in CSS code and recommends refactoring opportunities to eliminate instances of undoing style while preserving the semantics of the web application. We evaluate our technique on 41 real-world web applications, and outline a proof of correctness for our refactoring. Our findings show that undoing style is quite prominent in CSS code. Additionally, there are many refactorings that can be applied while hardly introducing any errors.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.73,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816455,cascading style sheets;code refactoring;refactoring opportunities;smell detection,Conferences;Software maintenance,Internet;programming language semantics;software maintenance;source code (software),A?B*A pattern;CSS code;Web application;Web document presentation semantics;cascading style sheets;undoing style,,1,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,10
Continuous Delivery Practices in a Large Financial Organization,C. Vassallo; F. Zampetti; D. Romano; M. Beller; A. Panichella; M. D. Penta; A. Zaidman,"Univ. of Zurich, Zurich, Switzerland",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,519,528,"Continuous Delivery is an agile software development practice in which developers frequently integrate changes into the main development line and produce releases of their software. An automated Continuous Integration infrastructure builds and tests these changes. Claimed advantages of CD include early discovery of (integration) errors, reduced cycle time, and better adoption of coding standards and guidelines. This paper reports on a study in which we surveyed 152 developers of a large financial organization (ING Nederland), and investigated how they adopt a Continuous Integration and delivery pipeline during their development activities. In our study, we focus on topics related to managing technical debt, as well as test automation practices. The survey results shed light on the adoption of some agile methods in practice, and sometimes confirm, while in other cases, confute common wisdom and results obtained in other studies. For example, we found that refactoring tends to be performed together with other development activities, technical debt is almost always ""self-admitted"", developers timely document source code, and assure the quality of their product through extensive automated testing, with a third of respondents dedicating more than 50% of their time to do testing activities.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.72,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816504,Agile Development;Continuous Delivery;Continuous Integration;DevOps;Refactoring;Technical Debt;Test-Driven Development;Testing,Measurement;Monitoring;Organizations;Pipelines;Software;Testing,financial data processing;program testing;quality assurance;software maintenance;software prototyping;software quality;source code (software),CD;CI infrastructure;ING Nederland;agile software development;automated testing;continuous delivery;continuous integration infrastructure;document source code;financial organization;product quality assurance;software refactoring,,2,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,9
Detect Cross-Browser Issues for JavaScript-Based Web Applications Based on Record/Replay,G. Wu; M. He; H. Tang; J. Wei,,2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,78,87,"With the advent of Web 2.0 application, and the increasing number of browsers and platforms on which the applications can be executed, cross-browser incompatibilities (XBIs) are becoming a serious problem for organizations to develop web-based software. Although some techniques and tools have been proposed to identify XBIs, a number of false positives and false negatives still exist as they cannot assure the same execution when the application runs across different browsers. To address this limitation, leveraging existing record/replay technique, we developed X-Check, a novel cross-browser testing technique and tool, which supports automated XBIs detection with high accuracy. Our empirical evaluation shows that X-Check is effective and improves the state of the art.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.28,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816456,cross-browser issues;record/replay;web application,Browsers;Crawlers;Data mining;Servers;Space exploration;Testing;Timing,Internet;program testing;software engineering,JavaScript-based Web applications;Web 2.0 application;Web-based software development;X-Check tool;XBI;cross-browser incompatibilities;cross-browser issues detection;cross-browser testing technique;record-replay techniques,,1,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,9
Integration of Static and Dynamic Code Analysis for Understanding Legacy Source Code,W. Kirchmayr; M. Moser; L. Nocke; J. Pichler; R. Tober,"Voestalpine Stahl GmbH, Linz, Austria",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,543,552,"In software development we are faced with the problem to comprehend and take over source code from other developers. The key challenge is to understand the underlying specification implemented by the software system. Regaining this understanding is more difficult when the source code is the only reliable source of information, documentation is outdated or only present in fragments, and original developers are not available anymore. Unfortunately, we encounter such situations frequently for scientific and engineering software systems, developed in industry. For instance, process models in the steelmaking domain are developed and maintained over decades by single engineers. If such an engineer leaves the company, he/she literally leaves behind a legacy system for another person (or team). We propose tool support combining static and dynamic program analysis to tackle this challenge. Using static program analysis we extract the input/output behavior from program source code and present the extracted information besides the analyzed source code, providing seamless navigation between both views. Dynamic program analysis allows developers to examine input/output behavior for single program executions and thereby gain insight into standard behavior and exceptional cases. In this paper we present requirements on tool support integrating static and dynamic code analysis, briefly describe the implementation of the tool and report on its application to a C++ program source in the industry. Furthermore, we discuss challenges in the present implementation as well as the potential and limitations of using the tool in general.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.70,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816507,Documentation Generation;Reverse Engineering;Software Maintenance,Adaptation models;Analytical models;Computational modeling;Data models;Documentation;Object oriented modeling;Software,program diagnostics;source code (software),C++ program source;dynamic code analysis;legacy source code understanding;program execution;software development;static code analysis;static program analysis;tool support,,,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,9
Introducing Traceability and Consistency Checking for Change Impact Analysis across Engineering Tools in an Automation Solution Company: An Experience Report,A. Demuth; R. Kretschmer; A. Egyed; D. Maes,"Inst. for Software Syst. Eng., Johannes Kepler Univ., Linz, Austria",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,529,538,"In today's engineering projects, companies continuously have to adapt their systems to changing customer or market requirements. This requires a flexible, iterative development process in which different parts of the system under construction are built and updated concurrently. However, concurrent engineering is quite problematic in domains where different engineering domains and different engineering tools come together. In this paper, we discuss experiences with Van Hoecke Automation, a leading company in the areas of production automation and product processing, in maintaining the consistency between electrical models and the corresponding software controller when both are subject to continuous change. The paper discusses how we let engineers describe the relationships between electrical model and software code in form of links and consistency rules, and how through continuous consistency checking our approach then notified those engineers of the erroneous impact of changes in either electrical model or code.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.50,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816505,Traceability;incremental consistency checking;model-driven engineering;software evolution,Automation;Companies;Hardware;Production;Safety;Software design,concurrent engineering;formal verification;production engineering computing;program diagnostics;software maintenance;software tools;source code (software),Van Hoecke automation;automation solution company;change impact analysis;concurrent engineering;consistency checking;electrical model;engineering tools;product processing;production automation;software code;software controller;system under construction;traceability,,,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,9
How Can We Help Software Rearchitecting Efforts? Study of an Industrial Case,B. Govin; N. Anquetil; A. Etien; S. Ducasse; A. Monegier,"Air Syst., Thales, Rungis, France",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,509,518,"Legacy software systems are valuable assets for organisations and are sometimes their main source of incomes. From time to time, renewing legacy software system architecture becomes necessary in order to offer them a new future. Migrating the architecture of a legacy software system is a difficult task. It involves understanding and aggregating a large set of data (the entire source code, dependencies, etc.), it may have a profound impact on the system's behaviour, and because it occurs very rarely in the life of a system, it is hard to gain experience in this domain. Based on the study of an industrial architecture migration case, we discuss how this essentially manual effort could be helped with automated tools and a better defined process. We identified several issues raised during the task, characterized their impact, and proposed possible solutions.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.43,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816503,,Companies;Computer architecture;Reverse engineering;Service-oriented architecture;Software systems,software architecture;software maintenance,industrial architecture migration case;legacy software systems;software rearchitecting effort;software system renewal,,,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,9
A Case Study of Automated Feature Location Techniques for Industrial Cost Estimation,A. Armaly; J. Klaczynski; C. McMillan,"Dept. of Comput. Sci. & Eng., Univ. of Notre Dame, Notre Dame, IN, USA",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,553,562,"We present a case study of feature location in industry. We study two off-the-shelf feature location algorithms for use as input to a software cost estimator. The feature location algorithms that we studied map program requirements to one or more function points. The cost estimator product, which is the industrial context in which we study feature location, transforms the list of function points into an estimate of the resources necessary to implement that requirement. We chose the feature location algorithms because they are simple to explain, deploy and maintain as a project evolves and personnel rotate on and off. We tested both feature location algorithms against a large software system with a development lifespan of over 20 years. We compared both algorithms by surveying our industrial partner about the accuracy of the list of function points produced by each algorithm. To provide further evidence, we compared both algorithms against an open source benchmarking dataset. Finally, we discuss the requirements of the industrial environment and the ways in which it differs from the academic environment. Our industrial partner elected to use Lucene combined with the PageRank algorithm as their feature location algorithm because it balanced accuracy with simplicity.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.76,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816508,Feature Location;Function Points;Industry,Algorithm design and analysis;Complexity theory;Context;Estimation;Heuristic algorithms;Software;Software algorithms,production engineering computing;public domain software;search engines;software cost estimation;systems analysis,PageRank algorithm;automated feature location;industrial cost estimation;large software system;open source benchmarking dataset;program requirement mapping;software cost estimator,,2,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,9
Customized Regression Testing Using Telemetry Usage Patterns,J. Anderson; H. Do; S. Salem,"Microsoft, North Dakota State Univ., Fargo, ND, USA",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,572,581,"Pervasive telemetry in modern applications is providing new possibilities in the application of regression testing techniques. Similar to how research in bioinformatics is leading to personalized medicine, tailored to individuals, usage telemetry in modern software allows for custom regression testing, tailored to the usage patterns of an installation. By customizing regression testing based on software usage, the effectiveness of regression testing techniques can be greatly improved, leading to reduced testing costs and enhanced detection of defects that are most important to that customer. In this research, we introduce the concept of fingerprinting software usage patterns through telemetry. We provide various algorithms tocompute fingerprints and conduct an empirical study that shows that fingerprints are effective in identifying distinct usage patterns. Further, we discuss how usage fingerprints can be used to improve regression test prioritization run time by over 30 percent compared to traditional prioritization techniques.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.30,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816511,regression testing;telemetry,Companies;Computer bugs;Software algorithms;Software as a service;Telemetry;Testing,program testing;regression analysis,bioinformatics;pervasive telemetry;regression test prioritization;regression testing technique;software usage;software usage pattern fingerprinting;telemetry usage pattern,,,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,9
Improving Code Maintainability: A Case Study on the Impact of Refactoring,M. Wahler; U. Drofenik; W. Snipes,"ABB Corp. Res., Baden-Da&#x0308;ttwil, Switzerland",2016 IEEE International Conference on Software Maintenance and Evolution (ICSME),20170116,2016,,,493,501,"It is a fact that a lot of software is written by people without a formal education in software engineering. As an example, material scientists often capture their knowledge in the form of simulation software that contains sophisticated algorithms representing complex physical concepts. Since software engineering is typically not a core skill of these scientists, there is a risk that their software becomes unmaintainable once it reaches a substantial size or structural complexity. This paper reports on a case study in which software engineers consulted magnetics researchers in refactoring their simulation software. This software had grown to 30 kloc of Java and was considered unmaintainable by the stakeholders of the research project. The case study describes the process of refactoring a system under the guidance of a software engineer with results supported by static analysis and software metrics. It shows how software engineers evaluated and selected refactorings to apply to the system using their expert judgment with input from static analysis tools and discusses the outcome of refactoring as evaluated by code owners and reported via static analysis metrics.",,Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7,10.1109/ICSME.2016.52,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816501,,Complexity theory;Graphical user interfaces;Java;Magnetics;Software;Software engineering;Windings,program diagnostics;software maintenance;software metrics,Java;code maintainability;simulation software;software engineering;software metrics;software refactoring;static analysis,,,,,,,,2-7 Oct. 2016,,IEEE,IEEE Conferences,,8
SimEvo: Testing Evolving Multi-process Software Systems,T. Yu,"Dept. of Comput. Sci., Univ. of Kentucky, Lexington, KY, USA",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,204,215,"Regression testing is used to perform re-validation of evolving software. However, most existing techniques for regression testing focus exclusively on single-process applications, but to date, no work has considered regression testing for software involving multiple processes or event handlers (e.g., software signals) at the system-level. The unique characteristics of concurrency control mechanism employed at the system-level can affect the static and dynamic analysis techniques on which existing regression testing approaches rely. Therefore, applying these approaches can result in inadequately tested software during maintenance, and ultimately impair software quality. In this paper, we propose SimEvo, the first regression testing techniques for multi-process applications. SimEvo employs novel impact analysis techniques to identify system-level concurrent events that are affected by the changes. It then reuses existing test cases, as well as generating new test cases, focused on the set of impacted events, to effectively and efficiently explore the newly updated concurrent behaviors. Our empirical study on a set of real-world Linux applications shows that SimEvo is more cost-effective in achieving high inter-process coverage and revealing real world system-level concurrency faults than other approaches.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.29,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094422,change impact analysis;regression testing;system-level concurrency,Concurrent computing;Linux;Process control;Software systems;Synchronization;Testing,Linux;concurrency control;program diagnostics;program testing;program verification;regression analysis;software maintenance;software quality,Linux applications;SimEvo;concurrency control;dynamic analysis techniques;multiprocess software systems;regression testing;software maintenance;software quality;software re-validation;software testing;static analysis techniques;system-level concurrency faults,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,11
An Empirical Study of Local Database Usage in Android Applications,Y. Lyu; J. Gui; M. Wan; W. G. J. Halfond,"Dept. of Comput. Sci., Univ. of Southern California, Los Angeles, CA, USA",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,444,455,"Local databases have become an important component within mobile applications. Developers use local databases to provide mobile users with a responsive and secure service for data storage and access. However, using local databases comes with a cost. Studies have shown that they are one of the most energy consuming components on mobile devices and misuseof their APIs can lead to performance and security problems. In this paper, we report the results of a large scale empirical study on 1,000 top ranked apps from the Google Play app store. Our results present a detailed look into the practices, costs, and potential problems associated with local database usage in deployed apps. We distill our findings into actionable guidance for developers and motivate future areas of research related to techniques to support mobile app developers.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.75,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094443,database;empirical study;energy;mobile applications;performance;security,Best practices;Databases;Mobile communication;Mobile handsets;Reliability;Runtime;Security,application program interfaces;database management systems;mobile computing;security of data;smart phones;software engineering,API;Android applications;data storage;local database usage;mobile app developers;mobile applications;mobile devices;mobile users;responsive service;secure service;security problems,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,11
Does Refactoring of Test Smells Induce Fixing Flaky Tests?,F. Palomba; A. Zaidman,"Delft Univ. of Technol., Delft, Netherlands",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,1,12,"Regression testing is a core activity that allows developers to ensure that source code changes do not introduce bugs. An important prerequisite then is that test cases are deterministic. However, this is not always the case as some tests suffer from socalled flakiness. Flaky tests have serious consequences, as they can hide real bugs and increase software inspection costs. Existing research has focused on understanding the root causes of test flakiness and devising techniques to automatically fix flaky tests; a key area of investigation being concurrency. In this paper, we investigate the relationship between flaky tests and three previously defined test smells, namely Resource Optimism, Indirect Testing and Test Run War.We have set up a study involving 19,532 JUnit test methods belonging to 18 software systems. A key result of our investigation is that 54% of tests that are flaky contain a test code smell that can cause the flakiness. Moreover, we found that refactoring the test smells not only removed the design flaws, but also fixed all 54% of flaky tests causally co-occurring with test smells.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.12,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094404,Flaky Tests;Refactoring;Test Smells,Computer bugs;Java;Production;Software systems;Testing;Tools,program testing;software fault tolerance;software maintenance;source code (software),JUnit test methods;indirect testing;regression testing;resource optimism;source code;test flakiness;test run war;test smells refactoring,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,11
CCLearner: A Deep Learning-Based Clone Detection Approach,L. Li; H. Feng; W. Zhuang; N. Meng; B. Ryder,"Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,249,260,"Programmers produce code clones when developing software. By copying and pasting code with or without modification, developers reuse existing code to improve programming productivity. However, code clones present challenges to software maintenance: they may require consistent application of the same or similar bug fixes or program changes to multiple code locations. To simplify the maintenance process, various tools have been proposed to automatically detect clones [1], [2], [3], [4], [5], [6]. Some tools tokenize source code, and then compare the sequence or frequency of tokens to reveal clones [1], [3], [4], [5]. Some other tools detect clones using tree-matching algorithms to compare the Abstract Syntax Trees (ASTs) of source code [2], [6]. In this paper, we present CCLEARNER, the first solely token-based clone detection approach leveraging deep learning. CCLEARNER extracts tokens from known method-level code clones and nonclones to train a classifier, and then uses the classifier to detect clones in a given codebase. To evaluate CCLEARNER, we reused BigCloneBench [7], an existing large benchmark of real clones. We used part of the benchmark for training and the other part for testing, and observed that CCLEARNER effectively detected clones. With the same data set, we conducted the first systematic comparison experiment between CCLEARNER and three popular clone detection tools. Compared with the approaches not using deep learning, CCLEARNER achieved competitive clone detection effectiveness with low time cost.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.46,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094426,clone detection;deep learning;empirical,Cloning;Feature extraction;Machine learning;Neural networks;Testing;Tools;Training,learning (artificial intelligence);pattern classification;program debugging;program diagnostics;public domain software;software maintenance;software reusability;source code (software);trees (mathematics),AST;BigCloneBench;CCLEARNER;CCLearner;abstract syntax trees;bug fixes;classifier training;clone detection tools;code locations;code reuse;codebase;competitive clone detection effectiveness;deep learning-based clone detection approach;method-level code clones;program changes;programming productivity;software development;software maintenance;source code tokenization;token-based clone detection approach;tree-matching algorithms,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,11
Using Observed Behavior to Reformulate Queries during Text Retrieval-based Bug Localization,O. Chaparro; J. M. Florez; A. Marcus,"Univ. of Texas at Dallas, Richardson, TX, USA",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,376,387,"Text Retrieval (TR)-based approaches for bug localization rely on formulating an initial query based on a bug report. Often, the query does not return the buggy software artifacts at or near the top of the list (i.e., it is a low-quality query). In such cases, the query needs reformulation. Existing research on supporting developers in the reformulation of queries focuses mostly on leveraging relevance feedback from the user or expanding the original query with additional information (e.g., adding synonyms). In many cases, the problem with such lowquality queries is the presence of irrelevant terms (i.e., noise) and previous research has shown that removing such terms from the queries leads to substantial improvement in code retrieval. Unfortunately, the current state of research lacks methods to identify the irrelevant terms. Our research aims at addressing this problem and our conjecture is that reducing a low-quality query to only the terms describing the Observed Behavior (OB) can improve TR-based bug localization. To verify our conjecture, we conducted an empirical study using bug data from 21 open source systems to reformulate 451 low-quality queries. We compare the accuracy achieved by four TR-based bug localization approaches at three code granularities (i.e., files, classes, and methods), when using the complete bug reports as queries versus a reduced version corresponding to the OB only. The results show that the reformulated queries improve TR-based bug localization for all approaches by 147.4% and 116.6% on average, in terms of MRR and MAP, respectively. We conclude that using the OB descriptions is a simple and effective technique to reformulate low-quality queries during TR-based bug localization.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.100,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094437,Bug Localization;Observed Behavior;Query Reformulation;Text Retrieval,Computer bugs;History;Natural languages;Noise measurement;Software systems;Software testing,program debugging;query processing;relevance feedback;text analysis,MAP;MRR;OB;TR-based approaches;TR-based bug localization;bug data;bug localization approaches;bug reports;buggy software artifacts;code retrieval;low-quality query;observed behavior;open source systems;query reformulation;relevance feedback;text retrieval-based bug localization,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,11
"Continuous, Evolutionary and Large-Scale: A New Perspective for Automated Mobile App Testing",M. Linares-Vêçsquez; K. Moran; D. Poshyvanyk,"Univ. de los Andes, Bogota, Colombia",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,399,410,"Mobile app development involves a unique set of challenges including device fragmentation and rapidly evolving platforms, making testing a difficult task. The design space for a comprehensive mobile testing strategy includes features, inputs, potential contextual app states, and large combinations of devices and underlying platforms. Therefore, automated testing is an essential activity of the development process. However, current state of the art of automated testing tools for mobile apps posses limitations that has driven a preference for manual testing in practice. As of today, there is no comprehensive automated solution for mobile testing that overcomes fundamental issues such as automated oracles, history awareness in test cases, or automated evolution of test cases.In this perspective paper we survey the current state of the art in terms of the frameworks, tools, and services available to developers to aid in mobile testing, highlighting present shortcomings. Next, we provide commentary on current key challenges that restrict the possibility of a comprehensive, effective, and practical automated testing solution. Finally, we offer our vision of a comprehensive mobile app testing framework, complete with research agenda, that is succinctly summarized along three principles: Continuous, Evolutionary and Large-scale (CEL).",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.27,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094439,,Automation;Graphical user interfaces;Manuals;Mobile communication;Systematics;Testing;Tools,mobile computing;program testing,"Continuous, Evolutionary and Large-scale;automated evolution;automated mobile app testing;automated oracles;automated testing tools;comprehensive automated solution;comprehensive mobile app testing framework;comprehensive mobile testing strategy;comprehensive testing solution;contextual app states;development process;device fragmentation;effective testing solution;mobile app development;practical automated testing solution;test cases",,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,11
AimDroid: Activity-Insulated Multi-level Automated Testing for Android Applications,T. Gu; C. Cao; T. Liu; C. Sun; J. Deng; X. Ma; J. Lê_,"State Key Lab. for Novel Software Technol., Nanjing Univ., Nanjing, China",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,103,114,"Activities are the fundamental components of Android applications (apps). However, existing approaches to automated testing for Android apps cannot effectively manage the transitions between activities, e.g., too rarely or too often. Besides, some techniques need to repeatedly restart from scratch and revisit every intermediate activity to reach a specific one, which leads to unnecessarily long transitions and wasted time. To address these problems, we propose AimDroid, a practical model-based approach to automated testing for Android apps that aims to manage the exploration of activities and meantime minimize unnecessary transitions between them. Specifically, AimDroid applies an activity-insulated multi-level strategy during testing and replaying. It systematically discovers unexplored activities and then intensively exploits every discovered individual with a reinforcement learning guided random algorithm. We conduct comprehensive experiments on 50 popular closed-source commercial apps that in total have billions of daily usages in China. The results demonstrate that AimDroid outperforms both Sapienz and Monkey in activity, method and instruction coverage, respectively. In addition, AimDroid also reports more crashes than the other two.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.72,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094413,Android Application Testing;Model-based Testing;Reinforcement Learning,Androids;Computer crashes;Graphical user interfaces;Humanoid robots;Smart phones;Systematics;Testing,Android (operating system);learning (artificial intelligence);mobile computing;program testing;public domain software,AimDroid;Android applications;activity-insulated multi-level strategy;activity-insulated multilevel automated testing;automated testing;closed-source commercial apps;reinforcement learning,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,11
An Exploratory Study of Performance Regression Introducing Code Changes,J. Chen; W. Shang,"Dept. of Comput. Sci. & Software Eng., Concordia Univ. - Montreal, Montreal, QC, Canada",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,341,352,"Performance is an important aspect of software quality. In fact, large software systems failures are often due to performance issues rather than functional bugs. One of the most important performance issues is performance regression. Examples of performance regressions are response time degradation and increased resource utilization. Although performance regressions are not all bugs, they often have a direct impact on users' experience of the system. Due to the possible large impact of performance regressions, prior research proposes various automated approaches that detect performance regressions. However, the detection of performance regressions is conducted after the fact, i.e., after the system is built and deployed in the field or dedicated performance testing environments. On the other hand, there exists rich software quality research that examines the impact of code changes on software quality; while a majority of prior findings do not use performance regression as a sign of software quality degradation. In this paper, we perform an exploratory study on the source code changes that introduce performance regressions. We conduct a statistically rigorous performance evaluation on 1,126 commits from ten releases of Hadoop and 135 commits from five releases of RxJava. In particular, we repetitively run tests and performance micro-benchmarks for each commit while measuring response time, CPU usage, Memory usage and I/O traffic. We identify performance regressions in each test or performance micro-benchmark if there exists statistically significant degradation with medium or large effect sizes, in any performance metric. We find that performance regressions widely exist during the development of both subject systems. By manually examining the issue reports that are associated with the identified performance regression introducing commits, we find that the majority of the performance regressions are introduced while fixing other bugs. In addition, we id- ntify six root-causes of performance regressions. 12.5% of the examined performance regressions can be avoided or their impact may be reduced during development. Our findings highlight the need for performance assurance activities during development. Developers should address avoidable performance regressions and be aware of the impact of unavoidable performance regressions.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.13,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094434,Code Changes;Mining Software Repositories;Performance Regression,Computer bugs;Performance evaluation;Software quality;Software systems;Time factors,data handling;program debugging;program testing;public domain software;regression analysis;software performance evaluation;software quality,CPU usage;Hadoop;I/O traffic;RxJava;code changes;large software systems failures;memory usage;performance microbenchmarks;performance regression;resource utilization;response time;response time degradation;software quality,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,11
Evaluating State-of-the-Art Free and Open Source Static Analysis Tools Against Buffer Errors in Android Apps,B. Aloraini; M. Nagappan,"Sch. of Comput. Sci., Univ. of Waterloo, Waterloo, ON, Canada",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,295,306,"Modern mobile apps incorporate rich and complex features, opening the doors for different security concerns. Android is the dominant platform in mobile app markets, and enhancing its apps security is a considerable area of research. Android malware (introduced intentionally by developers) has been well studied and many tools are available to detect them. However, little attention has been directed to address vulnerabilities caused unintentionally by developers in Android apps. Static analysis has been one way to detect such vulnerabilities in traditional desktop and server side desktop. Therefore, our research aims at assessing static analysis tools that could be used by Android developers. Our preliminary analysis revealed that Buffer Errors are the most frequent type of vulnerabilities that threaten Android apps. Also, we found that Buffer Errors in Android apps have the highest risk on Android that affects data integrity, confidentiality, and availability. Our main study therefore tested whether state-of-the-art static analysis tools could detect Buffer Errors in Android apps. We investigated 6 static analysis tools that are designed to detect Buffer Errors. The study shows that the free and open source state-of-the-art static analysis tools do not efficiently discover Buffer Error vulnerabilities in Android apps. We analyzed the tools carefully to see why they could not discover Buffer Errors and found that the lack of semantic analysis capabilities, inapplicability to Android apps, and the gap between native code and other contexts were some of the reasons. Thus, we concluded that there is a need to build better free and open source static analysis tools for detecting Buffer Errors in Android apps.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.77,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094430,Android Security;Buffer Errors;Static Analysis Tools,Androids;Databases;Humanoid robots;Security;Software;Static analysis;Tools,Android (operating system);invasive software;mobile computing;program diagnostics;public domain software,Android applications;Android malware;buffer errors;data availability;data confidentiality;data integrity;free-open source static analysis tools;static analysis tools,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,11
Supervised vs Unsupervised Models: A Holistic Look at Effort-Aware Just-in-Time Defect Prediction,Q. Huang; X. Xia; D. Lo,"Coll. of Comput. Sci. & Technol., Zhejiang Univ., Hangzhou, China",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,159,170,"Effort-aware just-in-time (JIT) defect prediction aims at finding more defective software changes with limited code inspection cost. Traditionally, supervised models have been used; however, they require sufficient labelled training data, which is difficult to obtain, especially for new projects. Recently, Yang et al. proposed an unsupervised model (LT) and applied it to projects with rich historical bug data. Interestingly, they reported that, under the same inspection cost (i.e., 20 percent of the total lines of code modified by all changes), it could find more defective changes than a state-of-the-art supervised model (i.e., EALR). This is surprising as supervised models that benefit from historical data are expected to perform better than unsupervised ones. Their finding suggests that previous studies on defect prediction had made a simple problem too complex. Considering the potential high impact of Yang et al.'s work, in this paper, we perform a replication study and present the following new findings: (1) Under the same inspection budget, LT requires developers to inspect a large number of changes necessitating many more context switches. (2) Although LT finds more defective changes, many highly ranked changes are false alarms. These initial false alarms may negatively impact practitioners' patience and confidence. (3) LT does not outperform EALR when the harmonic mean of Recall and Precision (i.e., F1-score) is considered. Aside from highlighting the above findings, we propose a simple but improved supervised model called CBS. When compared with EALR, CBS detects about 15% more defective changes and also significantly improves Precision and F1-score. When compared with LT, CBS achieves similar results in terms of Recall, but it significantly reduces context switches and false alarms before first success. Finally, we also discuss the implications of our findings for practitioners and researchers.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.51,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094418,Bias;Change Classification;Cost Effectiveness;Evaluation,Analytical models;Computer bugs;Feature extraction;Inspection;Measurement;Predictive models;Software,inspection;just-in-time;learning (artificial intelligence);program debugging;public domain software;software cost estimation;software maintenance;software metrics,CBS;EALR;JIT defect prediction;LT;code inspection cost;defective software;effort-aware just-in-time defect prediction;harmonic mean;historical bug data;inspection budget;unsupervised model,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,11
Understanding Android Application Programming and Security: A Dynamic Study,H. Cai; B. G. Ryder,"Washington State Univ., Pullman, WA, USA",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,364,375,"Most existing research for Android focuses on particular security issues, yet there is little broad understanding of Android application run-time characteristics and their implications. To mitigate this gap, we present the first systematic dynamic characterization study of Android apps that targets a broad understanding of application behaviors in Android. Through lightweight method-level profiling, we collected 59GB traces of method calls and Intent-based inter-component communication (ICC) from 125 popular Android apps and 62 pairs among them that enabled an intensive empirical investigation of their run-time behaviors. Our study revealed that, among other findings, (1) the application executions were overwhelmingly dominated by the Android framework, (2) Activity components dominated over other types of components and were responsible for most lifecycle callbacks (3) most event handlers dealt with user interactions as opposed to system events, (4) the majority of exercised ICCs did not carry any data payloads, and (5) sensitive data sources and sinks targeted only one/two dominant categories of information or operations. We also discuss the implications of our results for cost-effective program analysis and security defense for Android.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.31,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094436,Android;ICC;dynamic characterization;execution structure;security,Androids;Benchmark testing;Humanoid robots;Instruments;Measurement;Security;Tools,Android (operating system);mobile computing;object-oriented programming;program diagnostics;security of data;smart phones,Android application run-time characteristics;Android framework;activity components;application behaviors;application executions;cost-effective program analysis;event handlers;intent-based intercomponent communication;lifecycle callbacks;lightweight method-level profiling;method calls;popular Android apps;run-time behaviors;security defense;security issues;sensitive data sources;system events;systematic dynamic characterization;user interactions,,1,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,11
Revisiting Turnover-Induced Knowledge Loss in Software Projects,M. Nassif; M. P. Robillard,"Sch. of Comput. Sci., McGill Univ., Montreal, QC, Canada",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,261,272,"In large software projects, tacit knowledge of the system is threatened by developer turnover. When a developer leaves the project, their knowledge may be lost if the other developers do not understand the design decisions made by the leaving developer. Understanding the source code written by leaving developers thus becomes a burden for their successors. In a previous paper, Rigby et al. reported on a case study of turnover-induced knowledge loss in two large projects, Chromium and a project at Avaya, using risk evaluation methods usually applied to financial systems. They found that the two projects were susceptible to large knowledge losses that are more than three times the average loss. We report on a replication of their study on the Chromium project, as well as seven other large and medium-sized open source projects. We also extended theirwork by studying two variations of the knowledge loss metric, as well as the location and persistence of abandoned files. We found that all projects had a similar knowledge loss probability distribution, but extreme knowledge loss can be more severe than those originally discovered in Chromium and the project at Avaya. We also found that, in the systems under study, abandoned files often remained in the system for long periods.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.64,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094427,Developer Turnover;Knowledge Distribution;Mining Software Repository;Quantitative Risk Management;Replication study,Adaptation models;Chromium;History;Loss measurement;Probability distribution;Software,knowledge management;project management;public domain software;risk analysis;software management;statistical distributions,Avaya project;Chromium project;knowledge loss metric;knowledge loss probability distribution;open source projects;risk evaluation methods;software projects;tacit knowledge;turnover-induced knowledge loss,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,11
The Co-evolution of Test Maintenance and Code Maintenance through the Lens of Fine-Grained Semantic Changes,S. Levin; A. Yehudai,"Blavatnik Sch. of Comput. Sci., Tel Aviv Univ., Tel-Aviv, Israel",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,35,46,"Automatic testing is a widely adopted technique for improving software quality. Software developers add, remove and update test methods and test classes as part of the software development process as well as during the evolution phase, following the initial release. In this work we conduct a large scale study of 61 popular open source projects and report the relationships we have established between test maintenance, production code maintenance, and semantic changes (e.g, statement added, method removed, etc.). performed in developers' commits.We build predictive models, and show that the number of tests in a software project can be well predicted by employing code maintenance profiles (i.e., how many commits were performed in each of the maintenance activities: corrective, perfective, adaptive). Our findings also reveal that more often than not, developers perform code fixes without performing complementary test maintenance in the same commit (e.g., update an existing test or add a new one). When developers do perform test maintenance, it is likely to be affected by the semantic changes they perform as part of their commit.Our work is based on studying 61 popular open source projects, comprised of over 240,000 commits consisting of over 16,000,000 semantic change type instances, performed by over 4,000 software engineers.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.9,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094407,Human Factors;Mining Software Repositories;Predictive Models;Software Maintenance;Software Testing;Software metrics,Java;Maintenance engineering;Predictive models;Production;Semantics;Software;Tools,program testing;software development management;software maintenance;software quality,automatic testing;change type instances;code maintenance profiles;open source projects;production code maintenance;software developers;software development process;software engineers;software project;software quality;test maintenance,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,11
Software Practitioner Perspectives on Merge Conflicts and Resolutions,S. McKee; N. Nelson; A. Sarma; D. Dig,"Oregon State Univ., Corvallis, OR, USA",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,467,478,"Merge conflicts occur when software practitioners need to work in parallel and are inevitable in software development. Tool builders and researchers have focused on the prevention and resolution of merge conflicts, but there is little empirical knowledge about how practitioners actually approach and perform merge conflict resolution. Without such knowledge, tool builders might be building on wrong assumptions and researchers might miss opportunities for improving the state of the art.We conducted semi-structured interviews of 10 software practitioners across 7 organizations, including both open-source and commercial projects. We identify the key concepts and perceptions from practitioners, which we then validated via a survey of 162 additional practitioners.We find that practitioners are directly impacted by their perception of the complexity of the conflicting code, and may alter the timeline in which to resolve these conflicts, as well as the methods employed for conflict resolution based upon that initial perception. Practitioners' perceptions alter the impact of tools and processes that have been designed to preemptively and efficiently resolve merge conflicts. Understanding whether practitioners will react according to standard use cases is important when creating human-oriented tools to support development processes.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.53,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094445,conflict resolution;merge conflicts;perspectives,Complexity theory;Encoding;Face;Interviews;Organizations;Software;Tools,configuration management;organisational aspects;software maintenance,commercial projects;conflict resolution;conflicting code;human-oriented tools;merge conflicts;open-source projects;software development;software practitioner perspectives,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,11
Heterogeneous Defect Prediction Through Multiple Kernel Learning and Ensemble Learning,Z. Li; X. Y. Jing; X. Zhu; H. Zhang,"State Key Lab. of Software Eng., Wuhan Univ., Wuhan, China",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,91,102,"Heterogeneous defect prediction (HDP) aims to predict defect-prone software modules in one project using heterogeneous data collected from other projects. Recently, several HDP methods have been proposed. However, these methods do not sufficiently incorporate the two characteristics of the defect prediction data: (1) data could be linearly inseparable, and (2) data could be highly imbalanced. These two data characteristics make it challenging to build an effective HDP model. In this paper, we propose a novel Ensemble Multiple Kernel Correlation Alignment (EMKCA) based approach to HDP, which takes into consideration the two characteristics of the defect prediction data. Specifically, we first map the source and target project data into high dimensional kernel space through multiple kernel leaning, where the defective and non-defective modules can be better separated. Then, we design a kernel correlation alignment method to make the data distribution of the source and target projects similar in the kernel space. Finally, we integrate multiple kernel classifiers with ensemble learning to relieve the influence caused by class imbalance problem, which can improve the accuracy of the defect prediction model. Consequently, EMKCA owns the advantages of both multiple kernel learning and ensemble learning. Extensive experiments on 30 public projects show that EMKCA outperforms the related competing methods.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.19,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094412,class imbalance;ensemble learning;heterogeneous defect prediction;kernel correlation alignment;linearly inseparable;multiple kernel learning,Correlation;Data models;Kernel;Measurement;Predictive models,learning (artificial intelligence);pattern classification;software quality,HDP methods;HDP model;data characteristics;data distribution;defect prediction data;defect-prone software modules;ensemble multiple kernel correlation alignment based approach;heterogeneous data;heterogeneous defect prediction;high dimensional kernel space;kernel correlation alignment method;multiple kernel classifiers;multiple kernel learning;target project data;target projects,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,11
Towards Activity-Aware Tool Support for Change Tasks,K. Kevic; T. Fritz,"Dept. of Inf., Univ. of Zurich, Zurich, Switzerland",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,171,182,"To complete a change task, software developers perform a number of activities, such as locating and editing the relevant code. While there is a variety of approaches to support developers for change tasks, these approaches mainly focus on a single activity each. Given the wide variety of activities during a change task, a developer has to keep track of and switch between the different approaches. By knowing more about a developer's activities and in particular by knowing when she is working on which activity, we would be able to provide better and more tailored tool support, thereby reducing developer effort.In our research we investigate the characteristics of these activities, whether they can be identified, and whether we can use this additional information to improve developer support for change tasks. We conducted two exploratory studies with a total of 21 software developers collecting data on activities in the lab and field. An empirical analysis of the data shows, amongst other results, that activities comprise a consistently small amount of code elements across all developers and tasks (approx. 8.7 elements). Further analysis of the data shows, that we can automatically detect the boundaries and types of activities, and that the information on activity types can be used to improve the identification of relevant code elements.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.48,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094419,activities;change task;interaction,Computer bugs;Distance measurement;Navigation;Software;Switches;Tools,data analysis;software tools,activity-aware tool support;change tasks;data analysis;software developers,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,11
Learning to Predict Severity of Software Vulnerability Using Only Vulnerability Description,Z. Han; X. Li; Z. Xing; H. Liu; Z. Feng,"Tianjin Key Lab. of Adv. Networking, Tianjin Univ., Tianjin, China",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,125,136,"Software vulnerabilities pose significant security risks to the host computing system. Faced with continuous disclosure of software vulnerabilities, system administrators must prioritize their efforts, triaging the most critical vulnerabilities to address first. Many vulnerability scoring systems have been proposed, but they all require expert knowledge to determine intricate vulnerability metrics. In this paper, we propose a deep learning approach to predict multi-class severity level of software vulnerability using only vulnerability description. Compared with intricate vulnerability metrics, vulnerability description is the ""surface level"" information about how a vulnerability works. To exploit vulnerability description for predicting vulnerability severity, discriminative features of vulnerability description have to be defined. This is a challenging task due to the diversity of software vulnerabilities and the richness of vulnerability descriptions. Instead of relying on manual feature engineering, our approach uses word embeddings and a one-layer shallow Convolutional Neural Network (CNN) to automatically capture discriminative word and sentence features of vulnerability descriptions for predicting vulnerability severity. We exploit large amounts of vulnerability data from the Common Vulnerabilities and Exposures (CVE) database to train and test our approach.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.52,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094415,deep learning;mining software repositories;multi-class classification;vulnerability severity prediction,Databases;Feature extraction;Measurement;Security;Software;Vocabulary,learning (artificial intelligence);neural nets;risk management;security of data,CNN;convolutional neural network;deep learning approach;intricate vulnerability metrics;security risks;software vulnerability severity prediction;vulnerability description,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,11
On the Optimal Order of Reading Source Code Changes for Review,T. Baum; K. Schneider; A. Bacchelli,"FG Software Eng., Leibniz Univ. Hannover, Hannover, Germany",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,329,340,"Change-based code review, e.g., in the form of pull requests, is the dominant style of code review in practice. An important option to improve review's efficiency is cognitive support for the reviewer. Nevertheless, review tools present the change parts under review sorted in alphabetical order of file path, thus leaving the effort of understanding the construction, connections, and logic of the changes on the reviewer. This leads to the question: How should a code review tool order the parts of a code change to best support the reviewer? We answer this question with a middle-range theory, which we generated inductively in a mixed methods study, based on interviews, an online survey, and existing findings from related areas. Our results indicate that an optimal order is mainly an optimal grouping of the change parts by relatedness. We present our findings as a collection of principles and formalize them as a partial order relation among review orders.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.28,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094433,Change-based code review;Cognitive support review tools;Modern code review;Program comprehension;Pull-based development,Industries;Interviews;Navigation;Software;Software engineering;Tools,program diagnostics;public domain software;software quality;source code (software),alphabetical order;change parts;change-based code review;code review tool;middle-range theory;optimal grouping;optimal order;partial order relation;review efficiency;review orders;review tools;reviewer;source code change reading,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,11
Bug Propagation through Code Cloning: An Empirical Study,M. Mondal; C. K. Roy; K. A. Schneider,"Dept. of Comput. Sci., Univ. of Saskatchewan, Saskatoon, SK, Canada",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,227,237,"Code clones are defined to be the identical or nearly similar code fragments in a code-base. According to a number of existing studies, code clones are directly related to bugs and inconsistencies in software systems. Code cloning (i.e., creating code clones) is suspected to propagate temporarily hidden bugs from one code fragment to another. However, there is no study on the intensity of bug-propagation through code cloning.In this paper we present our empirical study on bug-propagation through code cloning. We define two clone evolution patterns that reasonably indicate bug propagation through code cloning. We first identify code clones that experienced bug-fix changes by analyzing software evolution history, and then determine which of these code clones evolved following the bug propagation patterns. According to our study on thousands of commits of four open-source subject systems written in Java, up to 33% of the clone fragments that experience bug-fix changes can contain propagated bugs. Around 28.57% of the bug-fixes experienced by the code clones can occur for fixing propagated bugs. We also find that near-miss clones are primarily involved with bug-propagation rather than identical clones. The clone fragments involved with bug propagation are mostly method clones. Bug propagation is more likely to occur in the clone fragments that are created in the same commit operation rather than in different commits. Our findings are important for prioritizing code clones for refactoring and tracking from the perspective of bug propagation.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.33,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094424,Bug Propagation;Clone Prioritization;Code Clones,Cloning;Computer bugs;History;Java;Software systems;Tools,Java;program debugging;public domain software;software maintenance;source code (software),Java;bug propagation;bug-fix changes;code cloning;open-source subject systems;software evolution;software systems,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,10
Recommending when Design Technical Debt Should be Self-Admitted,F. Zampetti; C. Noiseux; G. Antoniol; F. Khomh; M. D. Penta,"Dept. of Eng., Univ. of Sannio, Benevento, Italy",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,216,226,"Previous research has shown how developers ""selfadmit"" technical debt introduced in the source code, commenting why such code represents a workaround or a temporary, incomplete solution. This paper investigates the extent to which previously self-admitted technical debt can be used to provide recommendations to developers when they write new source code, suggesting them when to ""self-admit"" design technical debt, or possibly when to improve the code being written. To achieve this goal, we have developed a machine learning approach named TEDIOUS (TEchnical Debt IdentificatiOn System), which leverages various kinds of method-level features as independent variables, including source code structural metrics, readability metrics and, last but not least, warnings raised by static analysis tools. We assessed TEDIOUS on data from nine open source projects for which there are available tagged self-admitted technical debt instances, also comparing the performances of different machine learners. Results of the study indicate that TEDIOUS achieves, when recommending self-admitted technical debts within a single project, an average precision of about 50% and a recall of 52%. When predicting cross-projects, TEDIOUS improves, achieving an average precision of 67% and a recall of 55%. Last, but not least, we noticed how TEDIOUS leverages readability, size and complexity metrics, as well as some warnings raised by static analysis tools.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.44,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094423,Recommender Systems;Self-Admitted Technical Debt;Static Analysis Tools,Complexity theory;Feature extraction;Measurement;Readability metrics;Static analysis;Tools;Training,learning (artificial intelligence);program diagnostics;project management;public domain software;software development management;software maintenance;software metrics;software quality;source code (software),TEDIOUS;TEchnical Debt IdentificatiOn System;complexity metrics;design technical debt;machine learning approach;open source projects;readability metrics;source code structural metrics;source code writing;static analysis tools,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,10
Composite Software Diversification,S. Wang; P. Wang; D. Wu,"Coll. of Inf. Sci. & Technol., Pennsylvania State Univ., University Park, PA, USA",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,284,294,"Many techniques of software vulnerability exploitation rely on deep and comprehensive analysis of vulnerable program binaries. If a copy of the vulnerable software is available to attackers, they can compose their attack scripts and payloads by studying the sample copy and launch attacks on other copies of the same software in deployment. By transforming software into different forms before deployment, software diversification is considered as an effective mitigation of attacks originated from malicious binary analyses.Essentially, developing a software diversification transformation is nontrivial because it has to preserve the original functionality, provide strong enough unpredictability, and introduce negligible cost. Enlightened by research in other areas, we seek to apply different diversification transformations to the same program for a synergy effect such that the resulting hybrid transformations can have boosted diversification effects with modest cost. We name this approach the composite software diversification.Although the concept is straightforward, it becomes challenging when searching for satisfactory compositions of primitive transformations that maximize the synergy effect and make a balance between effectiveness and cost. In this work, we undertake an in-depth study and develop a reasonably well working selection strategy to find a transformation composition that performs better than any single transformation used in the composition. We believe our work can provide guidelines for practitioners who would like to improve the design of diversification tools in the future.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.61,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094429,binary instrumentation;reverse engineering;software diversification,Binary codes;Knowledge engineering;Reverse engineering;Semantics;Software;Software algorithms;Tools,program compilers;program diagnostics;security of data;software reliability,composite software diversification;deep analysis;diversification effects;diversification tools;hybrid transformations;primitive transformations;sample copy;single transformation;software diversification transformation;software vulnerability exploitation;synergy effect;transformation composition;vulnerable program binaries;vulnerable software,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,10
Is it Safe to Uplift this Patch?: An Empirical Study on Mozilla Firefox,M. Castelluccio; L. An; F. Khomh,"DIETI, Univ. Federico II, Napoli, Italy",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,411,421,"In rapid release development processes, patches that fix critical issues, or implement high-value features are often promoted directly from the development channel to a stabilization channel, potentially skipping one or more stabilization channels. This practice is called patch uplift. Patch uplift is risky, because patches that are rushed through the stabilization phase can end up introducing regressions in the code. This paper examines patch uplift operations at Mozilla, with the aim to identify the characteristics of uplifted patches that introduce regressions. Through statistical and manual analyses, we quantitatively and qualitatively investigate the reasons behind patch uplift decisions and the characteristics of uplifted patches that introduced regressions. Additionally, we interviewed three Mozilla release managers to understand organizational factors that affect patch uplift decisions and outcomes. Results show that most patches are uplifted because of a wrong functionality or a crash. Uplifted patches that lead to faults tend to have larger patch size, and most of the faults are due to semantic or memory errors in the patches. Also, release managers are more inclined to accept patch uplift requests that concern certain specific components, and- or that are submitted by certain specific developers.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.82,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094440,Mining software repositories;Patch uplift;Release engineering;Urgent update,Computer bugs;Fault diagnosis;Ion radiation effects;Magnetosphere;Manuals;Measurement,Internet;data mining;program debugging;program testing;public domain software;regression analysis;software development management,Mozilla Firefox;patch uplift;regressions;release engineering;software repositories mining;stabilization channel;statistical analyses,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,10
How Long and How Much: What to Expect from Summer of Code Participants?,J. D. O. Silva; I. S. Wiese; D. M. German; I. F. Steinmacher; M. A. Gerosa,"Pontifical Univ. of Sao Paulo, Sao Paulo, Brazil",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,69,79,"Open Source Software (OSS) communities depend on continu-ally recruiting new contributors. Some communities promote initiatives such as Summers of Code to foster contribution, but little is known about how successful these initiatives are. As a case study, we chose Google Summer of Code (GSoC), which is a three-month internship promoting software development by students in several OSS projects. We quantitatively inves-tigated different aspects of students' contribution, including number of commits, code churn, and contribution date inter-vals. We found that 82% of the studied OSS projects merged at least one commit in codebase. When only newcomers are considered, ~54% of OSS projects merged at least one com-mit. We also found that ~23% of newcomers contributed to GSoC projects before knowing they would be accepted. Addi-tionally, we found that the amount of commits and code of students with experience in the GSoC projects are strongly correlated with how much code they produced and how long they remained during and after GSoC. OSS communities can take advantage of our results to balance the trade-offs in-volved in entering CCEs, to set the communities' expectations about how much contribution they can expect to achieve, and for how long students will probably engage.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.81,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094410,Community Code Engagement;Google Summer of Code;Mining Software Repositories;Newcomers;Open Source Software;Sustainability,Google;Interviews;Open source software;Organizations;Proposals;Sustainable development,public domain software;software engineering;source code (software),GSoC projects;Google Summer of Code;OSS communities;OSS projects;Open Source Software communities;code churn;code participants;com-mit;software development,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,10
An Experiment Comparing Lifted and Delayed Variability-Aware Program Analysis,F. Angerer; P. Grê_nbacher; H. Prê_hofer; L. Linsbauer,"Christian Doppler Lab. MEVSS, Johannes Kepler Univ., Linz, Austria",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,148,158,"Today's software systems need to be highly flexible and managing their variability plays an essential role during development. Variability-aware program analysis techniques have been proposed to support developers in understanding code-level variability by analyzing the space of program variants. Such techniques are highly beneficial, e.g., when determining the impact of changes during maintenance and evolution. Two strategies have been proposed in the literature to make existing program analysis techniques variability-aware:(i) program analysis can be lifted by considering variability already in the parsing stage; or(ii) analysis can be delayed by considering and recovering variability only when needed. Both strategies have advantages and disadvantages, however, a systematic comparison is still missing. The contributions of this paper are an in-depth comparison of SPLLIFT and COACH, two existing approaches representing these two strategies, and an analysis and discussion of the trade-offs regarding precision and run-time performance. The results of our experiment show that the delayed strategy is significantly faster but typically less precise. Our findings are intended for researchers and practitioners deciding which strategy to select for their purpose and context.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.60,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094417,configuration;maintenance and evolution of product lines;variability-aware program analysis,Feature extraction;Image color analysis;Maintenance engineering;Software systems;Systematics;Tools,grammars;program diagnostics,COACH;SPLLIFT;code-level variability;delayed variability-aware program analysis;lifted-variability-aware program analysis;parsing stage,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,10
Refactoring Asynchrony in JavaScript,K. Gallaba; Q. Hanam; A. Mesbah; I. Beschastnikh,"McGill Univ., Montreal, QC, Canada",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,353,363,"JavaScript is a widely used programming language that makes extensive use of asynchronous computation, particularly in the form of asynchronous callbacks. These callbacks are used to handle tasks, from GUI events to network messages, in a non-blocking fashion. Asynchronous callbacks present developers with two challenges. First, JavaScript's try/catch error-handling mechanism is not sufficient for proper error handling in asynchronous contexts. In response, the JavaScript community has come to rely on the error-first protocol, an informal programming idiom that is not enforced or checked by the runtime. Second, JavaScript callbacks are frequently nested, making them difficult to handle (also known as callback hell). Fortunately, a recent language extension called promises provides an alternative to asynchronous callbacks. The adoption of promises, however, has been slow as refactoring existing code to use promises is a complex task. We present a set of program analysis techniques to detect instances of asynchronous callbacks and to refactor such callbacks, including callbacks with the error-first protocol, into promises. We implement our techniques in a tool called PROMISESLAND. We perform a manual analysis of four JavaScript applications to evaluate the tool's precision and recall, which are, on average, 100% and 83%, respectively. We evaluate PROMISESLAND on 21 large JavaScript applications, and find that PROMISESLAND (1) correctly refactors callbacks to promises, (2) outperforms a recent related refactoring technique, and (3) runs in under three seconds on all of our evaluation targets.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.83,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094435,Asynchrony;Callback;JavaScript;Promises;Refactoring,Computer languages;Libraries;Manuals;Programming;Protocols;Tools,Java;error handling;graphical user interfaces;object-oriented programming;program diagnostics;program verification;software maintenance,JavaScript applications;JavaScript callbacks;PROMISESLAND;asynchronous callbacks;asynchronous computation;callback hell;error-first protocol;error-handling mechanism;programming language,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,10
Interaction-Based Tracking of Program Entities for Test Case Evolution,H. A. Nguyen; T. T. Nguyen; T. N. Nguyen; H. V. Nguyen,"Iowa State Univ., Ames, IA, USA",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,433,443,"After changes are made to a system, developers typically perform regression testing to uncover the regression faults in previously existing functionality of the system. However, during software evolution, the program entities (i.e., classes/methods) realizing such functionality might be modified/replaced by other entities. Thus, in the new version, existing test cases containing obsolete class references or method calls might be broken or might not test the intended functionality. To repair the broken method calls in those test cases, for each obsolete class/method, a tester needs to find the corresponding entity that provides the same/similar function or has the same role in the new version. To automate that task, we present ITRACK, a novel tool for matching program entities across versions, which mainly relies on their interactions in the code. The key idea is that the role and functionality of an entity correlate with its interactions with other entities (e.g., how it uses or is used by others). Two entities in two versions are matched based on the similarity of their interactions with other entities in the respective versions via our novel iterative matching algorithm. Our empirical evaluation shows that ITRACK achieves from 84-99% accuracy in identifying the calls in previous test cases that need to be adapted in accordance with the replacements of entities and provide such matching to support repairing broken method calls.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.43,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094442,origin analysis;program differencing;tracking of program entities across versions,Collaboration;Conferences;Documentation;Software;Testing;Tools,program testing;regression analysis;software maintenance,ITRACK;fault regression;interaction;program entities tracking;regression testing;software evolution;test case evolution,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,10
Detecting DOM-Sourced Cross-Site Scripting in Browser Extensions,J. Pan; X. Mao,"Coll. of Comput., Nat. Univ. of Defense Technol., Changsha, China",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,24,34,"In recent years, with the advances in JavaScript engines and the adoption of HTML5 APIs, web applications begin to show a tendency to shift their functionality from the server side towards the client side, resulting in dense and complex interactions with HTML documents using the Document Object Model (DOM). As a consequence, client-side vulnerabilities become more and more prevalent. In this paper, we focus on DOM-sourced Cross-site Scripting (XSS), which is a kind of severe but not well-studied vulnerability appearing in browser extensions. Comparing with conventional DOM-based XSS, a new attack surface is introduced by DOM-sourced XSS where the DOM could become a vulnerable source as well besides common sources such as URLs and form inputs. To discover such vulnerability, we propose a detecting framework employing hybrid analysis with two phases. The first phase is the lightweight static analysis consisting of a text filter and an abstract syntax tree parser, which produces potential vulnerable candidates. The second phase is the dynamic symbolic execution with an additional component named shadow DOM, generating a document as a proof-of-concept exploit. In our large-scale real-world experiment, 58 previously unknown DOM-sourced XSS vulnerabilities were discovered in user scripts of the popular browser extension Greasemonkey.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.11,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094406,DOM-sourced XSS;JavaScript;Web security;browser extension vulnerability;dynamic symbolic execution;shadow DOM,Browsers;Metadata;Static analysis;Uniform resource locators;Web pages,Internet;Java;application program interfaces;computational linguistics;hypermedia markup languages;online front-ends;program diagnostics;program testing;security of data;text analysis;trees (mathematics),DOM-sourced cross-site scripting detection;Document Object Model;HTML documents;HTML5 API;JavaScript engines;Web applications;XSS vulnerabilities;abstract syntax tree parser;browser extensions;client-side vulnerabilities;static analysis;text filter,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,10
Deep Green: Modelling Time-Series of Software Energy Consumption,S. Romansky; N. C. Borle; S. Chowdhury; A. Hindle; R. Greiner,"Dept. of Comput. Sci., Univ. of Alberta, Edmonton, AB, Canada",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,273,283,"Inefficient mobile software kills battery life. Yet, developers lack the tools necessary to detect and solve energy bugs in software. In addition, developers are usually tasked with the creation of software features and triaging existing bugs. This means that most developers do not have the time or resources to research, build, or employ energy debugging tools. We present a new method for predicting software energy consumption to help debug software energy issues. Our approach enables developers to align traces of software behavior with traces of software energy consumption. This allows developers to match run-time energy hot spots to the corresponding execution. We accomplish this by applying recent neural network models to predict time series of energy consumption given a software's behavior. We compare our time series models to prior state-of-the-art models that only predict total software energy consumption. We found that machine learning based time series based models, and LSTM based time series based models, can often be more accurate at predicting instantaneous power use and total energy consumption.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.79,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094428,energy;green mining;modelling;online model;profiling;software engineering,Energy consumption;Energy measurement;Hardware;Predictive models;Software;Time series analysis;Tools,energy consumption;learning (artificial intelligence);mobile computing;neural nets;power aware computing;program debugging;program diagnostics;time series,LSTM;battery life;deep green;energy debugging tools;machine learning;mobile software;run-time energy hot spots;software behavior tracing;time series models;total energy consumption;total software energy consumption,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,10
A Tale of CI Build Failures: An Open Source and a Financial Organization Perspective,C. Vassallo; G. Schermann; F. Zampetti; D. Romano; P. Leitner; A. Zaidman; M. D. Penta; S. Panichella,"Univ. of Zurich, Zurich, Switzerland",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,183,193,"Continuous Integration (CI) and Continuous Delivery (CD) are widespread in both industrial and open-source software (OSS) projects. Recent research characterized build failures in CI and identified factors potentially correlated to them. However, most observations and findings of previous work are exclusively based on OSS projects or data from a single industrial organization. This paper provides a first attempt to compare the CI processes and occurrences of build failures in 349 Java OSS projects and 418 projects from a financial organization, ING Nederland. Through the analysis of 34,182 failing builds (26% of the total number of observed builds), we derived a taxonomy of failures that affect the observed CI processes. Using cluster analysis, we observed that in some cases OSS and ING projects share similar build failure patterns (e.g., few compilation failures as compared to frequent testing failures), while in other cases completely different patterns emerge. In short, we explain how OSS and ING CI processes exhibit commonalities, yet are substantially different in their design and in the failures they report.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.67,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094420,Agile development;Build failures;Continuous Delivery;Continuous Integration,Data mining;Organizations;Servers;Software;Taxonomy;Testing;Tools,Java;financial data processing;project management;public domain software;software development management,ING CI processes;ING Nederland;ING projects;Java OSS projects;build failure patterns;continuous integration;financial organization perspective;frequent testing failures;open-source software projects;single industrial organization,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,10
What are the Testing Habits of Developers? A Case Study in a Large IT Company,V. Blondeau; A. Etien; N. Anquetil; S. Cresson; P. Croisy; S. Ducasse,"CRIStAL, Univ. Lille, Lille, France",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,58,68,"Tests are considered important to ensure the good behavior of applications and improve their quality. But development in companies also involves tight schedules, old habits, less-trained developers, or practical difficulties such as creating a test database. As a result, good testing practices are not always used as often as one might wish. With a major IT company, we are engaged in a project to understand developers testing behavior, and whether it can be improved. Some ideas are to promote testing by reducing test session length, or by running automatically tests behind the scene and send warnings to developers about the failing ones. Reports on developers testing habits in the literature focus on highly distributed open-source projects, or involve students programmers. As such they might not apply to our industrial, closed source, context. In this paper, we take inspiration from experiments of two papers of the literature to enhance our comprehension of the industrial environment. We report the results of a field study on how often the developers use tests in their daily practice, whether they make use of tests selection and why they do. Results are reinforced by interviews with developers involved in the study. The main findings are that test practice is in better shape than we expected; developers select tests ""ruthlessly"" (instead of launching an entire test suite); although they are not accurate in their selection, and; contrary to expectation, test selection is not influenced by the size of the test suite nor the duration of the tests.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.68,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094409,Case study;IT company;Interviews;Regression Test Selection,Companies;Interviews;Manuals;Open source software;Testing;Tools,DP industry;database management systems;program testing;public domain software;software quality,IT company;distributed open-source projects;test database;test practice;test selection;test session length;testing habits,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,10
GEAS: Generic Adaptive Scheduling for High-Efficiency Context Inconsistency Detection,B. Guo; H. Wang; C. Xu; J. Lu,"State Key Lab. for Novel Software Technol., Nanjing Univ., Nanjing, China",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,137,147,"Context-aware applications adapt their behavior based on collected contexts. However, contexts can be inaccurate due to sensing noise, which might cause applications to misbehave. One promising approach is to check contexts against consistency constraints at runtime, so as to detect context inconsistencies for applications and resolve them in time. The checking is typically immediate upon each collected context change. Such a scheduling strategy is intuitive for avoiding missing context inconsistencies in the detection, but may cause low-efficiency problems for heavy-workload checking scenarios, even if equipped with existing incremental or parallel constraint checking techniques. One may choose to check contexts in a batch way to increase the efficiency by reducing the number of constraint checking. However, this can easily cause missed context inconsistencies, denying the purpose of inconsistency detection. In this paper, we propose a novel scheduling strategy GEAS of two nice properties: (1) adaptively tuning the batch window to avoid missing any context inconsistency; (2) generic to checking techniques with no or little adjustment. We experimentally evaluated GEAS against the immediate strategy with existing constraint checking techniques. The experimental results show that GEAS achieved 143-645% efficiency improvement without missing any context inconsistency, while alternatives caused 39.2-65.3% loss of detected context inconsistencies.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.10,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094416,Context inconsistency;scheduling strategy;suspicious pair,Adaptation models;Context;Context modeling;Context-aware services;Sensors;Software;Tuning,constraint handling;program diagnostics;scheduling;ubiquitous computing,batch window;collected context change;context-aware applications;detected context inconsistencies;generic adaptive scheduling;heavy-workload checking scenarios;high-efficiency context inconsistency detection;incremental checking techniques;missed context inconsistencies;parallel constraint checking techniques;scheduling strategy GEAS,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,10
An Empirical Study on the Removal of Self-Admitted Technical Debt,E. D. S. Maldonado; R. Abdalkareem; E. Shihab; A. Serebrenik,"Dept. of Comput. Sci. & Software Eng., Concordia Univ., Montreal, QC, Canada",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,238,248,"Technical debt refers to the phenomena of taking shortcuts to achieve short term gain at the cost of higher maintenance efforts in the future. Recently, approaches were developed to detect technical debt through code comments, referred to as Self-Admitted Technical Debt (SATD). Due to its importance, several studies have focused on the detection of SATD and examined its impact on software quality. However, preliminary findings showed that in some cases SATD may live in a project for a long time, i.e., more than 10 years. These findings clearly show that not all SATD may be regarded as 'bad' and some SATD needs to be removed, while other SATD may be fine to take on.Therefore, in this paper, we study the removal of SATD. In an empirical study on five open source projects, we examine how much SATD is removed and who removes SATD? We also investigate for how long SATD lives in a project and what activities lead to the removal of SATD? Our findings indicate that the majority of SATD is removed and that the majority is self-removed (i.e., removed by the same person that introduced it). Moreover, we find that SATD can last between approx. 18-172 days, on median. Finally, through a developer survey, we find that developers mostly use SATD to track future bugs and areas of the code that need improvements. Also, developers mostly remove SATD when they are fixing bugs or adding new features. Our findings contribute to the body of empirical evidence on SATD, in particular, evidence pertaining to its removal.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.8,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094425,Mining Software Repositories;Self-Admitted Technical Debt;Source Code Quality,Computer bugs;Data mining;Electronic mail;Java;Licenses;Open source software,program debugging;project management;software development management;software maintenance;software quality,SATD;bug fixing;code comments;maintenance efforts;self-admitted technical debt;software quality;technical debt detection,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,10
Recommending Framework Extension Examples,M. Asaduzzaman; C. K. Roy; K. A. Schneider; D. Hou,"Dept. of Comput. Sci., Univ. of Saskatchewan, Saskatoon, SK, Canada",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,456,466,"The use of software frameworks enables the delivery of common functionality but with significantly less effort than when developing from scratch. To meet application specific requirements, the behavior of a framework needs to be customized via extension points. A common way of customizing framework behavior is by passing a framework related object as an argument to an API call. Such an object can be created by subclassing an existing framework class or interface, or by directly customizing an existing framework object. However, to do this effectively requires developers to have extensive knowledge of the framework's extension points and their interactions. To aid the developers in this regard, we propose and evaluate a graph mining approach for extension point management. Specifically, we propose a taxonomy of extension patterns to categorize the various ways an extension point has been used in the code examples. Our approach mines a large amount of code examples to discover all extension points and patterns for each framework class. Given a framework class that is being used, our approach aids the developer by following a two-step recommendation process. First, it recommends all the extension points that are available in the class. Once the developer chooses an extension point, our approach then discovers all of its usage patterns and recommends the best code examples for each pattern. Using five frameworks, we evaluate the performance of our two-step recommendation, in terms of precision, recall, and F-measure. We also report several statistics related to framework extension points.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.80,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094444,API;code example;extension pattern;extension point;framework;graph mining;recommender;reuse,Data mining;Java;Rendering (computer graphics);Search engines;Software;Taxonomy;Tools,application program interfaces;data mining;graph theory;object-oriented methods;software management;software reusability;source code (software),API call;code examples;extension patterns taxonomy;extension point management;framework behavior;framework object;graph mining approach;software framework extension;software reusability,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,10
A Characterization Study of Repeated Bug Fixes,R. Yue; N. Meng; Q. Wang,"Key Lab. of High Confidence Software Technol. (, Peking Univ., Beijing, China",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,422,432,"Programmers always fix bugs when maintaining software. Previous studies showed that developers apply repeated bug fixes-similar or identical code changes-to multiple locations. Based on the observation, researchers built tools to identify code locations in need of similar changes, or to suggest similar bug fixes to multiple code fragments. However, some fundamental research questions, such as what are the characteristics of repeated bug fixes, are still unexplored. In this paper, we present a comprehensive empirical study with 341,856 bug fixes from 3 open source projects to investigate repeated fixes in terms of their frequency, edit locations, and semantic meanings. Specifically, we sampled bug reports and retrieved the corresponding fixing patches in version history. Then we chopped patches into smaller fixes (edit fragments). Among all the fixes related to a bug, we identified repeated fixes using clone detection, and put a fix and its repeated ones into one repeated-fix group. With these groups, we characterized the edit locations, and investigated the common bug patterns as well as common fixes.Our study on Eclipse JDT, Mozilla Firefox, and LibreOffice shows that (1) 15-20% of bugs involved repeated fixes; (2) 73-92% of repeated-fix groups were applied purely to code clones; and (3) 39% of manually examined groups focused on bugs relevant to additions or deletions of whole if-structures. These results deepened our understanding of repeated fixes. They enabled us to assess the effectiveness of existing tools, and will further provide insights for future research directions in automatic software maintenance and program repair.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.16,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094441,empirical study;fix pattern;repeated bug fix,Cloning;Computer bugs;Databases;Maintenance engineering;Semantics;Software;Tools,program debugging;public domain software;software maintenance,automatic software maintenance;bug reports;clone detection;code clones;common bug patterns;common fixes;edit locations;fixing patches;multiple locations;program repair;repeated bug fixes;repeated-fix group,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,10
The Utility Challenge of Privacy-Preserving Data-Sharing in Cross-Company Defect Prediction: An Empirical Study of the CLIFF&MORPH Algorithm,Y. Fan; C. Lv; X. Zhang; G. Zhou; Y. Zhou,"Sch. of Comput. Sci., Nanjing Univ. of Posts & Telecommun., Nanjing, China",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,80,90,"In practice, the data owners of source projects may need to share data without disclosing sensitive information. Therefore, privacy-preserving data-sharing becomes an important topic in cross-company defect prediction (CCDP). In this context, the challenge is how to achieve a high privacy-preserving level while ensuring the utility of the shared privatized data for CCDP. CLIFF&MORPH is a recently proposed state-of-the-art privacy-preserving data-sharing algorithm for CCDP. It has been reported that the CLIFF&MORPH CCDP model produces a promising defect prediction performance. However, we find that ManualDown, a simple (unsupervised) module size model, built on the target projects has a comparable or even better defect prediction performance. Since ManualDown does not require any source project data to build the model, it is free of the privacy-preserving data-sharing challenges for CCDP. This means that, for practitioners, the motivation of applying privacy-preserving data-sharing algorithms to CCDP could not be well justified if the utility challenge is not addressed. We analyze the implications of our findings and outline the directions for future research. In particular, we strongly suggest that future studies at least use ManualDown as a baseline model for comparison to help develop practical privacy-preserving data-sharing algorithms for CCDP.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.57,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094411,cross-project;defect prediction;model;privacy,Companies;Data models;Data privacy;Manuals;Prediction algorithms;Predictive models;Privacy,data privacy,CCDP model;CLIFF and MORPH algorithm;ManualDown;cross-company defect prediction;data owners;defect prediction performance;high privacy-preserving level;practical privacy-preserving data-sharing algorithms;shared privatized data;source project data,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,10
The Pricey Bill of Technical Debt: When and by Whom will it be Paid?,T. Besker; A. Martini; J. Bosch,"Comput. Sci. & Eng., Chalmers Univ. of Technol., Gothenburg, Sweden",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,13,23,"Software companies need to support continuous and fast delivery of customer value both in short and a long-term perspective. However, this can be hindered by evolution limitations and high maintenance efforts due to internal software quality issues by what is described as Technical Debt. Although significant theoretical work has been undertaken to describe the negative effects of Technical Debt, these studies tend to have a weak empirical basis and often lack quantitative data. The aim of this study is to estimate wasted time, caused by the Technical Debt interest during the software life-cycle. This study also investigates how practitioners perceive and estimate the impact of the negative consequences due to Technical Debt during the software development process. This paper reports the results of both an online web-survey provided quantitative data from 258 participants and follow-up interviews with 32 industrial software practitioners. The importance and originality of this study contributes and provides novel insights into the research on Technical Debt by quantifying the perceived interest and the negative effects it has on the software development life-cycle. The findings show that on average, 36% of all development time is estimated to be wasted due to Technical Debt; Complex Architectural Design and Requirement Technical Debt generates most negative effect; and that most time is wasted on understanding and/or measuring the Technical Debt. Moreover, the analysis of the professional roles and the age of the software system in the survey revealed that different roles are affected differently and that the consequences of Technical Debt are also influenced by the age of the software system.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.42,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094405,Development Cost;Empirical Study;Qualitative data;Quantitative data;Software Development;Survey;Technical Debt;Wasted time;component,Companies;Computer science;Interviews;Software quality;Software systems;Time measurement,project management;software houses;software maintenance;software quality,Requirement Technical Debt;Technical Debt interest;complex architectural design;customer value both;internal software quality;online Web-survey;pricey bill;software companies;software development process;software life-cycle;software system,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,10
Semantics-Aware Machine Learning for Function Recognition in Binary Code,S. Wang; P. Wang; D. Wu,"Coll. of Inf. Sci. & Technol., Pennsylvania State Univ., University Park, PA, USA",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,388,398,"Function recognition in program binaries serves as the foundation for many binary instrumentation and analysis tasks. However, as binaries are usually stripped before distribution, function information is indeed absent in most binaries. By far, identifying functions in stripped binaries remains a challenge. Recent research work proposes to recognize functions in binary code through machine learning techniques. The recognition model, including typical function entry point patterns, is automatically constructed through learning. However, we observed that as previous work only leverages syntax-level features to train the model, binary obfuscation techniques can undermine the pre-learned models in real-world usage scenarios. In this paper, we propose FID, a semantics-based method to recognize functions in stripped binaries. We leverage symbolic execution to generate semantic information and learn the function recognition model through well-performing machine learning techniques.FID extracts semantic information from binary code and, therefore, is effectively adapted to different compilers and optimizations. Moreover, we also demonstrate that FID has high recognition accuracy on binaries transformed by widely-used obfuscation techniques. We evaluate FID with over four thousand test cases. Our evaluation shows that FID is comparable with previous work on normal binaries and it notably outperforms existing tools on obfuscated code.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.59,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094438,function recognition;machine learning;reverse engineering,Binary codes;Instruments;Registers;Reverse engineering;Semantics;Syntactics;Tools,binary codes;learning (artificial intelligence);program diagnostics,FID;analysis tasks;binary code;binary instrumentation;binary obfuscation techniques;function information;function recognition model;program binaries;semantic information;semantics-aware machine learning;syntax-level features;typical function entry point patterns,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,10
The Evaluation of an Approach for Automatic Generated Documentation,N. Abid; N. Dragan; M. L. Collard; J. I. Maletic,"Dept. of Comput. Sci., Kent State Univ., Kent, OH, USA",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,307,317,"Two studies are conducted to evaluate an approach to automatically generate natural language documentation summaries for C++ methods. The documentation approach relies on a method's stereotype information. First, each method is automatically assigned a stereotype(s) based on static analysis and a set of heuristics. Then, the approach uses the stereotype information, static analysis, and predefined templates to generate a natural-language summary/documentation for each method. This documentation is automatically added to the code base as a comment for each method. The result of the first study reveals that the generated documentation is accurate, does not include unnecessary information, and does a reasonable job describing what the method does. Based on statistical analysis of the second study, the most important part of the documentation is the short description as it describes the intended behavior of a method.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.76,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094431,method stereotypes;program comprehension;source-code summarization;static analysis,C++ languages;Documentation;Java;Pragmatics;Static analysis,C++ language;natural language processing;program diagnostics;statistical analysis;system documentation,C++ methods;automatic generated documentation;natural language documentation summaries;static analysis;statistical analysis;stereotype information,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,10
Embroidery: Patching Vulnerable Binary Code of Fragmentized Android Devices,X. Zhang; Y. Zhang; J. Li; Y. Hu; H. Li; D. Gu,"Shanghai Jiao Tong Univ., Shanghai, China",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,47,57,"The rapid-iteration, web-style update cycle of Android helps fix revealed security vulnerabilities for its latest version. However, such security enhancements are usually only available for few Android devices released by certain manufacturers (e.g., Google's official Nexus devices). More manufactures choose to stop providing system update service for their obsolete models, remaining millions of vulnerable Android devices in use. In this situation, a feasible solution is to leverage existing source code patches to fix outdated vulnerable devices. To implement this, we introduce Embroidery, a binary rewriting based vulnerability patching system for obsolete Android devices without requiring the manufacturer's source code against Android fragmentation. Embroidery patches the known critical framework and kernel vulnerabilities in Android using both static and dynamic binary rewriting techniques. It transplants official patches (CVE source code patches) of known vulnerabilities to different devices by adopting heuristic matching strategies to deal with the code diversity introduced by Android fragmentation, and fulfills a complex dynamic memory modification to implement kernel vulnerabilities patching. We employ Embroidery to patch sophisticated Android kernel and framework vulnerabilities for various manufactures' obsolete devices ranging from Android 4.2 to 5.1. The result shows the patched devices are able to defend against known exploits and the normal functions are not affected.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.15,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094408,Fragmentized Android Devices;Patching,Androids;Binary codes;Ecosystems;Google;Humanoid robots;Kernel;Security,binary codes;mobile computing;rewriting systems;security of data;source code (software),Android fragmentation;CVE source code patches;Embroidery;Web-style update cycle;binary code patching;binary rewriting based vulnerability patching system;code diversity;dynamic binary rewriting techniques;heuristic matching strategies;kernel vulnerabilities patching;obsolete Android devices;security enhancements;security vulnerabilities;static binary rewriting techniques;system update service;vulnerable Android devices,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,10
Personality and Project Success: Insights from a Large-Scale Study with Professionals,X. Xia; D. Lo; L. Bao; A. Sharma; S. Li,"Zhejiang Univ., Hangzhou, China",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,318,328,"A software project is typically completed as a result of a collective effort done by individuals of different personalities. Personality reflects differences among people in behaviour patterns, communication, cognition and emotion. It often impacts relationships and collaborative work, and software engineering teamwork is no exception. Some personalities are more likely to click while others to clash. A number of studies have investigated the relationship between personality and collaborative work success. However, most of them are done in a laboratory setting, do not involve professionals, or consider non software engineering tasks. Additionally, they only answer a limited set of questions, and many other questions remain open.To enrich the existing body of work, we study professionals working on real software projects, answering a new set of research questions that assess linkages between project manager personality and team personality composition and project success. In particular, our study investigates 28 recently completed software projects, which contain a total of 346 professionals, in 2 large IT companies. We asked project members to do a DISC (Dominance, Influence, Steadiness, and Compliant) personality test, and correlated the test outcomes with project success scores measured in six different dimensions. The scores were given by managers of three office as part of their regular day-to-day work. Our results show that project teams with dominant managers, along with those with more influential members and less dominant members, have higher success scores. This work provides new insights to construct a personality matching strategy that can contribute to building an effective project team.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.50,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094432,Personality;Project Success;Software Project;Team Formation,Collaborative work;Companies;Outsourcing;Software;Software engineering;Tools,groupware;project management;software development management;team working,"DISC personality test;behaviour patterns;cognition;collaborative work success;communication;dominance, influence, steadiness, and compliant;dominant managers;dominant members;effective project team;emotion;influential members;laboratory setting;nonsoftware engineering tasks;personality matching strategy;professionals;project manager personality;project members;project success scores;project teams;software engineering teamwork;software projects;team personality composition",,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,10
How do Developers Test Android Applications?,M. Linares-Vêçsquez; C. Bernal-Cardenas; K. Moran; D. Poshyvanyk,"Univ. de Los Andes, Bogota, Colombia",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,613,622,"Enabling fully automated testing of mobile applications has recently become an important topic of study for both researchers and practitioners. A plethora of tools and approaches have been proposed to aid mobile developers both by augmenting manual testing practices and by automating various parts of the testing process. However, current approaches for automated testing fall short in convincing developers about their benefits, leading to a majority of mobile testing being performed manually. With the goal of helping researchers and practitioners - who design approaches supporting mobile testing - to understand developer's needs, we analyzed survey responses from 102 open source contributors to Android projects about their practices when performing testing. The survey focused on questions regarding practices and preferences of developers/testers in-the-wild for (i) designing and generating test cases, (ii) automated testing practices, and (iii) perceptions of quality metrics such as code coverage for determining test quality. Analyzing the information gleaned from this survey, we compile a body of knowledge to help guide researchers and professionals toward tailoring new automated testing approaches to the need of a diverse set of open source developers.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.47,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094467,,Androids;Humanoid robots;Manuals;Mobile communication;Programming;Testing;Tools,Android (operating system);mobile computing;program testing,Android applications;automated testing approaches;automated testing practices;mobile applications;mobile developers;mobile testing;open source developers;test quality,,1,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,9
RCIA: Automated Change Impact Analysis to Facilitate a Practical Cancer Registry System,S. Wang; T. Schwitalla; T. Yue; S. Ali; J. F. Nygê‰rd,"Simula Res. Lab., Oslo, Norway",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,603,612,"The Cancer Registry of Norway (CRN) employs a cancer registry system to collect cancer patient data (e.g., diagnosis and treatments) from various medical entities (e.g., clinic hospitals). The collected data are then checked for validity (i.e., validation) and assembled as cancer cases (i.e., aggregation) based on more than 1000 cancer coding rules in the system. However, it is frequent in practice that the collected cancer data changes due to various reasons (e.g., different treatments) and the cancer coding rules can also change/evolve due to new medical knowledge. Thus, such a cancer registry system requires an efficient means to automatically analyze these changes and provide consequent impacts to medical experts for further actions. This paper proposes an automated Rule-based Change Impact Analysis (CIA) approach named RCIA that includes: 1) a change classification to capture the potential changes that can occur at CRN; 2) in total 80 change impact analysis rules including 50 dependency rules and 30 impact rules; and 3) an efficient algorithm to analyze changes and produce consequent impacts. We evaluate RCIA via a case study with 12 real change sets from CRN and a conducted interview. The results showed that RCIA managed to produce 100% actual change impacts and the medical expert at CRN is quite positive to apply RCIA to facilitate their cancer registry system. We also shared a set of lessons learned based on the collaboration with CRN.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.22,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094466,cancer coding rules;cancer registry system;change classification;change impact analysis,Cancer;Encoding;Hospitals;Manuals;Medical diagnostic imaging;Surgery;Systematics,cancer;data analysis;data mining;expert systems;knowledge based systems;medical information systems;patient diagnosis;pattern classification,CRN;RCIA;automated change impact analysis;cancer patient data;cancer registry system;change classification;medical expert;rule-based change impact analysis,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,9
Coarse Hierarchical Delta Debugging,R. Hodovêçn; êÅ. Kiss; T. Gyimê_thy,"Dept. of Software Eng., Univ. of Szeged, Szeged, Hungary",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,194,203,"This paper introduces the Coarse Hierarchical Delta Debugging algorithm for efficient test case reduction. It can be used as a test case simplification algorithm in its own right if theoretical minimality is not a strict requirement, or it can act as a preprocessing step to the original Hierarchical Delta Debugging algorithm. Evaluation of artificial and real test cases shows that a coarse variant can produce reduced test cases with significantly fewer testing steps than the original algorithm (58% gain on average, 79% maximum), while still keeping the outputs acceptably small (never increasing the reduced test cases by more than 0.36% of the input).",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.26,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094421,coarse algorithm;hierarchical delta debugging;test case reduction,Computer crashes;Debugging;Grammar;Minimization;Software algorithms;Syntactics;Testing,data structures;program debugging;program testing,Coarse Hierarchical Delta Debugging algorithm;artificial test cases;efficient test case reduction;preprocessing step;real test cases;theoretical minimality,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,9
Predicting and Evaluating Software Model Growth in the Automotive Industry,J. Schroeder; C. Berger; A. Knauss; H. Preenja; M. Ali; M. Staron; T. Herpel,"Dept. of Comput. Sci. & Eng., Chalmers & Univ. of Gothenburg, Gothenburg, Sweden",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,584,593,"The size of a software artifact influences the software quality and impacts the development process. In industry, when software size exceeds certain thresholds, memory errors accumulate and development tools might not be able to cope anymore, resulting in a lengthy program start up times, failing builds, or memory problems at unpredictable times. Thus, foreseeing critical growth in software modules meets a high demand in industrial practice. Predicting the time when the size grows to the level where maintenance is needed prevents unexpected efforts and helps to spot problematic artifacts before they become critical. Although the amount of prediction approaches in literature is vast, it is unclear how well they fit with prerequisites and expectations from practice. In this paper, we perform an industrial case study at an automotive manufacturer to explore applicability and usability of prediction approaches in practice. In a first step, we collect the most relevant prediction approaches from literature, including both, approaches using statistics and machine learning. Furthermore, we elicit expectations towards predictions from practitioners using a survey and stakeholder workshops. At the same time, we measure software size of 48 software artifacts by mining four years of revision history, resulting in 4,547 data points. In the last step, we assess the applicability of state-of-the-art prediction approaches using the collected data by systematically analyzing how well they fulfill the practitioners' expectations. Our main contribution is a comparison of commonly used prediction approaches in a real world industrial setting while considering stakeholder expectations. We show that the approaches provide significantly different results regarding prediction accuracy and that the statistical approaches fit our data best.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.41,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094464,machine learning;measurement;model-based-software;prediction;software size;time series,Automotive engineering;Complexity theory;Mathematical model;Measurement;Predictive models;Software;Time series analysis,automobile industry;automobile manufacture;data mining;learning (artificial intelligence);production engineering computing;software metrics;software quality;statistical analysis,automotive industry;automotive manufacturer;machine learning;mining;prediction approaches;software artifact;software development process;software model growth;software modules;software quality;software size;statistics,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,9
Graph Data Management of Evolving Dependency Graphs for Multi-versioned Codebases,O. Goonetilleke; D. Meibusch; B. Barham,"Oracle Labs., Brisbane, QLD, Australia",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,574,583,"FrappeêÅ is a code comprehension tool developed by Oracle Labs that extracts the code dependencies from a codebase and stores them in a graph database enabling advanced comprehension tasks. In addition to traditional text-based queries, such context-sensitive tools allow developers to express navigational queries of the form Does function X or something it calls write to global variable Y? providing more insight into the underlying codebases. Frappe captures the dependencies based on the most recent snapshot of the codebase.In this work we focus on the challenges associated with the management of multiple source code revisions, and investigate strategies to enable advanced code comprehension when the underlying codebase evolves over time. To find the deltas, we detail how entities can be resolved across versions, and propose a model for representing evolving dependency graphs. Our versioned graphs are built using snapshots of large codebases in the order of 13 million lines of code.We show growth and storage benefits of versioned graphs compared to independently storing individual snapshots. We also demonstrate how existing Frappe queries can be executed on versioned graphs and new queries can retrieve a history of changes in a function for a code review use case.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.54,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094463,entity resolution;evolving dependency graphs;graph database;versioned codebase,Buildings;Data mining;Databases;History;Navigation;Tools,graph theory;query processing;software maintenance;software tools;text analysis,Frappe queries;Oracle Labs;code comprehension tool;code dependencies;code review;comprehension tasks;context-sensitive tools;graph data management;graph database;multiple source code revisions;navigational queries;text-based queries;versioned graphs,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,9
Behavior Metrics for Prioritizing Investigations of Exceptions,Z. Coker; K. Damevski; C. L. Goues; N. A. Kraft; D. Shepherd; L. Pollock,"Carnegie Mellon Univ., Pittsburgh, PA, USA",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,554,563,"Many software development teams collect product defect reports, which can either be manually submitted or automatically created from product logs. Periodically, the teams use the collected defect reports to prioritize which defect to address next. We present a set of behavior-based metrics that can be used in this process. These metrics are based on the insight that development teams can estimate user inconvenience from user and application behavior in interaction logs. To estimate user inconvenience, the behavior metrics capture important user and application behavior after exceptions (the defects of interest in our case). We validated these metrics through a survey of how developers would incorporate the behavior metrics into their prioritization decisions. We found that developers change their priority of investigating an exception about 31% of the time after including the behavior metrics in the priority decision. These findings provide evidence that behavior metrics provide a promising advance towards prioritizing application exceptions.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.62,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094461,Behavior Metrics;Bug Triage;Exceptions;IDE Usage Data;Stack Traces,Atmospheric measurements;Computer bugs;Manuals;Particle measurements;Robots,program debugging;software development management;software metrics,application behavior;behavior metrics;collected defect reports;prioritizing investigations;product defect reports;product logs;software development teams;user inconvenience estimation,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,9
Towards Accurate Duplicate Bug Retrieval Using Deep Learning Techniques,J. Deshmukh; A. K. M; S. Podder; S. Sengupta; N. Dubash,,2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,115,124,"Duplicate Bug Detection is the problem of identifying whether a newly reported bug is a duplicate of an existing bug in the system and retrieving the original or similar bugs from the past. This is required to avoid costly rediscovery and redundant work. In typical software projects, the number of duplicate bugs reported may run into the order of thousands, making it expensive in terms of cost and time for manual intervention. This makes the problem of duplicate or similar bug detection an important one in Software Engineering domain. However, an automated solution for the same is not quite accurate yet in practice, in spite of many reported approaches using various machine learning techniques. In this work, we propose a retrieval and classification model using Siamese Convolutional Neural Networks (CNN) and Long Short Term Memory (LSTM) for accurate detection and retrieval of duplicate and similar bugs. We report an accuracy close to 90% and recall rate close to 80%, which makes possible the practical use of such a system. We describe our model in detail along with related discussions from the Deep Learning domain. By presenting the detailed experimental results, we illustrate the effectiveness of the model in practical systems, including for repositories for which supervised training data is not available.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.69,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094414,Convolutional Neural Networks;Deep Learning;Duplicate Bug Detection;Information Retrieval;Long Short Term Memory;Natural Language Processing;Siamese Networks;Word Embeddings,Computational modeling;Computer bugs;Machine learning;Neural networks;Sun;Training,feedforward neural nets;information retrieval;learning (artificial intelligence);pattern classification;program debugging;software development management,CNN;Deep Learning domain;Deep Learning techniques;Duplicate Bug Detection;LSTM;Long Short Term Memory;Siamese Convolutional Neural Networks;Software Engineering domain;accurate detection;classification model;costly rediscovery;duplicate Bug retrieval;existing bug;machine learning techniques;newly reported bug;original bugs;redundant work;similar bug detection;supervised training data;typical software projects,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,9
An Experience Report on Applying Passive Learning in a Large-Scale Payment Company,R. Wieman; M. F. Aniche; W. Lobbezoo; S. Verwer; A. v. Deursen,"Delft Univ. of Technol., Delft, Netherlands",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,564,573,"Passive learning techniques infer graph models on the behavior of a system from large trace logs. The research community has been dedicating great effort in making passive learning techniques more scalable and ready to use by industry. However, there is still a lack of empirical knowledge on the usefulness and applicability of such techniques in large scale real systems. To that aim, we conducted action research over nine months in a large payment company. Throughout this period, we iteratively applied passive learning techniques with the goal of revealing useful information to the development team. In each iteration, we discussed the findings and challenges to the expert developer of the company, and we improved our tools accordingly. In this paper, we present evidence that passive learning can indeed support development teams, a set of lessons we learned during our experience, a proposed guide to facilitate its adoption, and current research challenges.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.71,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094462,dfasat;experience report;passive learning,Automata;Companies;Industries;Inference algorithms;Merging;Software;Tools,financial data processing;graph theory;learning (artificial intelligence);system monitoring,development team;graph models;large scale real systems;large-scale payment company;passive learning;system behavior;trace logs,,1,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,9
Mean Average Distance to Resolver: An Evaluation Metric for Ticket Routing in Expert Network,J. Han; A. Sun,"SAP Innovation Center, Singapore, Singapore",2017 IEEE International Conference on Software Maintenance and Evolution (ICSME),20171107,2017,,,594,602,"In the technical support division of a large enterprise software provider, customers' technical incidents, problems, and change requests are processed as tickets. Each ticket is assigned to a support engineer for processing. Due to the limited expertise of individuals, resolving a ticket may involve routing the ticket among multiple groups of engineers. Each routing step costs time and resources. It is desirable for experts to route a ticket to its most likely resolver with minimum steps. Automated or semi-automated systems are proposed to improve routing efficiency. To evaluate the performance of any system, including human routing, two metrics are commonly used, namely Mean Steps to Resolver (MSTR) and Resolution Rate (RR). The two measures are designed independently, with different objectives and at different scales, making it difficult to compare systems. Moreover, the current measures only consider the resolver group as the ground truth, even during path-level evaluation. They disregard the contribution of intermediate groups during the ticket resolution. In this paper, we propose a distance-based unified evaluation measure named Mean Average Distance to Resolver (MADR). This new framework addresses the aforementioned limitations, and it can be easily modified to adapt to different business requirements in different organizations. In addition, existing evaluation paradigm does not consider human routing steps except the resolver. We argue that the predicted paths may not be followed exactly by expert groups in real operation. An assistive routing evaluation framework is therefore designed to take into account expert's choice when recommendation fails, for each routing. Experiments using proprietary data from a large enterprise demonstrate that MADR can be used to benchmark and compare routing systems.",,Electronic:978-1-5386-0992-7; POD:978-1-5386-0993-4,10.1109/ICSME.2017.18,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094465,MADR;MSTR;RR;Ticket routing;expert network,Business;Measurement;Routing;Software;Sun;Testing,business data processing;technical support services,Mean Average Distance to Resolver;Mean Steps to Resolver;Resolution Rate;assistive routing evaluation framework;business requirements;distance-based unified evaluation measure;enterprise software provider;expert groups;expert network;human routing steps;path-level evaluation;resolver group;routing efficiency;routing systems;semiautomated systems;support engineer;technical support division;ticket resolution;ticket routing,,,,,,,,17-22 Sept. 2017,,IEEE,IEEE Conferences,,8